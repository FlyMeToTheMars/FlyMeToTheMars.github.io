<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Mars</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-04-29T12:06:56.834Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Fly Hugh</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CDH集群代理状态问题</title>
    <link href="http://yoursite.com/2019/04/29/Cluster%20Error%20Record1/"/>
    <id>http://yoursite.com/2019/04/29/Cluster Error Record1/</id>
    <published>2019-04-29T09:27:12.000Z</published>
    <updated>2019-04-29T12:06:56.834Z</updated>
    
    <content type="html"><![CDATA[<p>公司测试集群因为有好几个项目组的同事都在用，时不时会出一些问题</p><p>昨天下班前，集群报警</p><p>CDH中查看主机状态<br>datanode128出现：该主机与 Cloudera Manager Server 失去联系的时间过长。 该主机未与 Host Monitor 建立联系。</p><p>运行状态检测出现问题：<br><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g2jn7huhlvj20kg0n3wgi.jpg" alt="alt bug"></p><a id="more"></a> <p>几乎所有组件处于警告状态，基本可以确定是交换内存的问题，如果内存足够大，可以直接取消交换内存</p><p>查看节点agent 状态：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@datanode128 ~]# /data2/CM/cm-5.13.3/etc/init.d/cloudera-scm-agent status</span><br><span class="line">cloudera-scm-agent 已死，但 pid 文件存在</span><br></pre></td></tr></table></figure><p>解决办法：删除了pid文件，重新增加节点，将swappiness设置为0（不能用VIM设置，用<code>sysctl -w vm.swappiness=0</code>），swappiness文件有一些特性，这边不展开。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;公司测试集群因为有好几个项目组的同事都在用，时不时会出一些问题&lt;/p&gt;
&lt;p&gt;昨天下班前，集群报警&lt;/p&gt;
&lt;p&gt;CDH中查看主机状态&lt;br&gt;datanode128出现：该主机与 Cloudera Manager Server 失去联系的时间过长。 该主机未与 Host Monitor 建立联系。&lt;/p&gt;
&lt;p&gt;运行状态检测出现问题：&lt;br&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/bec9bff2ly1g2jn7huhlvj20kg0n3wgi.jpg&quot; alt=&quot;alt bug&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Apache Kudu</title>
    <link href="http://yoursite.com/2019/04/29/Kudu-Note/"/>
    <id>http://yoursite.com/2019/04/29/Kudu-Note/</id>
    <published>2019-04-29T09:27:12.000Z</published>
    <updated>2019-04-29T09:34:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Kudu</p><p>一图以蔽之：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g2jmwis7z6j20cj0brgln.jpg" alt="alt kudu"></p><a id="more"></a> <h3 id="1-Apache-Kudu介绍"><a href="#1-Apache-Kudu介绍" class="headerlink" title="1.Apache Kudu介绍"></a>1.Apache Kudu介绍</h3><blockquote><p>部分内容翻译自Kudu 1.7.1文档</p></blockquote><p>Kudu是为Apachche Hadoop平台开发的柱状存储管理器，Kudu有Hadoop生态系统应用的普遍技术属性：运行在商业硬件上，可以横向拓展，支持高可用操作。</p><p>Kudu的优点包括：</p><ul><li>快速处理OLAP（联机分析处理）工作负载</li><li>与MR、Spark和其他Hadoop生态组件整合</li><li>与Apache Impala紧密结合，使它成为在Apache Parquet使用HDFS的一个好的，可变的替代方案</li><li>强大但灵活的一致性迷行，允许你根据每个请求选择一致性要求，包括严格可序列化一致性选项</li><li>同时运行顺序和随机工作负载的强大性能</li><li>对于管理员，使用Cloudera Manager容易管理</li><li>高可用、Tablet服务和Master使用共识算法，保证只要超过一半的副本可用，table就可以读写</li><li>结构化数据模型</li></ul><p>通过结合这些特性，Kudu出现的目的是为了解决当前hadoop技术难以达成的应用场景，例如：</p><ul><li>新到达的数据要被立刻提供给用户报表</li><li>时间序列应用必须同时支持的：大量历史数据的查询的要求、对某个细颗粒查询迅速返回的时间要求</li><li>在基于所有历史数据来做出实时决策的预测模型上的应用</li></ul><h3 id="2-Kudu与Impala在CDH中的集成"><a href="#2-Kudu与Impala在CDH中的集成" class="headerlink" title="2.Kudu与Impala在CDH中的集成"></a>2.Kudu与Impala在CDH中的集成</h3><p><img src="https://s2.ax1x.com/2019/04/17/Az1eTx.png" alt="Az1eTx.png"></p><p>如图只要在impala的配置中配置该项目，配置项目为kudu_master_hosts，配置内容为kudu的master节点，端口号默认为7051</p><p>配置完成之后简单测试：</p><p>在HUE中调用impala的输入框中输入：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> my_first_table </span><br><span class="line">( </span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">BIGINT</span>, <span class="keyword">name</span> <span class="keyword">STRING</span>, PRIMARY <span class="keyword">KEY</span>(<span class="keyword">id</span>) </span><br><span class="line">) </span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">HASH</span> <span class="keyword">PARTITIONS</span> <span class="number">16</span> </span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br></pre></td></tr></table></figure><p>即可建立表格。</p><hr><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> my_first_table <span class="keyword">values</span> (<span class="number">99</span>,<span class="string">"sarah"</span>);</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO  my_first_table VALUES (1, &quot;john&quot;), (2, &quot;jane&quot;), (3,  &quot;jim&quot;);</span><br></pre></td></tr></table></figure><p>插入语句</p><hr><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span>  my_first_table;</span><br></pre></td></tr></table></figure><p>查表</p><hr><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span>  my_first_table <span class="keyword">where</span> <span class="keyword">id</span> =<span class="number">99</span>;</span><br></pre></td></tr></table></figure><p>删除语句</p><hr><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">update</span> my_first_table  <span class="keyword">set</span> <span class="keyword">name</span>=<span class="string">'lilei'</span> <span class="keyword">where</span> <span class="keyword">id</span>=<span class="number">99</span>;</span><br></pre></td></tr></table></figure><p>改语句</p><hr><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">upsert  into my_first_table <span class="keyword">values</span>(<span class="number">1</span>,  <span class="string">"john"</span>), (<span class="number">4</span>, <span class="string">"tom"</span>), (<span class="number">99</span>, <span class="string">"lilei1"</span>);</span><br></pre></td></tr></table></figure><p>Kudu中的upsert是update和insert的结合体，有更新就更新，没有该条数据就插入。</p><p>这边联想到mongo中的upsert，MongoDB 的update 方法的三个参数是upsert，这个参数是个布尔类型，默认是false。当它为true的时候，update方法会首先查找与第一个参数匹配的记录，在用第二个参数更新之。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.post.update(&#123;count:100&#125;,&#123;"$inc":&#123;count:10&#125;&#125;,true);</span><br></pre></td></tr></table></figure><p>在找不到count=100这条记录的时候，自动插入一条count=100，然后再加10，最后得到一条 count=110的记录。</p><h4 id="Kudu-Impala整合特征"><a href="#Kudu-Impala整合特征" class="headerlink" title="Kudu-Impala整合特征"></a>Kudu-Impala整合特征</h4><p>CREATE/ALTER/DROP TABLE</p><p>Impala支持使用Kudu作为持久层创建、修改和删除表，这些表和Impala其他表使用同样的内部和外部方法，允许复杂的数据整合和查询。</p><p>INSERT</p><p>可以使用通用语法插入数据到Kudu-Imapala表格</p><p>UPDATE/DELETE</p><p>支持SQL命令逐行或者批量修改Kudu表中存在的数据。SQL的语法尽可能与现有的相同。</p><p><strong>Flexible Partitioning</strong></p><p>和Hive表类似，Kudu也支持hash或者range预先动态分区，以便在集群中均匀读写。你可以通过很多方式分区，比如说任意列的主键，任意数量的哈希。</p><p><strong>并行扫描</strong></p><p>为了在现在硬件上达到最高可用性能，Impala使用Kudu并行扫描多个客户端。</p><p><strong>高效查询</strong></p><p>可能的时候，Impala会吧谓词评估推送给kudu,以便尽可能接近数据，在很多工作下，查询性能和Parquet相当。</p><p>更多细节需要查询Impala文档。</p><hr><h3 id="3-概念和术语"><a href="#3-概念和术语" class="headerlink" title="3. 概念和术语"></a>3. 概念和术语</h3><p><strong>Columnar Data Store</strong></p><p><em>列存储</em></p><p>Kudu是列存储，列存储是强类型的，通过适当的设计，相对于数仓是优越的，因为几个原因。</p><p><strong>Read Efficiency</strong></p><p><em>读取效率</em></p><p>对于分析查询，可以单独读取一列，或者一列的一部分，而忽略其他列。这意味着你可以在磁盘上读取最小的数据来满足查询。</p><p><strong>Data Compression</strong></p><p><em>数据压缩</em></p><p>因为是强类型，所以数据的压缩比要比基于行的解决方案效率高几个数量级。</p><p><strong>Table</strong></p><p>Table是数据存储在Kudu的位置，Table有schema和一个完全有序的主键，一个表被分割成叫做tablets的segment。</p><p><strong>Tablet</strong></p><p>首先，tablet是table的segment，类似于partition 机制。Tablet里面本身还涉及副本机制等。</p><p><strong>Tablet Server</strong></p><p>对于Tablet的副本机制来说，每个tablet都会有一个leader，别的是follower，leaders会接收读和写请求，followers只接受读请求。涉及到副本机制就涉及到共识算法，这里面用的共识算法是Raft Consensus Algorithm。</p><p><strong>Master</strong></p><p>Master跟踪tablets，tablet Server，Catalog Table 以及和Cluster关联的元数据，只能有一个master，如果挂了，那么会用Raft Consensus Algorithm重新选举一个出来。</p><p><em>Raft Consensus Algorithm</em></p><p>和Paxos一样是一个重要的共识算法</p><p><em>Catalog Table</em></p><p>Catalog Table是matadata的核心部位，记录table和tablets的信息，不能直接读写，只能通过Client API进行改动，存储两种类型的数据。</p><p>Tables：table的schemas, locations, and states</p><p>Tablets：tablets的list，tablet Server的映射关系，states，start and end keys</p><p><em>Logical Replication</em></p><p>逻辑复制：Kudu复制文件仅仅是逻辑上的复制，并没有涉及物理上的复制，这样做有几个好处：</p><ul><li><p>尽管插入和更新操作通过网络传输数据，删除操作不需要移动任何数据。删除操作被送到每一个执行本地删除操作的tablet server。</p></li><li><p>压缩这样的物理操作，不需要通过网络传输，这和使用HDFS的存储系统是不同的，HDFS中的blocks需要通过网络传输block来满足复制的需求。</p></li><li><p>Tablets不需要在同一时间压缩，或者其他在物理层上的同步，这降低了tablet因为大量压缩和写入遇到延迟的可能性。</p></li></ul><hr><h3 id="4-Java访问CDH集群中的Kudu"><a href="#4-Java访问CDH集群中的Kudu" class="headerlink" title="4.Java访问CDH集群中的Kudu"></a>4.Java访问CDH集群中的Kudu</h3><p>如果使用的不是局域网，跨网段需要进行配置。</p><p>需要在KuduMaster服务的高级配置“gflagfile 的 Master 高级配置代码段（安全阀）”增加配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">这个是受信人的子网名单，设置为0000代表允许所有IP没有经过验证/未加密的连接</span><br><span class="line"></span><br><span class="line">如果没有配置这个名单，会报错：</span><br><span class="line"></span><br><span class="line">```java</span><br><span class="line">W1128 16:56:55.749083 93981 negotiation.cc:318] Unauthorized connection attempt: Server connection negotiation failed: server connection from 100.73.0.57:42533: unauthenticated connections from publicly routable IPs are prohibited. See --trusted_subnets flag for more information</span><br></pre></td></tr></table></figure><p>## </p><h3 id="5-架构概述"><a href="#5-架构概述" class="headerlink" title="5.架构概述"></a>5.架构概述</h3><p>下图显示了一个Kudu集群，三个Master和多个table servers，每一个Server服务多个tablets。</p><p>这个图表明了Raft共识算法是如何作用在master-tablet server的master和server上的。</p><p>此外，一个 tablet server 既可以成为tablets的leader，也可以成为一个别的follower</p><p><img src="https://kudu.apache.org/docs/images/kudu-architecture-2.png" alt="底层结构"></p><p>只要有一半以上的副本可用，该tablet便可用于读写，技师在leader tablet出现故障的情况下，读取功能也可以通过read-only（只读）follower tablets来进行服务，或者是leader宕机的情况下，根据raft算法重新选举leader。</p><p>开发语言：C++</p><ul><li>建表的时候要求所有的tserver节点都活着 </li><li>根据raft机制，允许（replication的副本数-）/ 2宕掉，集群还会正常运行，否则会报错找不到ip:7050（7050是rpc的通信端口号），需要注意一个问题，第一次运行的时候要保证集群处于正常状态下，也就是所有的服务都启动，如果运行过程中，允许（replication的副本数-）/ 2宕掉 </li><li>读操作，只要有一台活着的情况下，就可以运行</li><li>KUDU分区数必须预先预定</li><li>在内存中对每个Tablet分区维护一个MemRowSet来管理最新更新的数据，当尺寸超过32M后Flush到磁盘上形成DiskRowSet，多个DiskRowSet在适当的时候进行归并处理 </li><li>和HBase采用的LSM（LogStructured Merge，很难对数据进行特殊编码，所以处理效率不高）方案不同的是，Kudu对同一行的数据更新记录的合并工作，不是在查询的时候发生的（HBase会将多条更新记录先后Flush到不同的Storefile中，所以读取时需要扫描多个文件，比较rowkey，比较版本等，然后进行更新操作），而是在更新的时候进行，在Kudu中一行数据只会存在于一个DiskRowSet中，避免读操作时的比较合并工作。那Kudu是怎么做到的呢？ 对于列式存储的数据文件，要原地变更一行数据是很困难的，所以在Kudu中，对于Flush到磁盘上的DiskRowSet（DRS）数据，实际上是分两种形式存在的，一种是Base的数据，按列式存储格式存在，一旦生成，就不再修改，另一种是Delta文件，存储Base数据中有变更的数据，一个Base文件可以对应多个Delta文件，这种方式意味着，插入数据时相比HBase，需要额外走一次检索流程来判定对应主键的数据是否已经存在。因此，Kudu是牺牲了写性能来换取读取性能的提升。 </li><li>更新、删除操作需要记录到特殊的数据结构里，保存在内存中的DeltaMemStore或磁盘上的DeltaFIle里面。DeltaMemStore是B-Tree实现的，因此速度快，而且可修改。磁盘上的DeltaFIle是二进制的列式的块，和base数据一样都是不可修改的。因此当数据频繁删改的时候，磁盘上会有大量的DeltaFiles文件，Kudu借鉴了Hbase的方式，会定期对这些文件进行合并。 </li><li>既然存在Delta数据，也就意味着数据查询时需要同时检索Base文件和Delta文件，这看起来和HBase的方案似乎又走到一起去了，不同的地方在于，Kudu的Delta文件与Base文件不同，不是按Key排序的，而是按被更新的行在Base文件中的位移来检索的，号称这样做，在定位Delta内容的时候，不需要进行字符串比较工作，因此能大大加快定位速度，但是无论如何，Delta文件的存在对检索速度的影响巨大。因此Delta文件的数量会需要控制，需要及时的和Base数据进行合并。由于Base文件是列式存储的，所以Delta文件合并时，可以有选择性的进行，比如只把变化频繁的列进行合并，变化很少的列保留在Delta文件中暂不合并，这样做也能减少不必要的IO开销。 </li><li>除了Delta文件合并，DRS自身也会需要合并，为了保障检索延迟的可预测性（这一点是HBase的痛点之一，比如分区发生Major Compaction时，读写性能会受到很大影响），Kudu的compaction策略和HBase相比，有很大不同，kudu的DRS数据文件的compaction，本质上不是为了减少文件数量，实际上Kudu DRS默认是以32MB为单位进行拆分的，DRS的compaction并不减少文件数量，而是对内容进行排序重组，减少不同DRS之间key的overlap（重复），进而在检索的时候减少需要参与检索的DRS的数量。 </li></ul><h3 id="6-设计原理"><a href="#6-设计原理" class="headerlink" title="6.设计原理"></a>6.设计原理</h3><h4 id="设计初衷"><a href="#设计初衷" class="headerlink" title="设计初衷"></a>设计初衷</h4><hr><p>有一个问题我一直在考虑就是Kudu出现的意义，官方文档中强调的优点很多都是列存储的优点。</p><p>那和Parquet相比，又有什么优点呢，和同事讨论，也只得到了细颗粒修改删除的区别。</p><p>看到设计初衷之后明白了</p><ul><li>静态数据通常以Parquet/Carbon/Avro形式直接存放在HDFS中，对于分析场景，这种存储通常是更加适合的。但无论以哪种方式存在于HDFS中，都难以支持单条记录级别的更新，随机读取也并不高效。</li><li>可变数据的存储通常选择HBase或者Cassandra，因为它们能够支持记录级别的高效随机读写。但这种存储却并不适合离线分析场景，因为它们在大批量数据获取时的性能较差（针对HBase而言，有两方面的主要原因：一是HFile本身的结构定义，它是按行组织数据的，这种格式针对大多数的分析场景，都会带来较大的IO消耗，因为可能会读取很多不必要的数据，相对而言Parquet格式针对分析场景就做了很多优化。 二是由于HBase本身的LSM-Tree架构决定的，HBase的读取路径中，不仅要考虑内存中的数据，同时要考虑HDFS中的一个或多个HFile，较之于直接从HDFS中读取文件而言，这种读取路径是过长的）。</li></ul><p>于是乎，上面的两种存储，都存在明显的优缺点：</p><ul><li>直接存放于HDFS中，适合离线分析，缺不利于记录级别的随机读写。</li><li>直接将数据放于HBase/Cassandra中，适合记录级别的随机读写，对离线分析却不友好。</li></ul><p>但在很多实际业务场景中，两种场景时常是并存的，基于Spark/Hive On HBase进行，性能较差</p><ul><li>数据存放于HBase中，对于分析任务，基于Spark/Hive On HBase进行，性能较差。</li><li>对于分析性能要求较高的，可以将数据在HDFS/Hive中多冗余存放一份，或者，将HBase中的数据定期的导出成Parquet/Carbon格式的数据。 明显这种方案对业务应用提出了较高的要求，而且容易导致在线数据与离线数据之间的一致性问题。</li></ul><p>Kudu的设计，就是试图在OLAP和OLTP之间，寻求一个最佳的结合点，从而在一个系统的一份数据中，技能支持OLAP，又能支持OLTP，另外一个初衷是，在Cloudera发布的《Kudu: New Apache Hadoop Storage for Fast Analytics on Fast Data》一文中有提及，Kudu作为一个新的分布式存储系统期望有效提升CPU的使用率，而低CPU使用率恰是HBase/Cassandra等系统的最大问题。</p><p><em>OLTP系统强调数据库内存效率，强调内存各种指标的命令率，强调绑定变量，强调并发操作</em></p><p><em>OLAP系统则强调数据分析，强调SQL执行市场，强调磁盘I/O，强调分区等</em></p><p><em>从功能角度来看，OLTP负责基本业务的正常运转，而业务数据积累时所产生的价值信息则被OLAP不断呈现，企业高层通过参考这些信息会不断调整经营方针，也会促进基础业务的不断优化，这是OLTP与OLAP最根本的区别</em></p><h4 id="事务与一致性"><a href="#事务与一致性" class="headerlink" title="事务与一致性"></a>事务与一致性</h4><p>Kudu仅仅提供单行事务，也不支持多行事务。这一点与HBase是相似的。但在数据一致性模型上，与HBase有较大的区别。 Kudu提供了如下两种一致性模型：</p><ul><li>Snapshot Consistency</li></ul><p>这是Kudu中的默认一致性模型。在这种模型中，只保证一个客户端能够看到自己所提交的写操作，而并不保障全局的（跨多个客户端的）事务可见性。</p><ul><li>External Consistency</li></ul><p>最早提出External Consistency机制的，应该是在Google的Spanner论文中。传统关系型数据库中的两阶段提交机制，需要两回合通信，这过程中带来的代价是较高的，但同时这过程中的复杂的锁机制也可能会带来一些可用性问题。一个更好的实现分布式事务/一致性的思路，是基于一个全局发布的Timestamp机制。Spanner提出了Commit-wait的机制，来保障全局事务的有序性：如果一个事务T1的提交先于另外一个事务T2的开始，则T1的Timestamp要小于T2的TimeStamp。我们知道，在分布式系统中，是很难于做这样的承诺的。在HBase中，我们可以想象，如果所有RegionServer中的SequenceID发布自同一个数据源，那么，HBase的很多事务性问题就迎刃而解了，然后最大的问题在于这个全局的SequenceID数据源将会是整个系统的性能瓶颈点。回到External Consistency机制，Spanner是依赖于高精度与可预见误差的本地时钟(TrueTime API)实现的(即需要一个高可靠和高精度的时钟源，同时，这个时钟的误差是可预见的。感兴趣的同学可以阅读Spanner论文，这里不赘述)。Kudu中提供了另外一种思路来实现External Consistency,基于Timestamp扩散机制，即，多个客户端可相互通信来告知彼此所提交的Timestamp值，从而保障一个全局的顺序。这种机制也是相对较为复杂的。<br>与Spanner类似，Kudu不允许用户自定义用户数据的Timestamp，但在HBase中却是不同，用户可以发起一次基于某特定Timestamp的查询。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Apache Kudu&lt;/p&gt;
&lt;p&gt;一图以蔽之：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/bec9bff2ly1g2jmwis7z6j20cj0brgln.jpg&quot; alt=&quot;alt kudu&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>大数据在小米的实践</title>
    <link href="http://yoursite.com/2019/04/22/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9C%A8%E5%B0%8F%E7%B1%B3%E7%9A%84%E5%AE%9E%E8%B7%B5/"/>
    <id>http://yoursite.com/2019/04/22/大数据在小米的实践/</id>
    <published>2019-04-22T13:45:12.000Z</published>
    <updated>2019-04-29T12:53:31.924Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文资料主要来自小米的工程师欧阳辰和张震分别在2016年在DAMS和2017年在DTCC上的演讲，内容主要是大数据技术在小米的实践梗概和自己的一些想法。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本文资料主要来自小米的工程师欧阳辰和张震分别在2016年在DAMS和2017年在DTCC上的演讲，内容主要是大数据技术在小米的实践梗概和自己的一些想法。&lt;/p&gt;
&lt;/blockquote&gt;

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Kerberos For CDH</title>
    <link href="http://yoursite.com/2019/04/22/Kerberos%20For%20CDH/"/>
    <id>http://yoursite.com/2019/04/22/Kerberos For CDH/</id>
    <published>2019-04-22T13:45:12.000Z</published>
    <updated>2019-04-29T08:49:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>从18年底开始，公司的服务器经常受到各种挖矿脚本病毒的公司，Java后端Redis漏洞层出不穷，Hadoop这边MR的提交权限BUG也被利用了，于是决定调研Kerberos，发现Kerberos是一个巨大的坑，在此记录下笔记，作为我的Github Pages第一篇文档，希望后来人少走弯路。此文可能分为几次更新。</p><p>第一次更新：2019-4-29</p><a id="more"></a> <h3 id="1-Kerberos-入门"><a href="#1-Kerberos-入门" class="headerlink" title="1.Kerberos 入门"></a>1.Kerberos 入门</h3><p>Kerberos是一种计算机网络授权协议，用来在非安全网络中，对个人通信以安全的手段进行身份认证。Hadoop集群中涉及的Kerberos一般是指MIT基于Kerberos协议开发的一套软件。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g2fvwiwb03g20rs0fvaa2.gif" alt="ALT Kerberos"></p><p>Kerberos在希腊神话中是Hades的一条凶猛的三头保卫神犬。这三个头在Kerberos代表了Client、Server和KDC。</p><p><em>Kerberos的特点</em>：并不要求通信双方所在的网络环境安全，即使通信过程中数据被截取或者篡改，依然不会影响整套机制的正常工作。时间戳是Kerberos用来保证通信安全的重要手段。</p><p><em>Kerberos的基本思路</em>：基于对称加密，利用集中的认证服务器，实现用户和服务器之间的双向认证。(提供一种不能伪造、不能重放、已经鉴别的票据对象)。</p><hr><h3 id="2-Kerberos涉及名词"><a href="#2-Kerberos涉及名词" class="headerlink" title="2.Kerberos涉及名词"></a>2.Kerberos涉及名词</h3><p><strong>Principal</strong>：认证的主体，简单来说也就是 用户名</p><p><strong>Kinit</strong>：Kerberos认证(登录)命令，可以使用密码或者KEYTAB</p><p><strong>realm</strong>：有点类似namespace，一个principle只有在某个realm下才有意义</p><p><strong>Password</strong>：某个用户的密码，对应于Kerberos中的master key。password可以存在一个KEYTAB文件中。所以Kerberos中需要使用密码的场景都可以用一个KEYTAB作为输入</p><p><strong>credential</strong>：credential是“证明某个人确定是他自己/某一种行为的确可以发生”的凭据。在不同的使用场景下， credential的具体含义也略有不同：</p><ul><li><p>对于某个principal个体而言，他的credential就是他的password</p></li><li><p>在Kerberos认证的环节中，credential就意味着各种各样的ticket</p></li></ul><p><strong>TGT</strong>：Ticket Granting Ticket，要获得key还需要一个资格认证，获得这个资格认证的证明，叫做TGT</p><p><strong>Long-term Key/Master Key</strong>：在Security的领域中，有的Key可能长期内保持不变，比如你在密码，可能几年都不曾改变，这样的Key、以及由此派生的Key被称为Long-term Key。对于Long-term Key的使用有这样的原则：被Long-term Key加密的数据不应该在网络上传输。原因很简单，一旦这些被Long-term Key加密的数据包被恶意的网络监听者截获，在原则上，只要有充足的时间，他是可以通过计算获得你用于加密的Long-term Key的——任何加密算法都不可能做到绝对保密。</p><p><strong>Short-term Key/Session Key</strong>：由于被Long-term Key加密的数据包不能用于网络传送，所以我们使用另一种Short-term<br>Key来加密需要进行网络传输的数据。由于这种Key只在一段时间内有效，即使被加密的数据包被黑客截获，等他把Key计算出来的时候，这个Key早就已经过期了。</p><hr><h3 id="3-Kerberos原理"><a href="#3-Kerberos原理" class="headerlink" title="3.Kerberos原理"></a>3.Kerberos原理</h3><p>最简单的对称加密的思路：A发送信息给B，信息分为两段，一段是明文，一段是加密之后的密文，这个密钥只有A和B两个人知道，B收到信息后，用两个人都知道的密钥破解了这段密文，如果破解之后的内容和明文内容一致就说明 A的身份没有问题。</p><p><strong>Kerberos就是基于此基础之上的一套复杂的认证机制。</strong></p><p>下面对整个认证过程进行一个细致的分析，对于安装部署过程中纠错来说（尤其CDH集群集成的<code>Kerberos</code>有一些问题），这个过程是非常有必要的：</p><p>通过第二节介绍的两种Key，让被认证的一方提供一个仅限于他和认证方知晓的Key来鉴定对方的真实身份。而被这个<code>Key</code>加密的数据包需要在<code>Client</code>和<code>Server</code>之间传送，所以这个<code>Key</code>不能是一个<code>Long-term Key</code>，而只可能是<code>hort-term Key</code>，这个可以仅仅在<code>Client</code>和<code>Server</code>的一个<code>Session</code>中有效，所以我们称这个<code>Key</code>为<code>Client</code>和<code>Server</code>之间的<code>Session Key（Sserver-Client）</code>。</p><p>这个<code>Sserver-Client</code> 需要引入<code>Kerberos</code>中的一个十分重要的觉得：<code>Kerberos Distribution Center-KDC</code>。<code>KDC</code>在整个<code>Kerberos</code>认证流程中作为<code>Client</code>和<code>Server</code>共同信任的第三方起着重要的作用，而<code>Kerberos</code>的认证过程就是通过这三方协作完成。<code>KDC</code>中维护着一个存储着该<code>Domain</code>中所有账户的<code>Account Database</code>（一个轻量级的数据库），这个数据库汇中存储着每个<code>Account</code>的名称和派生于该<code>Account Password</code>的<code>Master Key</code>，派生手段一般来说是类似Hash这种，不可逆的，然后可以一一对应的方法。</p><p>稍微扩展一下上面的<code>key</code>的分发过程：</p><p>首先是<code>Client</code>向<code>KDC</code>发送一个对<code>SServer-Client</code>的申请。这个申请的内容可以简单概括为“我是某个<code>Client</code>，我需要一个<code>Session Key</code>用于访问某个<code>Server</code> ”。<code>KDC</code>在接受了这个请求以后，生成一个<code>Session</code>Key，为了保证这个<code>Session Key</code>仅仅限于发送请求的<code>Client</code>和他希望访问的<code>Server</code>知晓，<code>KDC</code>会为这个<code>Session Key</code>生成两个<code>Copy</code>，分别被<code>Client</code>和<code>Server</code>使用。然后从<code>Account database</code>中提取<code>Client</code>和<code>Server</code>的<code>Master Key</code>分别对这两个<code>Copy</code>进行对称加密。对于后者，和<code>Session Key</code>一起被加密的还包含关于<code>Client</code>的一些信息。（这里的<code>Client</code>可以理解为发送连接请求的节点，<code>Server</code>可以理解为<code>Client</code>发送请求的接受节点）。</p><p>现在KDC有了两个分别被<code>Master</code>和<code>Server</code>的<code>Master key</code>加密过的<code>Session Key</code>，下面介绍这两个<code>Session Key</code>的处理方式。</p><p>Kerberos 并不会直接把两个加密包分别发送给<code>Client</code>和<code>Server</code>，原因主要有两个：</p><p>第一：由于一个<code>Server</code>会面对若干不同的<code>Client</code>, 而每个<code>Client</code>都具有一个不同的<code>Session Key</code>。那么<code>Server</code>就会为所有的<code>Client</code>维护这样一个<code>Session Key</code>的列表，这样对于<code>Server</code>来说是比较麻烦而低效的。</p><p>第二：由于网络传输的不确定性，可能出现这样一种情况：<code>Client</code>很快获得<code>Session Key</code>，并将这个<code>Session Key</code>作为<code>Credential</code>随同访问请求发送到<code>Server</code>，但是用于<code>Server</code>的<code>Session Key</code>确还没有收到，并且很有可能承载这个<code>Session Key</code>的永远也到不了<code>Server</code>端，<code>Client</code>将永远得不到认证。</p><p>为了解决这个问题，<code>Kerberos</code>的做法是：<strong>将这两个被加密的<code>Copy</code>一并发送给<code>Client</code>，属于<code>Server</code>的那份由<code>Client</code>发送给<code>Server</code>。</strong></p><p><code>Client</code>实际上获得了两组信息：一个通过自己<code>Master Key</code>加密的<code>Session Key</code>，另一个被<code>Server</code>的<code>Master Key</code>加密的数据包，包含<code>Session Key</code>和关于自己的一些确认信息。通过一个双方知晓的<code>Key</code>就可以对对方进行有效的认证，但是在一个网络的环境中，这种简单的做法是具有安全漏洞，为此,<code>Client</code>需要提供更多的证明信息，我们把这种证明信息称为<code>Authenticator</code>，在<code>Kerberos</code>的<code>Authenticator</code>实际上就是关于<code>Client</code>的一些信息和当前时间的一个<code>Timestamp</code>。</p><p><code>Client</code>通过自己的<code>Master Key</code>对<code>KDC</code>加密的<code>Session Key</code>进行解密从而获得<code>Session Key</code>，随后创建<strong><code>Authenticator（Client Info + Timestamp）</code></strong>并用<code>Session Key</code>对其加密。最后连同从<code>KDC</code>获得的、被<code>Server</code>的<code>Master Key</code>加密过的数据包<strong><code>（Client Info + Session Key）</code></strong>一并发送到<code>Server</code>端。我们把通过<code>Server</code>的<code>Master Key</code>加密过的数据包称为<code>Session Ticket</code>。当<code>Server</code>接收到这两组数据后，先使用他自己的<code>Master Key</code>对<code>Session Ticket</code>进行解密，从而获得<code>Session Key</code>。随后使用该<code>Session Key</code>解密<code>Authenticator</code>，通过比较<code>Authenticator</code>中的<code>Client Info</code>和<code>Session Ticket</code>中的<code>Client Info</code>从而实现对Client的认证。</p><p>这里涉及到了一个<code>Timestamp</code>，<code>Client</code>向<code>Server</code>发送的数据包如果被某个恶意网络监听者截获，该监听者随后将数据包作为自己的<code>Credential</code>冒充该<code>Client</code>对<code>Server</code>进行访问，在这种情况下，依然可以很顺利地获得<code>Server</code>的成功认证。为了解决这个问题，<code>Client</code>在<code>Authenticator</code>中会加入一个当前时间的<code>Timestamp</code>。</p><p>在<code>Server</code>对<code>Authenticator</code>中的<code>Client Info</code>和<code>Session Ticket</code>中的<code>Client Info</code>进行比较之前，会先提取<code>Authenticator</code>中的<code>Timestamp</code>，并同当前的时间进行比较，如果他们之间的偏差超出一个可以<strong>接受的时间范围（一般是5mins）</strong>，<code>Server</code>会直接拒绝该<code>Client</code>的请求。在这里需要知道的是，<code>Server</code>维护着一个列表，这个列表记录着在这个可接受的时间范围内所有进行认证的Client和认证的时间。对于时间偏差在这个可接受的范围中的<code>Client</code>，<code>Server</code>会从这个列表中获得<strong>最近一个该<code>Client</code>的认证时间</strong>，只有当<code>Server</code>接收到<code>Authenticator</code>时，验证<code>Authenticator</code>中的<code>Timestamp</code>，确定传输时间小于接受范围后，<code>Server</code>才采用进行后续的认证流程。</p><hr><p><strong><code>Time Synchronization</code>的重要性</strong></p><p>上述基于<code>Timestamp</code>的认证机制只有在<code>Client</code>和<code>Server</code>端的时间保持同步的情况才有意义。所以保持<code>Time</code> <code>Synchronization</code>在整个认证过程中显得尤为重要。在一个<code>Domain</code>中，一般通过访问同一个<code>Time Service</code>获得当前时间的方式来实现时间的同步。</p><p><strong>双向认证（Mutual Authentication）</strong></p><p><code>Kerberos</code>一个重要的优势在于它能够提供双向认证：不但<code>Server</code>可以对<code>Client</code> 进行认证，<code>Client</code>也能对<code>Server</code>进行认证。</p><p>具体过程是这样的，如果<code>Client</code>需要对他访问的<code>Server</code>进行认证，会在它向<code>Server</code>发送的<code>Credential</code>中设置一个是否需要认证的<code>Flag</code>。<code>Server</code>在对<code>Client</code>认证成功之后，会把<code>Authenticator</code>中的<code>Timestamp</code>提出来，通过<code>Session Key</code>进行加密，当<code>Client</code>接收到并使用<code>Session Key</code>进行解密之后，如果确认<code>Timestamp</code>和原来的完全一致，那么他可以认定<code>Server</code>正试图访问的<code>Server</code>。</p><p>那么为什么<code>Server</code>不直接把通过Session Key进行加密的<code>Authenticator</code>原样发送给<code>Client</code>，而要把<code>Timestamp</code>提取出来加密发送给<code>Client</code>呢？原因在于防止恶意的监听者通过获取的<code>Client</code>发送的<code>Authenticator</code>冒充<code>Server</code>获得<code>Client</code>的认证。</p><p><strong>More</strong>：</p><p>通过上面的介绍，我们发现<code>Kerberos</code>实际上一个基于<code>Ticket</code>的认证方式。<code>Client</code>想要获取<code>Server</code>端的资源，先得通过<code>Server</code>的认证；而认证的先决条件是<code>Client</code>向<code>Server</code>提供从<code>KDC</code>获得的一个有<code>Server</code>的<code>Master Key</code>进行加密的<code>Session Ticket</code>（<code>Session Key + Client Info</code>）。可以这么说，<code>Session Ticket</code>是<code>Client</code>进入<code>Server</code>领域的一张门票。而这张门票必须从一个合法的<code>Ticket</code>颁发机构获得，这个颁发机构就是<code>Client</code>和<code>Server</code>双方信任的<code>KDC</code>， 同时这张<code>Ticket</code>具有超强的防伪标识：<strong>它是被<code>Server</code>的<code>Master Key</code>加密的。对<code>Client</code>来说， 获得<code>Session</code> <code>Ticket</code>是整个认证过程中最为关键的部分。</strong></p><hr><p>我了解到这儿感觉已经差不多了，然而这还只是Kerbeos的梗概  T_T</p><p><code>Client</code>要获得<code>Ticket</code>之前，还需要一个步骤，即获得<code>KDC</code>的权限确认，这个过程叫做<code>TGT：Ticket</code><br><code>Granting Ticket</code>。<code>TGT</code>的分发方仍然是<code>KDC</code>。首先<code>Client</code>向<code>KDC</code>发起对<code>TGT</code>的申请，申请的内容大致可以这样表示：“我需要一张<code>TGT</code>用以申请获取用以访问所有<code>Server</code>的<code>Ticket</code>”。<code>KDC</code>在收到该申请请求后，生成一个用于该<code>Client</code>和<code>KDC</code>进行安全通信的<code>Session Key（SKDC-Client）</code>。为了保证该<code>Session Key</code>仅供该<code>Client</code>和自己使用，<code>KDC</code>使用<code>Client</code>的<code>Master Key</code>和自己的<code>Master Key</code>对生成的<code>Session Key</code>进行加密，从而获得两个加密的<code>SKDC-Client</code>的<code>Copy</code>。对于后者，随<code>SKDC-Client</code>一起被加密的还包含以后用于鉴定<code>Client</code>身份的关于<code>Client</code>的一些信息。最后<code>KDC</code>将这两份<code>Copy</code>一起发送给<code>Client</code>。这里有一点需要注意的是：为了免去<code>KDC</code>对于基于不同<code>Client</code>的<code>Session Key</code>进行维护的麻烦，就像<code>Server</code>不会保存<code>Session Key（SServer-Client）</code>一样，<code>KDC</code>也不会去保存这个<code>Session Key（SKDC-Client）</code>，而选择完全靠<code>Client</code>自己提供的方式。</p><p>当<code>Client</code>收到<code>KDC</code>的两个加密数据包之后，先使用自己的<code>Master Key</code>对第一个<code>Copy</code>进行解密，从而获得<code>KDC</code>和<code>Client</code>的<code>Session</code><br><code>Key（SKDC-Client）</code>，并把该<code>Session</code> 和<code>TGT</code>进行缓存。有了<code>Session Key</code>和<code>TGT</code>，<code>Client</code>自己的<code>Master</code><br><code>Key</code>将不再需要，因为此后<code>Client</code>可以使用<code>SKDC-Client</code>向<code>KDC</code>申请用以访问每个<code>Server</code>的<code>Ticket</code>。同时需要注意的是<code>SKDC-Client</code>是一个<code>Session Key</code>，他具有自己的生命周期，同时<code>TGT</code>和<code>Session</code>相互关联，当<code>Session Key</code>过期，<code>TGT</code>也就宣告失效，此后<code>Client</code>不得不重新向<code>KDC</code>申请新的<code>TGT</code>，<code>KDC</code>将会生成一个不同<code>Session Key</code>和与之关联的<code>TGT</code>。同时，由于<code>Client Log off</code>也导致<code>SKDC-Client</code>的失效，所以<code>SKDC-Client</code>又被称为<code>Logon Session Key</code>。<strong><code>TGT</code>和<code>Ticket</code>有个区别就是<code>Ticket</code>是基于某个具体的<code>Server</code>的，而<code>TGT</code>则是和具体的<code>Server</code>无关的。</strong></p><p><code>Client</code>在获得自己和<code>KDC</code>的<code>Session Key（SKDC-Client）</code>之后，生成自己的<code>Authenticator</code>以及所要访问的<code>Server</code>名称的并使用<code>SKDC-Client</code>进行加密。随后连同<code>TGT</code>一起发送给<code>KDC</code>。<code>KDC</code>使用自己的<code>Master Key</code>对<code>TGT</code>进行解密，提取<code>Client Info</code>和<code>Session Key（SKDC-Client）</code>，然后使用这个<code>SKDC-Client</code>解密<code>Authenticator</code>获得<code>Client Info</code>，对两个<code>Client Info</code>进行比较进而验证对方的真实身份。验证成功，生成一份基于<code>Client</code>所要访问的<code>Server</code>的<code>Ticket</code>给<code>Client</code>，然后继续上面之说的过程。</p><p>介绍了这么多，重新把整个过程理一遍：</p><p>现在介绍的整个Authentication过程大概分为三个子过程</p><ul><li><p>Client向KDC申请TGT（Ticket Granting Ticket）。</p></li><li><p>Client通过获得TGT向DKC申请用于访问Server的Ticket。</p></li><li><p>Client最终向为了Server对自己的认证向其提交Ticket。</p></li></ul><p>整个Kerberos Authentication认证过程通过3个sub-protocol来完成：</p><ol><li>Authentication Service Exchange</li><li>Ticket Granting Service Exchange</li><li>Client/Server Exchange</li></ol><p>下面内容来自官方文档的翻译：</p><p>1.Authentication Service Exchange</p><p><code>Client</code>向<code>KDC</code>的<code>Authentication Service</code>发送<code>Authentication Service Request</code>（<code>KRB_AS_REQ</code>）, 为了确保<code>KRB_AS_REQ</code>仅限于自己和<code>KDC</code>知道，<code>Client</code>使用自己的<code>Master Key</code>对<code>KRB_AS_REQ</code>的主体部分进行加密（<code>KDC</code>可以通过<code>Domain</code> 的<code>Account Database</code>获得该<code>Client</code>的<code>Master Key</code>）。<code>KRB_AS_REQ</code>的大体包含以下的内容：</p><ul><li><code>Pre-authentication data</code>：包含用以证明自己身份的信息。说白了，就是证明自己知道自己声称的那个<code>account</code>的<code>Password</code>。一般地，它的内容是一个被<code>Client</code>的<code>Master key</code>加密过的<code>Timestamp</code>。</li><li><code>Client name</code> &amp; <code>realm</code>: 简单地说就是<code>Domain name\Client</code></li><li><code>Server Name</code>：注意这里的<code>Server Name</code>并不是<code>Client</code>真正要访问的<code>Server</code>的名称，而我们也说了<code>TGT</code>是和<code>Server</code>无关的（<code>Client</code>只能使用<code>Ticket</code>，而不是<code>TGT</code>去访问<code>Server</code>）。这里的<code>Server Name</code>实际上是<code>KDC</code>的<code>Ticket Granting Service</code>的<code>Server Name</code>。</li></ul><p><code>AS（Authentication Service）</code>通过它接收到的<code>KRB_AS_REQ</code>验证发送方的是否是在<code>Client name</code> &amp; <code>realm</code>中声称的那个人，也就是说要验证发送方是否知道<code>Client</code>的<code>Password</code>。所以<code>AS</code>只需从<code>Account Database</code>中提取<code>Client</code>对应的<code>Master Key</code>对<code>Pre-authentication data</code>进行解密，如果是一个合法的<code>Timestamp</code>，则可以证明发送方提供的是正确无误的密码。验证通过之后，<code>AS</code>将一份<code>Authentication Service</code> <code>Response（KRB_AS_REP）</code>发送给<code>Client</code>。<code>KRB_AS_REQ</code>主要包含两个部分：本<code>Client</code>的<code>Master Key</code>加密过的<code>Session Key（SKDC-Client：Logon Session Key）</code>和被自己（<code>KDC</code>）加密的<code>TGT</code>。而<code>TGT</code>大体又包含以下的内容：</p><ul><li><p><code>Client name &amp; realm</code>: 简单地说就是<code>Domain name\Client</code></p></li><li><p><code>Client name &amp; realm</code>: 简单地说就是<code>Domain name\Client</code></p></li><li><p><code>End time</code>: <code>TGT</code>到期的时间</p></li></ul><p>Client通过自己的Master Key对第一部分解密获得Session Key（SKDC-Client：Logon Session Key）之后，携带着TGT便可以进入下一步：TGS（Ticket Granting Service）Exchange。</p><p>2.Ticket Granting Service Exchange</p><p><code>TGS</code>（<code>Ticket Granting Service</code>）<code>Exchange</code>通过<code>Client</code>向<code>KDC</code>中的<code>TGS</code>（<code>Ticket Granting Service</code>）发送<code>Ticket Granting Service Request</code>（<code>KRB_TGS_REQ</code>）开始。<code>KRB_TGS_REQ</code>大体包含以下的内容：</p><ul><li><p>TGT：Client通过AS Exchange获得的Ticket Granting Ticket，TGT被KDC的Master Key进行加密。</p></li><li><p>Authenticator：用以证明当初TGT的拥有者是否就是自己，所以它必须以TGT的办法方和自己的Session Key（SKDC-Client：Logon Session Key）来进行加密。</p></li><li><p>Client name &amp; realm: 简单地说就是Domain name\Client。</p></li><li><p>Server name &amp; realm: 简单地说就是Domain name\Server，这回是Client试图访问的那个Server。</p></li></ul><p><code>TGS</code>收到<code>KRB_TGS_REQ</code>在发给<code>Client</code>真正的<code>Ticket</code>之前，先得整个<code>Client</code>提供的那个<code>TGT</code>是否是<code>AS</code>颁发给它的。于是它不得不通过<code>Client</code>提供的<code>Authenticator</code>来证明。但是<code>Authentication</code>是通过<code>Logon Session Key（SKDC-Client）</code>进行加密的，而自己并没有保存这个<code>Session Key</code>。所以TGS先得通过自己的<code>Master Key</code>对<code>Client</code>提供的<code>TGT</code>进行解密，从而获得这个<code>Logon Session Key（SKDC-Client）</code>，再通过这个<code>Logon Session Key（SKDC-Client）</code>解密<code>Authenticator</code>进行验证。验证通过向对方发送<code>Ticket Granting</code><br><code>Service Response（KRB_TGS_REP）</code>。这个<code>KRB_TGS_REP</code>有两部分组成：使用<code>Logon Session Key（SKDC-Client）</code>加密过用于<code>Client</code>和<code>Server</code>的<code>Session Key（SServer-Client）</code>和使用<code>Server</code>的<code>Master Key</code>进行加密的<code>Ticket</code>。该<code>Ticket</code>大体包含以下一些内容：</p><ul><li><p>Client name &amp; realm: 简单地说就是Domain name\Client</p></li><li><p>Client name &amp; realm: 简单地说就是Domain name\Client</p></li><li><p>End time: Ticket的到期时间</p></li></ul><p><code>Client</code>收到<code>KRB_TGS_REP</code>，使用<code>Logon Session Key（SKDC-Client）</code>解密第一部分后获得<code>Session Key（SServer-Client）</code>。有了<code>Session Key</code>和<code>Ticket，Client</code>就可以之间和<code>Server</code>进行交互，而无须在通过<code>KDC</code>作中间人了。所以我们说<code>Kerberos</code>是一种高效的认证方式，它可以直接通过<code>Client</code>和<code>Server</code>双方来完成，不像Windows NT 4下的<code>NTLM</code>认证方式，每次认证都要通过一个双方信任的第3方来完成。</p><p>我们现在来看看 <code>Client</code>如果使用<code>Ticket</code>和<code>Server</code>怎样进行交互的，这个阶段通过我们的第3个<code>Sub-protocol</code>来完成：<code>CS（Client/Server ）Exchange</code>。</p><ol start="3"><li>CS（Client/Server ）Exchange</li></ol><p>这个已经经介绍过。<code>Client</code>通过<code>TGS Exchange</code>获得<code>Client</code>和<code>Server</code>的<code>Session Key（SServer-Client）</code>，随后创建用于证明自己就是Ticket的真正所有者的<code>Authenticator</code>，并使用<code>Session Key（SServer-Client）</code>进行加密。最后将这个被加密过的<code>Authenticator</code>和<code>Ticket</code>作为<code>Application Service Request（KRB_AP_REQ）</code>发送给<code>Server</code>。除了上述两项内容之外，<code>KRB_AP_REQ</code>还包含一个<code>Flag</code>用于表示<code>Client</code>是否需要进行双向验证（<code>Mutual Authentication</code>）。</p><p><code>Server</code>接收到<code>KRB_AP_REQ</code>之后，通过自己的<code>Master Key</code>解密<code>Ticket</code>，从而获得<code>Session Key（SServer-Client）</code>。通过<code>Session Key（SServer-Client）</code>解密<code>Authenticator</code>，进而验证对方的身份。验证成功，让<code>Client</code>访问需要访问的资源，否则直接拒绝对方的请求。</p><p>对于需要进行双向验证，<code>Server</code>从<code>Authenticator</code>提取<code>Timestamp</code>，使用<code>Session Key（SServer-Client）</code>进行加密，并将其发送给<code>Client</code>用于<code>Client</code>验证<code>Server</code>的身份。</p><hr><p>以上是2000年的<code>Kerberos</code>技术，和今天我们使用的<code>Kerberos</code>是不太相同的，因为这样的一个认证过程有一个最大的隐患就是<strong>Long-term Key加密的数据在网络中传递</strong>。</p><p>解决办法也很简单：就是采用一个<code>Short-term</code>的<code>Session Key</code>，而不是<code>Server Master Key</code>对<code>Ticket</code>进行加密。这就是<code>Kerberos</code>的第四个<code>Sub-protocol</code>：<code>User2User Protocol</code>。</p><p>因为<code>KDC</code>是不是维护<code>Session Key</code>的，所以这个<code>Session key</code>只能靠申请<code>Ticket</code>的<code>Client</code>提供，所以在原先的第一步和第二步之间，<code>Client</code>还得对<code>Server</code>进行请求已获得<code>Server</code>和<code>KDC</code>之间的<code>Session Key</code>。而对于<code>Server</code>来说，他可以像<code>Client</code>一样通过<code>AS Exchange</code>获得他和<code>KDC</code>之间的<code>Session Key</code>（<code>SKDC-Server</code>）和一个封装了这个<code>Session Key</code>并被<code>KDC</code>的<code>Master Key</code>进行加密的<code>TGT</code>，一旦获得这个<code>TGT</code>，<code>Server</code>会缓存它，以待<code>Client</code>对它的请求。</p><p>所以现在添加完这个User2User的认证过程，这个过程有4个步骤组成，四个步骤如下：</p><ul><li><p>AS Exchange：Client通过此过程获得了属于自己的TGT，有了此TGT，Client可凭此向KDC申请用于访问某个Server的Ticket。</p></li><li><p>User2User：这一步的主要任务是获得封装了Server和KDC的Session Key（SKDC-Server）的属于Server的TGT。如果该TGT存在于Server的缓存中，则Server会直接将其返回给Client。否则通过AS Exchange从KDC获取。</p></li><li>TGS Exchange：Client通过向KDC提供自己的TGT，Server的TGT以及Authenticator向KDC申请用于访问Server的Ticket。KDC使用先用自己的Master Key解密Client的TGT获得SKDC-Client，通过SKDC-Client解密Authenticator验证发送者是否是TGT的真正拥有者，验证通过再用自己的Master Key解密Server的TGT获得KDC和Server 的Session Key（SKDC-Server），并用该Session Key加密Ticket返回给Client。</li><li>C/S Exchange：Client携带者通过KDC和Server 的Session Key（SKDC-Server）进行加密的Ticket和通过Client和Server的Session Key（SServer-Client）的Authenticator访问Server，Server通过SKDC-Server解密Ticket获得SServer-Client，通过SServer-Client解密Authenticator实现对Client的验证。</li></ul><hr><h3 id="4-Kerberos的安装和Apach原生HDFS的配置"><a href="#4-Kerberos的安装和Apach原生HDFS的配置" class="headerlink" title="4.Kerberos的安装和Apach原生HDFS的配置"></a>4.Kerberos的安装和Apach原生HDFS的配置</h3><p><strong>环境：</strong></p><ul><li>Linux版本：CentOS Linux release 7.2.1511 (Core)</li><li>CDH版本：5.13.3</li><li>JDK版本：jdk1.8.0_144</li><li>运行用户：root</li></ul><p><strong>准备工作：</strong></p><p>确认添加主机名解析到/etc/hosts 文件中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">172.16.0.3  master</span><br><span class="line">172.16.0.4  datanode0</span><br><span class="line">172.16.0.5  datanode1</span><br></pre></td></tr></table></figure><p>hostname 请使用小写，要不然在集成Kerberos 时会出现一些错误。</p><p><strong>安装Kerberos</strong>:</p><p>在<code>master</code>上安装包 <code>krb5</code>、<code>krb5-server</code> 和<code>krb5-client</code>。</p><p><code>yum install krb5-server -y</code></p><p>在所有节点上安装<code>krb5-devel</code>、<code>krb5-workstation</code>：</p><p><code>yum install krb5-devel krb5-workstation -y</code></p><p>修改配置文件</p><p>Kerberos的配置文件需要修改三个</p><p><code>/etc/krb5.conf</code></p><p><code>/var/kerberos/krb5kdc/kdc.conf</code></p><p><code>/var/kerberos/krb5kdc/kadm5.acl</code></p><p>配置Kerberos的krb5.conf</p><p>官网样例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[libdefaults]</span><br><span class="line">    default_realm = ATHENA.MIT.EDU</span><br><span class="line">    dns_lookup_kdc = true</span><br><span class="line">    dns_lookup_realm = false</span><br><span class="line"></span><br><span class="line">[realms]</span><br><span class="line">    ATHENA.MIT.EDU = &#123;</span><br><span class="line">        kdc = kerberos.mit.edu</span><br><span class="line">        kdc = kerberos-1.mit.edu</span><br><span class="line">        kdc = kerberos-2.mit.edu</span><br><span class="line">        admin_server = kerberos.mit.edu</span><br><span class="line">        master_kdc = kerberos.mit.edu</span><br><span class="line">    &#125;</span><br><span class="line">    EXAMPLE.COM = &#123;</span><br><span class="line">        kdc = kerberos.example.com</span><br><span class="line">        kdc = kerberos-1.example.com</span><br><span class="line">        admin_server = kerberos.example.com</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">[domain_realm]</span><br><span class="line">    mit.edu = ATHENA.MIT.EDU</span><br><span class="line"></span><br><span class="line">[capaths]</span><br><span class="line">    ATHENA.MIT.EDU = &#123;</span><br><span class="line">           EXAMPLE.COM = .</span><br><span class="line">    &#125;</span><br><span class="line">    EXAMPLE.COM = &#123;</span><br><span class="line">           ATHENA.MIT.EDU = .</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>说明：样例来自MIT官网，部分配置选项含义如下：</p><p><code>[logging]</code>：表示 server 端的日志的打印位置</p><p><code>[libdefaults]</code>：每种连接的默认配置，需要注意以下几个关键的小配置</p><p><code>default_realm = EXAMPLE.COM</code>：设置 Kerberos 应用程序的默认领域。如果您有多个领域，只需向 [realms] 节添加其他的语句。</p><p><code>ticket_lifetime</code>： 表明凭证生效的时限，一般为24小时。</p><p><code>renew_lifetime</code>： 表明凭证最长可以被延期的时限，一般为一个礼拜。当凭证过期之后，对安全认证的服务的后续访问则会失败。</p><p><code>clockskew</code>：时钟偏差是不完全符合主机系统时钟的票据时戳的容差，超过此容差将不接受此票据。通常，将时钟扭斜设置为 300 秒（5 分钟）。这意味着从服务器的角度看，票证的时间戳与它的偏差可以是在前后 5 分钟内。</p><p><code>udp_preference_limit= 1</code>：禁止使用 udp 可以防止一个 Hadoop 中的错误</p><p><code>[realms]</code>：列举使用的 realm。</p><p><code>kdc</code>：代表要 kdc 的位置。格式是 机器:端口</p><p><code>admin_server</code>：代表 admin 的位置。格式是 机器:端口</p><p><code>default_domain</code>：代表默认的域名</p><p><code>[appdefaults]</code>：可以设定一些针对特定应用的配置，覆盖默认配置。</p><p>经过一段时间的对比实验，最终配置文件设置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[logging]</span><br><span class="line">     default = FILE:/var/log/krb5libs.log</span><br><span class="line">     kdc = FILE:/var/log/krb5kdc.log</span><br><span class="line">     admin_server = FILE:/var/log/kadmind.log</span><br><span class="line"></span><br><span class="line">[libdefaults]</span><br><span class="line">     dns_lookup_realm = false</span><br><span class="line">     dns_lookup_kdc = false</span><br><span class="line">     ticket_lifetime = 24h</span><br><span class="line">     renew_lifetime = 7d</span><br><span class="line">     forwardable = true</span><br><span class="line">     renewable = true</span><br><span class="line">     udp_preference_limit = 1</span><br><span class="line">     rdns = false</span><br><span class="line">     pkinit_anchors = /etc/pki/tls/certs/ca-bundle.crt</span><br><span class="line">     default_realm = JIMI.COM</span><br><span class="line">     default_tgs_enctypes = arcfour-hmac</span><br><span class="line">     default_tkt_enctypes = arcfour-hmac</span><br><span class="line"></span><br><span class="line">[realms]</span><br><span class="line">    JIMI.COM = &#123;</span><br><span class="line">      kdc = master126</span><br><span class="line">      admin_server = master126</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">[domain_realm]</span><br><span class="line">     .jimi.com = JIMI.COM</span><br><span class="line">    jimi.com = JIMI.COM</span><br></pre></td></tr></table></figure><p>接下来是第二个配置文件<code>/var/kerberos/krb5kdc/kdc.conf</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[kdcdefaults]</span><br><span class="line"> kdc_ports = 88</span><br><span class="line"> kdc_tcp_ports = 88</span><br><span class="line"></span><br><span class="line">[realms]</span><br><span class="line"> JIMI.COM = &#123;</span><br><span class="line">  #master_key_type = aes256-cts</span><br><span class="line">  max_renewable_life= 7d 0h 0m 0s</span><br><span class="line">  acl_file = /var/kerberos/krb5kdc/kadm5.acl</span><br><span class="line">  dict_file = /usr/share/dict/words</span><br><span class="line">  admin_keytab = /var/kerberos/krb5kdc/kadm5.keytab</span><br><span class="line">  supported_enctypes = aes256-cts:normal aes128-cts:normal des3-hmac-sha1:normal arcfour-hmac:normal camellia256-cts:normal camellia128-cts:normal des-hmac-sha1:normal des-cbc-md5:normal des-cbc-crc:normal</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>这边直接放上配置文件，官方的配置文件相当冗余，加上版本问题，我删除了很多选项，只留下了小部分，剩下的应该会以默认值运行。</p><p>贴上一点简单的选项说明：</p><p><code>EXAMPLE.COM</code>： 是设定的 <code>realms</code>。名字随意。<code>Kerberos</code> 可以支持多个 <code>realms</code>，会增加复杂度。大小写敏感，一般为了识别使用全部大写。这个 <code>realms</code> 跟机器的 <code>host</code> 没有大关系。</p><p><code>master_key_type</code>：和 <code>supported_enctypes</code> 默认使用 <code>aes256-cts</code>。JAVA 使用 <code>aes256-cts</code> 验证方式需要安装 JCE 包，见下面的说明。为了简便，你可以不使用 <code>aes256-cts</code> 算法，这样就不需要安装 <code>JCE</code> 。</p><p><code>acl_file</code>：标注了 admin 的用户权限，需要用户自己创建。文件格式是：<code>Kerberos_principal permissions</code> [target_principal] [restrictions]</p><p><code>supported_enctypes</code>：支持的校验方式。</p><p>admin_keytab：KDC 进行校验的 keytab。</p><p>这边要注意，如果系统是Centos5.6及以上系统，默认使用AES-256来加密，但是这个AES-256 JDK的安全包里默认不存在，所以要去<a href="https://www.oracle.com/technetwork/cn/java/javase/downloads/jce8-download-2133166-zhs.html" target="_blank" rel="noopener">Oracle</a>下载，但是这个密码增强包貌似对JDK过高的版本支持有BUG，但是暂时好像还没遇到，下载下来之后放到这个目录里：$JAVA_HOME/jre/lib/security</p><p>还有一个文件<code>/var/kerberos/krb5kdc/kadm5.acl</code>：</p><p>这个是权限控制文件，修改为</p><p><a href="mailto:`*/admin@JIMI.COM" target="_blank" rel="noopener">`*/admin@JIMI.COM</a>        *`</p><p>这三个配置文件中只有krb5.conf需要拷贝到集群中其他服务器</p><p>别的两个配置文件不需要分发到别的节点。</p><p><strong>创建数据库</strong>：</p><p>原理里面已经讲过了KDC里面有一个小型的数据库，下面是对这个数据库的操作。</p><p>在master上运行初始化数据库命令，其中 -r 指定对应的realm</p><p><code>kdb5_util create -r JIMI.COM -s</code></p><p>出现 <code>loading random data</code> 的时候另开个终端执行点消耗CPU的命令如<code>cat /dev/sda &gt; /dev/urandom</code> 可以加快随机数采集。该命令会在<code>/var/kerberos/krb5kdc/</code> 目录下创建 <code>principal</code> 数据库。</p><p>如果遇到数据库已经存在的提示，可以把 <code>/var/kerberos/krb5kdc/</code> 目录下的 principal 的相关文件都删除掉。默认的数据库名字都是 <code>principal</code>。可以使用 -d 指定数据库名字。</p><p>这个数据库相当重要，后面还会介绍。</p><p><strong>启动服务</strong>：</p><p>在master节点上运行：</p><p>centos 6：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">chkconfig krb5kdc on </span><br><span class="line">chkconfig kadmin on </span><br><span class="line">service krb5kdc start </span><br><span class="line">service kadmin start</span><br></pre></td></tr></table></figure><p>centos 7：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl start krb5kdc </span><br><span class="line">systemctl start kadmin </span><br><span class="line">systemctl status krb5kdc </span><br><span class="line">systemctl status kadmin</span><br></pre></td></tr></table></figure><hr><p><strong>创建Kerberos管理员</strong></p><p>Kerberos的管理，有两个方式，分别是kadmin.local 或 kadmin，至于使用哪个，取决于账户和权限访问。</p><ul><li><p>如果有访问 kdc 服务器的 root 权限，但是没有 kerberos admin 账户，使用 kadmin.local</p></li><li><p>如果没有访问 kdc 服务器的 root 权限，但是用 kerberos admin 账户，使用 kadmin</p></li></ul><p>在master上创建远程管理的程序员:</p><p>#手动输入两次密码，这里密码为 root</p><p><code>kadmin.local -q &quot;addprinc root/admin&quot;</code></p><p>#也可以不用手动输入密码</p><p><code>echo -e &quot;root\nroot&quot; | kadmin.local -q &quot;addprinc root/admin&quot;</code></p><p>#或者运行下面命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kadmin.local &lt;&lt;eoj</span><br><span class="line">addprinc -pw root root/admin</span><br><span class="line">eoj</span><br></pre></td></tr></table></figure><p>系统时提示输入密码，密码不能为空，而且需要妥善保管。</p><p>测试Kerberos：</p><p>查看当前认证用户</p><p>#查看 principals</p><p><code>kadmin: list_principals</code></p><p>#添加一个新的principal</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kadmin:  addprinc user1</span><br><span class="line">WARNING: no policy specified for user1@JIMI.COM; defaulting to no policy</span><br><span class="line">Enter password for principle</span><br><span class="line">Re-enter password for principal &quot;user1@JIMI.COM&quot;:</span><br><span class="line">Principal &quot;user1@JIMI.COM&quot; created.</span><br></pre></td></tr></table></figure><p>#删除 principal</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kadmin:  delprinc user1</span><br><span class="line">Are you sure you want to delete the principal &quot;user1@JIMI.COM&quot;? (yes/no): yes</span><br><span class="line">Principal &quot;user1@JIMI.COM&quot; deleted.</span><br><span class="line">Make sure that you have removed this principal from all ACLs before reusing.</span><br><span class="line">kadmin:exit</span><br></pre></td></tr></table></figure><p>也可以直接通过下面的命令来执行</p><p>#提示需要输入密码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kadmin -p root/admin -q &quot;list_principals&quot;</span><br><span class="line">kadmin -p root/admin -q &quot;list_principals&quot;</span><br><span class="line">kadmin -p root/admin -q &quot;addprinc user2&quot;</span><br></pre></td></tr></table></figure><p>#不用输入密码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kadmin.local -q &quot;list_principals&quot;</span><br><span class="line">kadmin.local -q &quot;addprinc user2&quot;</span><br><span class="line">kadmin.local -q &quot;delprinc user2&quot;</span><br></pre></td></tr></table></figure><p>#创建一个测试用户test，密码设置为test：</p><p><code>echo -e &quot;test\ntest&quot; | kadmin.local -q &quot;addprinc test&quot;</code></p><p>#获取test用户的ticket 通过用户名和密码登录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">kinit test</span><br><span class="line">Password for test@JIMI.COM</span><br><span class="line">klist -e </span><br><span class="line">Ticket cache: FILE:/tmp/krb5cc_0</span><br><span class="line">Default principal: test@JIMI.COM</span><br><span class="line">Valid starting     Expires            Service principal</span><br><span class="line">11/07/14 15:29:02  11/08/14 15:29:02  krbtgt/JIMI.COM@JIMI.COM</span><br><span class="line">  renew until 11/17/14 15:29:02, Etype (skey, tkt): aes256-cts-hmac-sha1-96, aes256-cts-hmac-sha1-96</span><br><span class="line">Kerberos 4 ticket cache: /tmp/tkt0</span><br><span class="line">klist: You have no tickets cached</span><br></pre></td></tr></table></figure><p>销毁test用户的ticket</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kdestroy</span><br><span class="line">klist</span><br><span class="line">klist: No credentials cache found (ticket cache FILE:/tmp/krb5cc_0)</span><br><span class="line">Kerberos 4 ticket cache: /tmp/tkt0</span><br><span class="line">klist: You have no tickets cached</span><br></pre></td></tr></table></figure><p>更新ticket</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">kinit root/admin</span><br><span class="line">Password for root/admin@JIMI.COM</span><br><span class="line">klist</span><br><span class="line">Ticket cache: FILE:/tmp/krb5cc_0</span><br><span class="line">Default principal: root/admin@JIMI.COM</span><br><span class="line">Valid starting     Expires            Service principal</span><br><span class="line">11/07/14 15:33:57  11/08/14 15:33:57  krbtgt/JIMI.COM@JIMI.COM</span><br><span class="line">renew until 11/17/14 15:33:57</span><br><span class="line">Kerberos 4 ticket cache: /tmp/tkt0</span><br><span class="line">klist: You have no tickets cached</span><br><span class="line">kinit -R</span><br><span class="line">klist</span><br><span class="line">Ticket cache: FILE:/tmp/krb5cc_0</span><br><span class="line">Default principal: root/admin@JIMI.COM</span><br><span class="line">Valid starting     Expires            Service principal</span><br><span class="line">11/07/14 15:34:05  11/08/14 15:34:05  krbtgt/JIMI.COM@JIMI.COM</span><br><span class="line">renew until 11/17/14 15:33:57</span><br><span class="line">Kerberos 4 ticket cache: /tmp/tkt0</span><br><span class="line">klist: You have no tickets cached</span><br></pre></td></tr></table></figure><p>抽取密钥并将其储存在本地 keytab 文件 /etc/krb5.keytab 中。这个文件由超级用户拥有，所以您必须是 root 用户才能在 kadmin shell 中执行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">kadmin.local -q &quot;ktadd kadmin/admin&quot;</span><br><span class="line">klist -k /etc/krb5.keytab</span><br><span class="line">Keytab name: FILE:/etc/krb5.keytab</span><br><span class="line">KVNO Principal</span><br><span class="line">---------------------------------------------------------</span><br><span class="line">     3 kadmin/admin@LASHOU-INC.COM</span><br><span class="line">     3 kadmin/admin@LASHOU-INC.COM</span><br><span class="line">     3 kadmin/admin@LASHOU-INC.COM</span><br><span class="line">     3 kadmin/admin@LASHOU-INC.COM</span><br><span class="line">     3 kadmin/admin@LASHOU-INC.COM</span><br></pre></td></tr></table></figure><p>HDFS上配置kerberos</p><p>创建认证规则</p><p>在 <code>Kerberos</code> 安全机制里，一个 <code>principal</code> 就是 <code>realm</code> 里的一个对象，一个 <code>principal</code> 总是和一个密钥（<code>secret key</code>）成对出现的。</p><p>这个 <code>principal</code> 的对应物可以是 <code>service</code>，可以是 <code>host</code>，也可以是 <code>user</code>，对于 <code>Kerberos</code> 来说，都没有区别。</p><p><code>Kdc(Key distribute center)</code> 知道所有 <code>principal</code> 的 <code>secret key</code>，但每个 <code>principal</code> 对应的对象只知道自己的那个 <code>secret key</code> 。这也是“共享密钥“的由来。</p><p>对于 <code>hadoop</code>，<code>principals</code> 的格式为</p><p><a href="mailto:`username/fully.qualified.domain.name@YOUR-REALM.COM" target="_blank" rel="noopener">`username/fully.qualified.domain.name@YOUR-REALM.COM</a>`</p><p>通过 <code>yum</code> 源安装的 <code>cdh</code> 集群中，NameNode和 DataNode 是通过 hdfs 启动的，故为集群中每个服务器节点添加两个<code>principals：hdfs</code>、HTTP。</p><p>在 KCD server 上（这里是 cdh1）创建 hdfs principal：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kadmin.local -q &quot;addprinc -randkey hdfs/datanode0@JIMI.COM&quot;</span><br><span class="line">kadmin.local -q &quot;addprinc -randkey hdfs/datanode1@JIMI.COM&quot;</span><br><span class="line">kadmin.local -q &quot;addprinc -randkey hdfs/master@JIMI.COM&quot;</span><br></pre></td></tr></table></figure><p>-randkey<br>标志没有为新 <code>principal</code> 设置密码，而是指示 <code>kadmin</code> 生成一个随机密钥。之所以在这里使用这个标志，是因为此 <code>principal</code> 不需要用户交互。它是计算机的一个服务器账户。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kadmin.local -q &quot;addprinc -randkey HTTP/ datanode0@JIMI.COM &quot;</span><br><span class="line">kadmin.local -q &quot;addprinc -randkey HTTP/ datanode1@JIMI.COM &quot;</span><br><span class="line">kadmin.local -q &quot;addprinc -randkey HTTP/ master@JIMI.COM &quot;</span><br></pre></td></tr></table></figure><p>创建完成后，查看：</p><p><code>kadmin.local -q &quot;listprincs&quot;</code></p><p>手动创建keytab文件</p><p><code>keytab</code>是包含 <code>principals</code> 和加密 <code>principal key</code> 的文件。<code>keytab</code> 文件对于每个 <code>host</code>是唯一的，因为 <code>key</code> 中包含 <code>hostname</code>。<code>keytab</code>文件用于不需要人工交互和保存纯文本密码，实现到 <code>kerberos</code> 上验证一个主机上的 <code>principal</code>。因为服务器上可以访问 <code>keytab</code> 文件即可以以 <code>principal</code> 的身份通过 <code>kerberos</code> 的认证，所以，<code>keytab</code> 文件应该被妥善保存，应该只有少数的用户可以访问。</p><p>创建包含 hdfs principal 和 host principal 的 hdfs keytab：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xst -norandkey -k hdfs.keytab hdfs/fully.qualified.domain.name host/fully.qualified.domain.name</span><br></pre></td></tr></table></figure><p>创建包含 mapred principal 和 host principal 的 mapred keytab：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xst -norandkey -k mapred.keytab mapred/fully.qualified.domain.name host/fully.qualified.domain.name</span><br></pre></td></tr></table></figure><p>注意：上面的方法使用了xst的norandkey参数，有些kerberos不支持该参数。<br>当不支持该参数时有这样的提示：<code>Principal -norandkey does not exist</code>.，需要使用下面的方法来生成keytab文件:</p><p>在master节点，即KDC server节点上执行下面的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /var/kerberos/krb5kdc/</span><br><span class="line">kadmin.local -q &quot;xst  -k hdfs-unmerged.keytab  hdfs/datanode0@JIMI.COM&quot;</span><br><span class="line">kadmin.local -q &quot;xst  -k hdfs-unmerged.keytab  hdfs/datanode1@JIMI.COM&quot;</span><br><span class="line">kadmin.local -q &quot;xst  -k hdfs-unmerged.keytab  hdfs/master@JIMI.COM&quot;</span><br><span class="line">----------------------------------------------------------------------------------</span><br><span class="line">kadmin.local -q &quot;xst  -k HTTP.keytab  HTTP/ datanode0@JIMI.COM &quot;</span><br><span class="line">kadmin.local -q &quot;xst  -k HTTP.keytab  HTTP/ datanode1@JIMI.COM &quot;</span><br><span class="line">kadmin.local -q &quot;xst  -k HTTP.keytab  HTTP/ master@JIMI.COM &quot;</span><br></pre></td></tr></table></figure><p>这样，就会在 /var/kerberos/krb5kdc/ 目录下生成hdfs-unmerged.keytab 和 HTTP.keytab 两个文件，接下来使用 ktutil 合并者两个文件为 hdfs.keytab。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd /var/kerberos/krb5kdc/</span><br><span class="line">ktutil</span><br><span class="line">ktutil: rkt hdfs-unmerged.keytab</span><br><span class="line">ktutil: rkt HTTP.keytab</span><br><span class="line">ktutil: wkt hdfs.keytab</span><br><span class="line">ktutil: exit</span><br></pre></td></tr></table></figure><p>使用 klist 即可查看 hdfs.keytab 文件列表：（省略）</p><p>验证是否正确合并了key，使用合并后的keytab，分别使用hdfs和host principals来获取证书。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kinit -k -t hdfs.keytab hdfs/master@JIMI.COM</span><br><span class="line">kinit -k -t hdfs.keytab HTTP/master@JIMI.COM</span><br></pre></td></tr></table></figure><p>如果出现错误：<code>kinit: Key table entry not found while getting initial credentials</code>，则上面的合并有问题，重新执行前面的操作。</p><p>部署kerberos keytab文件</p><p>拷贝 hdfs.keytab 文件到其他节点的 /etc/hadoop/conf 目录</p><p>并设置权限，分别在三个节点上运行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chown hdfs:hadoop /etc/hadoop/conf/hdfs.keytab</span><br><span class="line">chmod 400 /etc/hadoop/conf/hdfs.keytab</span><br></pre></td></tr></table></figure><p>原因：</p><p>由于 keytab 相当于有了永久凭证，不需要提供密码(如果修改<code>kdc</code>中的<code>principal</code>的密码，则该<code>keytab</code>就会失效)，所以其他用户如果对该文件有读权限，就可以冒充 <code>keytab</code> 中指定的用户身份访问 <code>hadoop</code>，所以 <code>keytab</code> 文件需要确保只对 <code>owner</code> 有读权限(0400)</p><p>修改hdfs配置文件，先停止集群</p><p>在集群总所有节点的<code>core-site.xml</code>文件中添加下面的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.security.authentication&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;kerberos&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.security.authorization&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>在集群总所有节点的<code>hdfs-site.xml</code>文件中添加下面的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;  </span><br><span class="line">  &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt;  </span><br><span class="line">  &lt;value&gt;700&lt;/value&gt;  </span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/etc/hadoop/conf/hdfs.keytab&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;hdfs/_HOST@JAVACHEN.COM&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.namenode.kerberos.https.principal&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HTTP/_HOST@JAVACHEN.COM&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.datanode.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;0.0.0.0:1004&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.datanode.http.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;0.0.0.0:1006&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/etc/hadoop/conf/hdfs.keytab&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;hdfs/_HOST@JAVACHEN.COM&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.datanode.kerberos.https.principal&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HTTP/_HOST@JAVACHEN.COM&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>如果想开启 SSL，请添加（本文不对这部分做说明）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.http.policy&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HTTPS_ONLY&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>如果 HDFS 配置了 QJM HA，则需要添加（另外，你还要在 zookeeper 上配置 kerberos）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/etc/hadoop/conf/hdfs.keytab&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;hdfs/_HOST@JAVACHEN.COM&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HTTP/_HOST@JAVACHEN.COM&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>如果配置了WebHDFS，则添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HTTP/_HOST@JAVACHEN.COM&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/etc/hadoop/conf/hdfs.keytab&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>配置中需要注意的点：</p><p>1.<code>dfs.datanode.address</code>表示<code>data transceiver RPC server</code>所绑定的<code>hostname</code>或IP地址，如果开启 security，端口号必须小于 1024(privileged port)，否则的话启动 datanode 时候会报 <code>Cannot start secure cluster without privileged resources</code> 错误。</p><p>2.<code>principal</code> 中的 <code>instance</code> 部分可以使用 _HOST 标记，系统会自动替换它为全称域名。</p><p>3.如果开启了 <code>security, hadoop</code> 会对 <code>hdfs block data</code>(由 dfs.data.dir 指定)做 <code>permission check</code>，方式用户的代码不是调用<code>hdfs api</code>而是直接本地读<code>block data</code>，这样就绕过了<code>kerberos</code>和文件权限验证，管理员可以通过设置 <code>dfs.datanode.data.dir.perm</code> 来修改 <code>datanode</code> 文件权限，这里我们设置为700</p><p>CDH的权限管理（<a href="https://www.cloudera.com/documentation/enterprise/6/latest/topics/cm_sg_s1_install_cm_cdh.html" target="_blank" rel="noopener">来自cloudera官网</a>）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hdfs：NameNode, DataNodes, and Secondary NameNode</span><br><span class="line">mapred：JobTracker and TaskTrackers (MR1) and Job History Server (YARN)</span><br><span class="line">yarn：ResourceManager and NodeManagers (YARN)</span><br><span class="line">oozie：Oozie Server</span><br><span class="line">hue：Hue Server, Beeswax Server, Authorization Manager, and Job Designer</span><br></pre></td></tr></table></figure><p>目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dfs.name.dir/ hdfs:hadoop</span><br><span class="line">dfs.data.dir/ hdfs:hadoop</span><br><span class="line">mapred.local.dir/ mapred:hadoop</span><br><span class="line">mapred.system.dir in HDFS/ mapred:hadoop</span><br><span class="line">yarn.nodemanager.local-dirs/ yarn:yarn</span><br><span class="line">yarn.nodemanager.log-dirs/ yarn:yarn</span><br><span class="line">oozie.service.StoreService.jdbc.url (if using Derby)/ oozie:oozie</span><br><span class="line">[[database]] name/ hue:hue</span><br><span class="line">javax.jdo.option.ConnectionURL/ hue:hue</span><br></pre></td></tr></table></figure><p>启动NameNode</p><p>启动之前必须确保JCE jar已经替换，首先检查JSVC</p><p>首先master节点查看是否安装了JSVC</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ls /usr/lib/bigtop-utils/</span><br><span class="line">bigtop-detect-classpath  bigtop-detect-javahome  bigtop-detect-javalibs  jsvc</span><br></pre></td></tr></table></figure><p>然后编辑<code>/etc/default/hadoop-hdfs-datanode</code>，取消对下面注释并添加一行JSVC_HOME，修改如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_SECURE_DN_USER=hdfs</span><br><span class="line">export HADOOP_SECURE_DN_PID_DIR=/var/run/hadoop-hdfs</span><br><span class="line">export HADOOP_SECURE_DN_LOG_DIR=/var/log/hadoop-hdfs</span><br><span class="line">export JSVC_HOME=/usr/lib/bigtop-utils</span><br></pre></td></tr></table></figure><p>hadoop-hdfs-datanode同步到其他节点</p><p>随后分别在CDH2、CDH3获取ticket然后启动服务</p><p>#root为root/admin密码</p><p><code>kinit -k -t /etc/hadoop/conf/hdfs.keytab hdfs/master@JIMI.COM; service hadoop-hdfs-datanode start</code></p><p>（这仅仅为master节点上的操作，别的节点类似）</p><p>观察master上的Namenode日志，出现下面的日志表名Datanode启动成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">14/11/04 17:21:41 INFO security.UserGroupInformation:</span><br><span class="line">Login successful for user hdfs/cdh2@JAVACHEN.COM using keytab file /etc/hadoop/conf/hdfs.keytab</span><br></pre></td></tr></table></figure><p>Tips:</p><ul><li><p>配置 hosts，hostname 请使用小写</p></li><li><p>确保 kerberos 客户端和服务端连通</p></li><li><p>替换 JRE 自带的 JCE jar 包</p></li><li><p>为 DataNode 设置运行用户并配置 JSVC_HOME</p></li><li><p>启动服务前，先获取 ticket 再运行相关命令</p></li></ul><p>Quote:</p><p><a href="https://www.cloudera.com/documentation/enterprise/5-12-x/topics/cdh_sg_kerberos_prin_keytab_deploy.html" target="_blank" rel="noopener">CDH官方文档对Kerberos的介绍1</a></p><p><a href="https://blog.cloudera.com/blog/2015/03/how-to-quickly-configure-kerberos-for-your-apache-hadoop-cluster/" target="_blank" rel="noopener">CDH官方文档对Kerberos的介绍2</a></p><p><a href="http://web.mit.edu/~kerberos/krb5-devel/doc/admin/conf_files/krb5_conf.html" target="_blank" rel="noopener">MIT官网的文档</a></p><p><a href="https://docs.oracle.com/cd/E24847_01/html/819-7061/setup-9.html" target="_blank" rel="noopener">Oracle官网对Kerberos的介绍</a></p><hr><h3 id="5-Apach-原生Zookeeper的Kerberos配置及其验证"><a href="#5-Apach-原生Zookeeper的Kerberos配置及其验证" class="headerlink" title="5.Apach 原生Zookeeper的Kerberos配置及其验证"></a>5.Apach 原生Zookeeper的Kerberos配置及其验证</h3><p>Zookeeper的配置分为两个步骤，先配置<code>Server</code>的<code>keytab</code>，再配置<code>Client</code>的<code>keytab</code>,如果<code>zookeeper-client</code> 和 <code>zookeeper-server</code> 安装在同一个节点上，则 <code>java.env</code> 中的 <code>java.security.auth.login.config</code> 参数会被覆盖，这一点从<code>zookeeper-client</code> 命令启动日志可以看出来。</p><p>首先是配置 <code>Zk Server</code></p><p>因为KDC已经配置了，所以KDC不用再配</p><p>第一步直接生成Keytab</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ cd /var/kerberos/krb5kdc/</span><br><span class="line">kadmin.local -q &quot;addprinc -randkey zookeeper/master@JIMI.COM &quot;</span><br><span class="line">kadmin.local -q &quot;addprinc -randkey zookeeper/datanode0@JIMI.COM &quot;</span><br><span class="line">kadmin.local -q &quot;addprinc -randkey zookeeper/datanode1@JIMI.COM &quot;</span><br><span class="line">kadmin.local -q &quot;xst  -k zookeeper.keytab  zookeeper/master@JIMI.COM &quot;</span><br><span class="line">kadmin.local -q &quot;xst  -k zookeeper.keytab  zookeeper/datanode0@JIMI.COM &quot;</span><br><span class="line">kadmin.local -q &quot;xst  -k zookeeper.keytab  zookeeper/datanode1@JIMI.COM &quot;</span><br></pre></td></tr></table></figure><p>将Keytab拷贝到目录<code>/etc/zookeeper/conf</code></p><p>在三个节点上分别执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/zookeeper/conf/;chown zookeeper:hadoop zookeeper.keytab ;chmod 400 *.keytab</span><br></pre></td></tr></table></figure><p>目的是为了控制权限。</p><p>然后修改配置文件</p><p>在三个节点上的zoo.cfg文件中添加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">authProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider jaasLoginRenew=3600000</span><br></pre></td></tr></table></figure><p>然后创建JAAS配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Server &#123;</span><br><span class="line">  com.sun.security.auth.module.Krb5LoginModule required</span><br><span class="line">  useKeyTab=true</span><br><span class="line">  keyTab=&quot;/etc/zookeeper/conf/zookeeper.keytab&quot;</span><br><span class="line">  storeKey=true</span><br><span class="line">  useTicketCache=false</span><br><span class="line">  principal=&quot;zookeeper/master@JIMI.COM&quot;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>三个节点都要有，每个节点里面的principal有点不同</p><p>然后是配置<strong>Zookeeper Client</strong></p><p>还是先生成<code>keytab</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ cd /var/kerberos/krb5kdc/</span><br><span class="line">kadmin.local -q &quot;addprinc -randkey zkcli/master@JIMI.COM &quot;</span><br><span class="line">kadmin.local -q &quot;addprinc -randkey zkcli/datanode0@JIMI.COM &quot;</span><br><span class="line">kadmin.local -q &quot;addprinc -randkey zkcli/datanode1@JIMI.COM &quot;</span><br><span class="line">kadmin.local -q &quot;xst  -k zkcli.keytab  zkcli/master@JIMI.COM &quot;</span><br><span class="line">kadmin.local -q &quot;xst  -k zkcli.keytab  zkcli/datanode0@JIMI.COM &quot;</span><br><span class="line">kadmin.local -q &quot;xst  -k zkcli.keytab  zkcli/datanode1@JIMI.COM &quot;</span><br></pre></td></tr></table></figure><p>拷贝 zkcli.keytab 文件到其他节点的 <code>/etc/zookeeper/conf</code> 目录，并设置权限，分别在master、datanode0、datanode1 上执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/zookeeper/conf/;</span><br><span class="line">chown zookeeper:</span><br><span class="line">hadoop zkcli.keytab ;chmod 400 *.keytab</span><br></pre></td></tr></table></figure><p>由于 <code>keytab</code> 相当于有了永久凭证，不需要提供密码(如果修改 <code>kdc</code> 中的 <code>principal</code> 的密码，则该 <code>keytab</code> 就会失效)，所以其他用户如果对该文件有读权限，就可以冒充 <code>keytab</code> 中指定的用户身份访问 <code>hadoop</code>，所以 <code>keytab</code> 文件需要确保只对 <code>owner</code> 有读权限(0400)</p><p>创建 JAAS 配置文件</p><p>在<code>/etc/zookeeper/conf/</code>创建<code>client-jaas.conf</code>文件，内容如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Client &#123;</span><br><span class="line">  com.sun.security.auth.module.Krb5LoginModule required</span><br><span class="line">  useKeyTab=true</span><br><span class="line">  keyTab=&quot;/etc/zookeeper/conf/zkcli.keytab&quot;</span><br><span class="line">  storeKey=true</span><br><span class="line">  useTicketCache=false</span><br><span class="line">  principal=&quot;zkcli@JIMI.COM&quot;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>同步到其他节点，然后在<code>/etc/zookeeper/conf/</code>目录创建或者修改<code>java.env</code>，内容如下</p><p><code>export CLIENT_JVMFLAGS=&quot;-Djava.security.auth.login.config=/etc/zookeeper/conf/client-jaas.conf&quot;</code></p><p>并且同步到别的节点上</p><p>接着是验证：</p><p>启动客户端：<code>zookeeper-client -server master:2181</code></p><p>创建一个<code>znode</code>节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: master:2181(CONNECTED) 0] create /znode1 sasl:zkcli@JIMI.COM:cdwra</span><br><span class="line">Created /znode1</span><br></pre></td></tr></table></figure><p>验证该节点是否创建以及其ACL：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[zk: master:2181(CONNECTED) 1] getAcl /znode1</span><br><span class="line">    &apos;world,&apos;anyone</span><br><span class="line">    : cdrwa</span><br></pre></td></tr></table></figure><p>只要能够在一个节点上创建<code>znode</code>，在别的节点上能够显示出来，就说明<code>Zookeeper</code>的<code>kerberos</code>已经配置成功。</p><hr><h3 id="6-Apach原生Kafka的Kerberos配置及其验证"><a href="#6-Apach原生Kafka的Kerberos配置及其验证" class="headerlink" title="6.Apach原生Kafka的Kerberos配置及其验证"></a>6.Apach原生Kafka的Kerberos配置及其验证</h3><p>因为之前的操作已经搭建完了<code>KDC</code>，所以省略了自建<code>Kerberos</code>的步骤</p><p>首先还是为<code>broker</code>每台服务器在<code>Kerberos</code>服务器生成相应的<code>principal</code>和<code>Keytab</code>，将下列命令里生成的<code>kafka.keytab</code>文件分发到对应<code>broker</code>机器的统一位置，比如<code>/etc/kafka.keytab</code>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">addprinc -randkey kafka/kafkahost1@EXAMPLE.COM</span><br><span class="line">addprinc -randkey kafka/kafkahost2@EXAMPLE.COM</span><br><span class="line">addprinc -randkey kafka/kafkahost3@EXAMPLE.COM</span><br><span class="line">--------------------------------------------------------</span><br><span class="line">xst -norandkey -k /opt/kafkahost1/kafka.keytab kafka/kafkahost1@EXAMPLE.COM</span><br><span class="line">xst -norandkey -k /opt/kafkahost2/kafka.keytab kafka/kafkahost2@EXAMPLE.COM</span><br><span class="line">xst -norandkey -k /opt/kafkahost3/kafka.keytab kafka/kafkahost3@EXAMPLE.COM</span><br></pre></td></tr></table></figure><p>配置kafka server文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">listeners=SASL_PLAINTEXT://:9092</span><br><span class="line">security.inter.broker.protocol=SASL_PLAINTEXT</span><br><span class="line">sasl.mechanism.inter.broker.protocol=GSSAPI</span><br><span class="line">sasl.enabled.mechanisms=GSSAPI</span><br><span class="line">sasl.kerberos.service.name=kafka</span><br><span class="line">super.users=User:kafka</span><br><span class="line">authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer</span><br></pre></td></tr></table></figure><p>KafkaClient模块是为了bin目录下kafka-console-consumer.sh之类的脚本使用的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">KafkaServer &#123;</span><br><span class="line">            com.sun.security.auth.module.Krb5LoginModule required</span><br><span class="line">            useKeyTab=true</span><br><span class="line">            storeKey=true</span><br><span class="line">            keyTab=&quot;/etc/kafka.keytab&quot;</span><br><span class="line">            principal=&quot;kafka/kafkahost1@EXAMPLE.COM&quot;;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">KafkaClient &#123;</span><br><span class="line">        com.sun.security.auth.module.Krb5LoginModule required</span><br><span class="line">        useKeyTab=true</span><br><span class="line">        storeKey=true</span><br><span class="line">        keyTab=&quot;/etc/kafka.keytab&quot;</span><br><span class="line">        principal=&quot;kafka/kafkahost1@EXAMPLE.COM&quot;</span><br><span class="line">        useTicketCache=true;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>修改bin目录下kafka-run-class.sh，在  exec $JAVA 后面增加kerberos启动参数,然后就可以用正常的脚本启动服务了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Djava.security.krb5.conf=/etc/krb5.conf -Djava.security.auth.login.config=/opt/kafka/config/kafka_server_jaas.conf</span><br></pre></td></tr></table></figure><p>或者用这个脚本启动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">export KAFKA_HEAP_OPTS=&apos;-Xmx256M&apos;</span><br><span class="line">export KAFKA_OPTS=&apos;-Djava.security.krb5.conf=/etc/krb5.conf -Djava.security.auth.login.confi</span><br><span class="line">g=/etc/kafka/zookeeper_jaas.conf&apos;</span><br><span class="line">bin/zookeeper-server-start.sh config/zookeeper.properties &amp;</span><br><span class="line"></span><br><span class="line">sleep 5</span><br><span class="line"></span><br><span class="line">export KAFKA_OPTS=&apos;-Djava.security.krb5.conf=/etc/krb5.conf -Djava.security.auth.login.confi</span><br><span class="line">g=/etc/kafka/kafka_server_jaas.conf&apos;</span><br><span class="line">bin/kafka-server-start.sh config/server.properties</span><br></pre></td></tr></table></figure><p>最终的目的都是一样</p><p>客户端脚本使用</p><p>启用kerberos后，部分kafka管理脚本需要增加额外的参数才能使用</p><p>首先建立配置文件<code>client.properties</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">security.protocol=SASL_PLAINTEXT</span><br><span class="line">sasl.kerberos.service.name=kafka</span><br><span class="line">sasl.mechanism=GSSAPI</span><br></pre></td></tr></table></figure><p>涉及到的zookeeper.properties</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">authProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider</span><br><span class="line">requireClientAuthScheme=sasl</span><br><span class="line">jaasLoginRenew=3600000</span><br></pre></td></tr></table></figure><p>所以新命令的使用方式为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-groups.sh --bootstrap-server kafkahost1:9092 --list --command-config client.properties</span><br><span class="line">bin/kafka-console-producer.sh --broker-list kafkahost1:9092 --topic test --producer.config client.properties</span><br><span class="line">bin/kafka-console-consumer.sh --bootstrap-server kafkahost1:9092 --topic test --consumer.config client.properties</span><br></pre></td></tr></table></figure><p>如果之前JCE的包没有安装好的话会报如下错误，需要把JCE包安装到位即可</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">WARN [Controller-60-to-broker-60-send-thread], Controller 60&apos;s connection to broker kafka60:9092 (id: 60 rack: null) was unsuccessful (kafka.controller.RequestSendThread)</span><br><span class="line">java.io.IOException: Connection to kafka60:9092 (id: 60 rack: null) failed</span><br></pre></td></tr></table></figure><p>能在命令行上运行成功命令行消费者和命令行生产者就说明ZK和Kafka的安装基本搞定，没有问题。</p><p>用Java连接集群上的Kerberos组件篇幅较长，涉及代码，另外开一篇文章说明。</p><hr><h3 id="7-Cloudera’s-Distribution-Including-Apache-Hadoop-CDH-上Kerberos的安装"><a href="#7-Cloudera’s-Distribution-Including-Apache-Hadoop-CDH-上Kerberos的安装" class="headerlink" title="7.Cloudera’s Distribution Including Apache Hadoop(CDH)上Kerberos的安装"></a>7.Cloudera’s Distribution Including Apache Hadoop(<em>CDH</em>)上Kerberos的安装</h3><p>CDH上面的Kerberos安装其实已经被简化了，简化的好处是安装方便，坏处是一旦出现问题不知从何处下手。所以对前面单独组件的了解是有必要的。实际操作下来，官网和各技术博客都有些许问题。在此记录。</p><p>首先配置KDC，和单独安装操作相同</p><p>首先KDC还是要配置，在CM服务器上配置KDC</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install krb5-serverkrb5-libs krb5-auth-dialog krb5-workstation</span><br></pre></td></tr></table></figure><p>修改<code>/etc/krb5.conf</code>、<code>/var/kerberos/krb5kdc/kadm5.acl</code>、<code>/var/kerberos/krb5kdc/kdc.conf</code>配置，配置内容相同，不再赘述。</p><p>然后在所有节点上（包括CM）安装Kerberos客户端</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install krb5-libs krb5-workstation</span><br></pre></td></tr></table></figure><p>然后在CM节点上独立安装额外的包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install openldap-clients</span><br></pre></td></tr></table></figure><p>分发krb5.conf到另外两个节点</p><p>JCE包还是要记得替换，替换位置：<code>/usr/share/java/jdk1.8.0_144/jre/lib/security</code></p><p>KDC安装完成后，建立测试Kerberos的管理员账号。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g2g5k45t4jj20et03u3yg.jpg" alt="alt admin"></p><hr><p>CM界面 -&gt;管理 -&gt; 安全</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g2g5rgh6faj20o702ut8o.jpg" alt="CDH"></p><p>点击启用</p><hr><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g2g5v0ar5zj20pe0o43zp.jpg" alt="CDH1"></p><p>全部勾选即可</p><hr><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g2g5v0a7vuj20n00pmt9i.jpg" alt></p><p>这边别的都好理解，都是和host上面对应的，然后这个加密类型是和krb5.conf对应相同的</p><hr><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g2g5v08hypj20k005dgll.jpg" alt></p><p>这上面有张图没截到，是选择是否要通过CM管理的，一般选择不通过</p><p>这边管理账户输入之前创建的管理账户即可。</p><hr><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g2g5v0a1fxj20hz05d0ss.jpg" alt></p><p>这边CDH会帮助验证密码</p><hr><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g2g5v0ayqyj20mx0oamxv.jpg" alt></p><p>接下来的这个步骤我标红了一块，我在这边spark2的部分，服务范围设置的是spark2，默认是spark，我修改了一下，避免以后的keytab名字出现歧义</p><hr><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g2g5v0e6e7j20oc0q1wfz.jpg" alt></p><p>随后，直接勾选重启选项即可</p><p>这边初步的配置就完成了</p><p>后面涉及每个组件，都有不同的配置方法，有的简单，有的复杂一点</p><p>还有Java连接代码需要补完</p><hr><h3 id="Kerberos卸载BUG"><a href="#Kerberos卸载BUG" class="headerlink" title="Kerberos卸载BUG"></a>Kerberos卸载BUG</h3><p>Linux上的KDC存在严重的卸载BUG，使用<code>yun remove</code>卸载会出现严重的问题</p><p>因为之前<code>principal</code>的认证因为人为操作出现了一些问题，所以用yum remove卸载重新安装了一下，yum remove之后出现了大问题，凡是新连接外部的命令都无法使用，包括并不限于：yum、ssh、wgt等命令，FTP工具也无法使用，这就导致了无法连接外部下载kdc安装包</p><p>还好我卸载之前连接的SSH窗口没有关闭（新的连接无法建立， 但是已经建立的连接不会断开），用的XSHELL 6，我尝试用XFTP连接，失败，但是XSHELL 6 默认输入框里就有传输文件的功能，上传四个Kerberos文件之后重新安装之后才解决了问题。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;从18年底开始，公司的服务器经常受到各种挖矿脚本病毒的公司，Java后端Redis漏洞层出不穷，Hadoop这边MR的提交权限BUG也被利用了，于是决定调研Kerberos，发现Kerberos是一个巨大的坑，在此记录下笔记，作为我的Github Pages第一篇文档，希望后来人少走弯路。此文可能分为几次更新。&lt;/p&gt;
&lt;p&gt;第一次更新：2019-4-29&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>

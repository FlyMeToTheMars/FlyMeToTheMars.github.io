<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Mars</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-05-31T05:44:41.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Fly Hugh</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Apache Maven 编译打包Flink</title>
    <link href="http://yoursite.com/2020/05/30/%E4%BD%BF%E7%94%A8Maven%E7%BC%96%E8%AF%91Flink/"/>
    <id>http://yoursite.com/2020/05/30/使用Maven编译Flink/</id>
    <published>2020-05-30T10:55:57.954Z</published>
    <updated>2020-05-31T05:44:41.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Apache Maven 编译打包Flink</p></blockquote><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf9x6qsh2lj20tk0fnta2.jpg" alt="微信截图_20200530031106.png"></p><p>给爷狠狠得Success</p><a id="more"></a> <h1 id="Apache-Maven-编译打包Flink"><a href="#Apache-Maven-编译打包Flink" class="headerlink" title="Apache Maven 编译打包Flink"></a>Apache Maven 编译打包Flink</h1><p>因为需要修改一些Flink的模块，所以需要自己编译打包Flink，花了好长时间摸索，成功打包1.8.1和1.10.1之后，记录下自己踩的坑。</p><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>在打包Flink之前就有一些准备工作需要做。</p><h3 id="环境和预处理"><a href="#环境和预处理" class="headerlink" title="环境和预处理"></a>环境和预处理</h3><table><thead><tr><th>类型</th><th>版本</th></tr></thead><tbody><tr><td>系统版本</td><td>win10</td></tr><tr><td>maven</td><td>3.6.3</td></tr><tr><td>JDK</td><td>8u231</td></tr><tr><td>scala</td><td>2.11.8</td></tr><tr><td>hadoop</td><td>2.7.6</td></tr><tr><td>node</td><td>v12.14.0</td></tr><tr><td>Flink版本</td><td>1.8.1&amp;1.10.1</td></tr></tbody></table><p>路径注意全英文</p><h4 id="一些区别"><a href="#一些区别" class="headerlink" title="一些区别"></a>一些区别</h4><p>Flink1.8.1编译的时候，编译遇到几次错误是因为</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">type</span>&gt;</span>test-jar<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Flink1.10.1并没有遇到，主要出现在两个模块，<code>flink-s3-fs-hadoop</code> 和 <code>flink-oss-fs-hadoop</code> </p><p>Flink1.8.1还在<code>flink-connectors/flink-hadoop-compatibility/pom.xml</code>模块里面添加了</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-cli<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-cli<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>以及在<code>flink-connectors/pom.xml</code>里面添加了</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-net<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-net<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>这些问题在github下载下来的release版本1.10.1里面并没有出现，不知道是改进了还是什么原因。</p><h4 id="网络部分"><a href="#网络部分" class="headerlink" title="网络部分"></a>网络部分</h4><p>为了在编译的过程中，排错彻底排除网络原因，我采用了几个办法：</p><p><strong>连接手机热点</strong>：非常有用的措施，电信宽带被DNS污染非常严重，移动对于外网应该是最宽容的</p><p><strong>SSR</strong>：快速 稳定的线路一条</p><p><strong>配置Maven的代理到SSR的端口上</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">Licensed to the Apache Software Foundation (ASF) under one</span></span><br><span class="line"><span class="comment">or more contributor license agreements.  See the NOTICE file</span></span><br><span class="line"><span class="comment">distributed with this work for additional information</span></span><br><span class="line"><span class="comment">regarding copyright ownership.  The ASF licenses this file</span></span><br><span class="line"><span class="comment">to you under the Apache License, Version 2.0 (the</span></span><br><span class="line"><span class="comment">"License"); you may not use this file except in compliance</span></span><br><span class="line"><span class="comment">with the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">Unless required by applicable law or agreed to in writing,</span></span><br><span class="line"><span class="comment">software distributed under the License is distributed on an</span></span><br><span class="line"><span class="comment">"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY</span></span><br><span class="line"><span class="comment">KIND, either express or implied.  See the License for the</span></span><br><span class="line"><span class="comment">specific language governing permissions and limitations</span></span><br><span class="line"><span class="comment">under the License.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment"> | This is the configuration file for Maven. It can be specified at two levels:</span></span><br><span class="line"><span class="comment"> |</span></span><br><span class="line"><span class="comment"> |  1. User Level. This settings.xml file provides configuration for a single user,</span></span><br><span class="line"><span class="comment"> |                 and is normally provided in $&#123;user.home&#125;/.m2/settings.xml.</span></span><br><span class="line"><span class="comment"> |</span></span><br><span class="line"><span class="comment"> |                 <span class="doctag">NOTE:</span> This location can be overridden with the CLI option:</span></span><br><span class="line"><span class="comment"> |</span></span><br><span class="line"><span class="comment"> |                 -s /path/to/user/settings.xml</span></span><br><span class="line"><span class="comment"> |</span></span><br><span class="line"><span class="comment"> |  2. Global Level. This settings.xml file provides configuration for all Maven</span></span><br><span class="line"><span class="comment"> |                 users on a machine (assuming they're all using the same Maven</span></span><br><span class="line"><span class="comment"> |                 installation). It's normally provided in</span></span><br><span class="line"><span class="comment"> |                 $&#123;maven.conf&#125;/settings.xml.</span></span><br><span class="line"><span class="comment"> |</span></span><br><span class="line"><span class="comment"> |                 <span class="doctag">NOTE:</span> This location can be overridden with the CLI option:</span></span><br><span class="line"><span class="comment"> |</span></span><br><span class="line"><span class="comment"> |                 -gs /path/to/global/settings.xml</span></span><br><span class="line"><span class="comment"> |</span></span><br><span class="line"><span class="comment"> | The sections in this sample file are intended to give you a running start at</span></span><br><span class="line"><span class="comment"> | getting the most out of your Maven installation. Where appropriate, the default</span></span><br><span class="line"><span class="comment"> | values (values used when the setting is not specified) are provided.</span></span><br><span class="line"><span class="comment"> |</span></span><br><span class="line"><span class="comment"> |--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">settings</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/SETTINGS/1.0.0"</span></span></span><br><span class="line"><span class="tag">          <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">          <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd"</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- localRepository</span></span><br><span class="line"><span class="comment">   | The path to the local repository maven will use to store artifacts.</span></span><br><span class="line"><span class="comment">   |</span></span><br><span class="line"><span class="comment">   | Default: $&#123;user.home&#125;/.m2/repository</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  --&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">&lt;!-- interactiveMode</span></span><br><span class="line"><span class="comment">   | This will determine whether maven prompts you when it needs input. If set to false,</span></span><br><span class="line"><span class="comment">   | maven will use a sensible default value, perhaps based on some other setting, for</span></span><br><span class="line"><span class="comment">   | the parameter in question.</span></span><br><span class="line"><span class="comment">   |</span></span><br><span class="line"><span class="comment">   | Default: true</span></span><br><span class="line"><span class="comment">  &lt;interactiveMode&gt;true&lt;/interactiveMode&gt;</span></span><br><span class="line"><span class="comment">  --&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- offline</span></span><br><span class="line"><span class="comment">   | Determines whether maven should attempt to connect to the network when executing a build.</span></span><br><span class="line"><span class="comment">   | This will have an effect on artifact downloads, artifact deployment, and others.</span></span><br><span class="line"><span class="comment">   |</span></span><br><span class="line"><span class="comment">   | Default: false</span></span><br><span class="line"><span class="comment">  &lt;offline&gt;false&lt;/offline&gt;</span></span><br><span class="line"><span class="comment">  --&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- pluginGroups</span></span><br><span class="line"><span class="comment">   | This is a list of additional group identifiers that will be searched when resolving plugins by their prefix, i.e.</span></span><br><span class="line"><span class="comment">   | when invoking a command line like "mvn prefix:goal". Maven will automatically add the group identifiers</span></span><br><span class="line"><span class="comment">   | "org.apache.maven.plugins" and "org.codehaus.mojo" if these are not already contained in the list.</span></span><br><span class="line"><span class="comment">   |--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">pluginGroups</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- pluginGroup</span></span><br><span class="line"><span class="comment">     | Specifies a further group identifier to use for plugin lookup.</span></span><br><span class="line"><span class="comment">    &lt;pluginGroup&gt;com.your.plugins&lt;/pluginGroup&gt;</span></span><br><span class="line"><span class="comment">    --&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">pluginGroups</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- proxies</span></span><br><span class="line"><span class="comment">   | This is a list of proxies which can be used on this machine to connect to the network.</span></span><br><span class="line"><span class="comment">   | Unless otherwise specified (by system property or command-line switch), the first proxy</span></span><br><span class="line"><span class="comment">   | specification in this list marked as active will be used.</span></span><br><span class="line"><span class="comment">   |--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">proxies</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">    proxy</span></span><br><span class="line"><span class="comment">     | Specification for one proxy, to be used in connecting to the network.</span></span><br><span class="line"><span class="comment">     |</span></span><br><span class="line"><span class="comment">     &lt;proxy&gt;</span></span><br><span class="line"><span class="comment">    </span></span><br><span class="line"><span class="comment">      &lt;id&gt;httpproxy&lt;/id&gt;</span></span><br><span class="line"><span class="comment">      &lt;active&gt;true&lt;/active&gt;</span></span><br><span class="line"><span class="comment">      &lt;protocol&gt;http&lt;/protocol&gt;</span></span><br><span class="line"><span class="comment">      </span></span><br><span class="line"><span class="comment">        &lt;username&gt;proxyuser&lt;/username&gt;</span></span><br><span class="line"><span class="comment">        &lt;password&gt;proxypass&lt;/password&gt;</span></span><br><span class="line"><span class="comment">        &lt;nonProxyHosts&gt;local.net|some.host.com&lt;/nonProxyHosts&gt;</span></span><br><span class="line"><span class="comment">      </span></span><br><span class="line"><span class="comment">      &lt;host&gt;socks5://127.0.0.1&lt;/host&gt;</span></span><br><span class="line"><span class="comment">      &lt;port&gt;1080&lt;/port&gt;</span></span><br><span class="line"><span class="comment">      </span></span><br><span class="line"><span class="comment">    &lt;/proxy&gt;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    &lt;proxy&gt;</span></span><br><span class="line"><span class="comment">      &lt;id&gt;httpsproxy&lt;/id&gt;</span></span><br><span class="line"><span class="comment">      &lt;active&gt;true&lt;/active&gt;</span></span><br><span class="line"><span class="comment">      &lt;protocol&gt;https&lt;/protocol&gt;</span></span><br><span class="line"><span class="comment">      </span></span><br><span class="line"><span class="comment">        &lt;username&gt;proxyuser&lt;/username&gt;</span></span><br><span class="line"><span class="comment">        &lt;password&gt;proxypass&lt;/password&gt;</span></span><br><span class="line"><span class="comment">        &lt;nonProxyHosts&gt;local.net|some.host.com&lt;/nonProxyHosts&gt;</span></span><br><span class="line"><span class="comment">      </span></span><br><span class="line"><span class="comment">      &lt;host&gt;socks5://127.0.0.1&lt;/host&gt;</span></span><br><span class="line"><span class="comment">      &lt;port&gt;1080&lt;/port&gt;</span></span><br><span class="line"><span class="comment">    &lt;/proxy&gt; --&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">proxy</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">id</span>&gt;</span>ss<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">active</span>&gt;</span>true<span class="tag">&lt;/<span class="name">active</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">protocol</span>&gt;</span>socks5<span class="tag">&lt;/<span class="name">protocol</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">username</span>&gt;</span><span class="tag">&lt;/<span class="name">username</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">password</span>&gt;</span><span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">host</span>&gt;</span>127.0.0.1<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">port</span>&gt;</span>1080<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">nonProxyHosts</span>&gt;</span>127.0.0.1<span class="tag">&lt;/<span class="name">nonProxyHosts</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">proxy</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">proxies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- servers</span></span><br><span class="line"><span class="comment">   | This is a list of authentication profiles, keyed by the server-id used within the system.</span></span><br><span class="line"><span class="comment">   | Authentication profiles can be used whenever maven must make a connection to a remote server.</span></span><br><span class="line"><span class="comment">   |--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">servers</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- server</span></span><br><span class="line"><span class="comment">     | Specifies the authentication information to use when connecting to a particular server, identified by</span></span><br><span class="line"><span class="comment">     | a unique name within the system (referred to by the 'id' attribute below).</span></span><br><span class="line"><span class="comment">     |</span></span><br><span class="line"><span class="comment">     | <span class="doctag">NOTE:</span> You should either specify username/password OR privateKey/passphrase, since these pairings are</span></span><br><span class="line"><span class="comment">     |       used together.</span></span><br><span class="line"><span class="comment">     |</span></span><br><span class="line"><span class="comment">    &lt;server&gt;</span></span><br><span class="line"><span class="comment">      &lt;id&gt;deploymentRepo&lt;/id&gt;</span></span><br><span class="line"><span class="comment">      &lt;username&gt;repouser&lt;/username&gt;</span></span><br><span class="line"><span class="comment">      &lt;password&gt;repopwd&lt;/password&gt;</span></span><br><span class="line"><span class="comment">    &lt;/server&gt;</span></span><br><span class="line"><span class="comment">    --&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- Another sample, using keys to authenticate.</span></span><br><span class="line"><span class="comment">    &lt;server&gt;</span></span><br><span class="line"><span class="comment">      &lt;id&gt;siteServer&lt;/id&gt;</span></span><br><span class="line"><span class="comment">      &lt;privateKey&gt;/path/to/private/key&lt;/privateKey&gt;</span></span><br><span class="line"><span class="comment">      &lt;passphrase&gt;optional; leave empty if not used.&lt;/passphrase&gt;</span></span><br><span class="line"><span class="comment">    &lt;/server&gt;</span></span><br><span class="line"><span class="comment">    --&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">servers</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- mirrors</span></span><br><span class="line"><span class="comment">   | This is a list of mirrors to be used in downloading artifacts from remote repositories.</span></span><br><span class="line"><span class="comment">   |</span></span><br><span class="line"><span class="comment">   | It works like this: a POM may declare a repository to use in resolving certain artifacts.</span></span><br><span class="line"><span class="comment">   | However, this repository may have problems with heavy traffic at times, so people have mirrored</span></span><br><span class="line"><span class="comment">   | it to several places.</span></span><br><span class="line"><span class="comment">   |</span></span><br><span class="line"><span class="comment">   | That repository definition will have a unique id, so we can create a mirror reference for that</span></span><br><span class="line"><span class="comment">   | repository, to be used as an alternate download site. The mirror site will be the preferred</span></span><br><span class="line"><span class="comment">   | server for that repository.</span></span><br><span class="line"><span class="comment">   |--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">mirrors</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- mirror</span></span><br><span class="line"><span class="comment">     | Specifies a repository mirror site to use instead of a given repository. The repository that</span></span><br><span class="line"><span class="comment">     | this mirror serves has an ID that matches the mirrorOf element of this mirror. IDs are used</span></span><br><span class="line"><span class="comment">     | for inheritance and direct lookup purposes, and must be unique across the set of mirrors.</span></span><br><span class="line"><span class="comment">     |</span></span><br><span class="line"><span class="comment">    &lt;mirror&gt;</span></span><br><span class="line"><span class="comment">      &lt;id&gt;mirrorId&lt;/id&gt;</span></span><br><span class="line"><span class="comment">      &lt;mirrorOf&gt;repositoryId&lt;/mirrorOf&gt;</span></span><br><span class="line"><span class="comment">      &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt;</span></span><br><span class="line"><span class="comment">      &lt;url&gt;http://my.repository.com/repo/path&lt;/url&gt;</span></span><br><span class="line"><span class="comment">    &lt;/mirror&gt;</span></span><br><span class="line"><span class="comment">     --&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">     <span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line"></span><br><span class="line">     </span><br><span class="line">     <span class="tag">&lt;<span class="name">id</span>&gt;</span>alimaven<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>aliyun maven<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.aliyun.com/nexus/content/groups/public/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>alimaven<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>aliyun maven<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.aliyun.com/nexus/content/repositories/central/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>ibiblio<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>Human Readable Name for this Mirror.<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://mirrors.ibiblio.org/pub/mirrors/maven2/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>jboss-public-repository-group<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>JBoss Public Repository Group<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://repository.jboss.org/nexus/content/groups/public<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>central<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>Maven Repository Switchboard<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://repo1.maven.org/maven2/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>repo2<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>Human Readable Name for this Mirror.<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://repo2.maven.org/maven2/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">  <span class="tag">&lt;/<span class="name">mirrors</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- profiles</span></span><br><span class="line"><span class="comment">   | This is a list of profiles which can be activated in a variety of ways, and which can modify</span></span><br><span class="line"><span class="comment">   | the build process. Profiles provided in the settings.xml are intended to provide local machine-</span></span><br><span class="line"><span class="comment">   | specific paths and repository locations which allow the build to work in the local environment.</span></span><br><span class="line"><span class="comment">   |</span></span><br><span class="line"><span class="comment">   | For example, if you have an integration testing plugin - like cactus - that needs to know where</span></span><br><span class="line"><span class="comment">   | your Tomcat instance is installed, you can provide a variable here such that the variable is</span></span><br><span class="line"><span class="comment">   | dereferenced during the build process to configure the cactus plugin.</span></span><br><span class="line"><span class="comment">   |</span></span><br><span class="line"><span class="comment">   | As noted above, profiles can be activated in a variety of ways. One way - the activeProfiles</span></span><br><span class="line"><span class="comment">   | section of this document (settings.xml) - will be discussed later. Another way essentially</span></span><br><span class="line"><span class="comment">   | relies on the detection of a system property, either matching a particular value for the property,</span></span><br><span class="line"><span class="comment">   | or merely testing its existence. Profiles can also be activated by JDK version prefix, where a</span></span><br><span class="line"><span class="comment">   | value of '1.4' might activate a profile when the build is executed on a JDK version of '1.4.2_07'.</span></span><br><span class="line"><span class="comment">   | Finally, the list of active profiles can be specified directly from the command line.</span></span><br><span class="line"><span class="comment">   |</span></span><br><span class="line"><span class="comment">   | <span class="doctag">NOTE:</span> For profiles defined in the settings.xml, you are restricted to specifying only artifact</span></span><br><span class="line"><span class="comment">   |       repositories, plugin repositories, and free-form properties to be used as configuration</span></span><br><span class="line"><span class="comment">   |       variables for plugins in the POM.</span></span><br><span class="line"><span class="comment">   |</span></span><br><span class="line"><span class="comment">   |--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">profiles</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- profile</span></span><br><span class="line"><span class="comment">     | Specifies a set of introductions to the build process, to be activated using one or more of the</span></span><br><span class="line"><span class="comment">     | mechanisms described above. For inheritance purposes, and to activate profiles via &lt;activatedProfiles/&gt;</span></span><br><span class="line"><span class="comment">     | or the command line, profiles have to have an ID that is unique.</span></span><br><span class="line"><span class="comment">     |</span></span><br><span class="line"><span class="comment">     | An encouraged best practice for profile identification is to use a consistent naming convention</span></span><br><span class="line"><span class="comment">     | for profiles, such as 'env-dev', 'env-test', 'env-production', 'user-jdcasey', 'user-brett', etc.</span></span><br><span class="line"><span class="comment">     | This will make it more intuitive to understand what the set of introduced profiles is attempting</span></span><br><span class="line"><span class="comment">     | to accomplish, particularly when you only have a list of profile id's for debug.</span></span><br><span class="line"><span class="comment">     |</span></span><br><span class="line"><span class="comment">     | This profile example uses the JDK version to trigger activation, and provides a JDK-specific repo.</span></span><br><span class="line"><span class="comment">    &lt;profile&gt;</span></span><br><span class="line"><span class="comment">      &lt;id&gt;jdk-1.4&lt;/id&gt;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">      &lt;activation&gt;</span></span><br><span class="line"><span class="comment">        &lt;jdk&gt;1.4&lt;/jdk&gt;</span></span><br><span class="line"><span class="comment">      &lt;/activation&gt;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">      &lt;repositories&gt;</span></span><br><span class="line"><span class="comment">        &lt;repository&gt;</span></span><br><span class="line"><span class="comment">          &lt;id&gt;jdk14&lt;/id&gt;</span></span><br><span class="line"><span class="comment">          &lt;name&gt;Repository for JDK 1.4 builds&lt;/name&gt;</span></span><br><span class="line"><span class="comment">          &lt;url&gt;http://www.myhost.com/maven/jdk14&lt;/url&gt;</span></span><br><span class="line"><span class="comment">          &lt;layout&gt;default&lt;/layout&gt;</span></span><br><span class="line"><span class="comment">          &lt;snapshotPolicy&gt;always&lt;/snapshotPolicy&gt;</span></span><br><span class="line"><span class="comment">        &lt;/repository&gt;</span></span><br><span class="line"><span class="comment">      &lt;/repositories&gt;</span></span><br><span class="line"><span class="comment">    &lt;/profile&gt;</span></span><br><span class="line"><span class="comment">    --&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">     | Here is another profile, activated by the system property 'target-env' with a value of 'dev',</span></span><br><span class="line"><span class="comment">     | which provides a specific path to the Tomcat instance. To use this, your plugin configuration</span></span><br><span class="line"><span class="comment">     | might hypothetically look like:</span></span><br><span class="line"><span class="comment">     |</span></span><br><span class="line"><span class="comment">     | ...</span></span><br><span class="line"><span class="comment">     | &lt;plugin&gt;</span></span><br><span class="line"><span class="comment">     |   &lt;groupId&gt;org.myco.myplugins&lt;/groupId&gt;</span></span><br><span class="line"><span class="comment">     |   &lt;artifactId&gt;myplugin&lt;/artifactId&gt;</span></span><br><span class="line"><span class="comment">     |</span></span><br><span class="line"><span class="comment">     |   &lt;configuration&gt;</span></span><br><span class="line"><span class="comment">     |     &lt;tomcatLocation&gt;$&#123;tomcatPath&#125;&lt;/tomcatLocation&gt;</span></span><br><span class="line"><span class="comment">     |   &lt;/configuration&gt;</span></span><br><span class="line"><span class="comment">     | &lt;/plugin&gt;</span></span><br><span class="line"><span class="comment">     | ...</span></span><br><span class="line"><span class="comment">     |</span></span><br><span class="line"><span class="comment">     | <span class="doctag">NOTE:</span> If you just wanted to inject this configuration whenever someone set 'target-env' to</span></span><br><span class="line"><span class="comment">     |       anything, you could just leave off the &lt;value/&gt; inside the activation-property.</span></span><br><span class="line"><span class="comment">     |</span></span><br><span class="line"><span class="comment">    &lt;profile&gt;</span></span><br><span class="line"><span class="comment">      &lt;id&gt;env-dev&lt;/id&gt;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">      &lt;activation&gt;</span></span><br><span class="line"><span class="comment">        &lt;property&gt;</span></span><br><span class="line"><span class="comment">          &lt;name&gt;target-env&lt;/name&gt;</span></span><br><span class="line"><span class="comment">          &lt;value&gt;dev&lt;/value&gt;</span></span><br><span class="line"><span class="comment">        &lt;/property&gt;</span></span><br><span class="line"><span class="comment">      &lt;/activation&gt;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">      &lt;properties&gt;</span></span><br><span class="line"><span class="comment">        &lt;tomcatPath&gt;/path/to/tomcat/instance&lt;/tomcatPath&gt;</span></span><br><span class="line"><span class="comment">      &lt;/properties&gt;</span></span><br><span class="line"><span class="comment">    &lt;/profile&gt;</span></span><br><span class="line"><span class="comment">    --&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">profiles</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- activeProfiles</span></span><br><span class="line"><span class="comment">   | List of profiles that are active for all builds.</span></span><br><span class="line"><span class="comment">   |</span></span><br><span class="line"><span class="comment">  &lt;activeProfiles&gt;</span></span><br><span class="line"><span class="comment">    &lt;activeProfile&gt;alwaysActiveProfile&lt;/activeProfile&gt;</span></span><br><span class="line"><span class="comment">    &lt;activeProfile&gt;anotherAlwaysActiveProfile&lt;/activeProfile&gt;</span></span><br><span class="line"><span class="comment">  &lt;/activeProfiles&gt;</span></span><br><span class="line"><span class="comment">  --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">settings</span>&gt;</span></span><br></pre></td></tr></table></figure><p>稍微测试一下，连上了代理然后连接阿里云，如果有插件下载不下来再把阿里云的镜像地址注释掉。如此确保网络没有问题。</p><h4 id="框架的可视化部分"><a href="#框架的可视化部分" class="headerlink" title="框架的可视化部分"></a>框架的可视化部分</h4><p>对于可视化部分，需要用到node js，在我实际编译的过程中，如果不提前做好node.js的准备工作，很容易就会卡死在那，原因未知。</p><p>在Flink的安装过程中，会执行一次</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm ci --cache-max=0 --no-save</span><br></pre></td></tr></table></figure><p>应该提前在<code>flink-release-1.10.1\flink-runtime-web\web-dashboard</code>文件目录中执行一次，如果能够轻松执行成功的话说明ok</p><p>我遇到的问题：</p><p>首先我这条命令是执行不了的，执行到某一行命令，自动去github上面抓取某个<code>.node</code>文件，结果一直下载不下来，因为上面已经排除了网络原因，我自己打开那个链接找了一下发现那个网页已经换过了位置，自己手动下载下载之后，我使用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node XX.node</span><br></pre></td></tr></table></figure><p>命令手动装载，这条命令有没有执行效果我并不确定，因为后面我的npm大量报错，我进行了非常多的操作，不确定有没有重置这个操作。</p><p>出现的错误：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf9xv0euitj20sv13kn1u.jpg" alt="微信图片_20200530033900.png"></p><p>这个错误在我更新了个如下代码后得到缓解，之所以说缓解，稍后会解释。</p><p><a href="https://www.npmjs.com/package/@angular-devkit/build-angular" target="_blank" rel="noopener">首先查询到这个插件的最新版本</a>，然后在<code>flink-release-1.10.1\flink-runtime-web\web-dashboard</code>目录下执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall @angular-devkit/build-angular</span><br><span class="line">npm install @angular-devkit/build-angular@0.901.7</span><br></pre></td></tr></table></figure><p>同时可能用到的npm清缓存重新安装命令在这里附上</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rm -rf node_modules</span><br><span class="line">rm package-lock.json</span><br><span class="line">npm cache clear --force</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure><h2 id="开始编译"><a href="#开始编译" class="headerlink" title="开始编译"></a>开始编译</h2><h3 id="flink-fd-hadoop-shaded"><a href="#flink-fd-hadoop-shaded" class="headerlink" title="flink-fd-hadoop-shaded"></a>flink-fd-hadoop-shaded</h3><p>首先遇到的 <em>flink-shaded-hadoop-2</em> 模块在中央仓库找不到，后来发现官网已经进行了说明</p><p>进行编译之前根据需求在官方文档上面找到自己需要的内容：<a href="https://ci.apache.org/projects/flink/flink-docs-stable/flinkDev/building.html" target="_blank" rel="noopener">Building Flink From Source</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">If the used Hadoop version is not listed on the download page (possibly due to being a Vendor-specific version), then it is necessary to build flink-shaded against this version. You can find the source code for this project in the Additional Components section of the download page.</span><br></pre></td></tr></table></figure><p>这里有两种解决方式：</p><ol><li>自己去maven仓库下载一个版本相近的jar包回来，然后用安装命令安装到本地仓库，修改一下版本号即可，大多数情况下都能使用。这种方法很通用。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn install:install-file -DgroupId=org.apache.flink -DartifactId=flink-shaded-hadoop-2 -Dversion=2.7.6-9.0 -Dpackaging=jar  -Dfile=./flink-shaded-hadoop-2-2.7.5-7.0.jar</span><br></pre></td></tr></table></figure><ol start="2"><li>下载 <code>flink-shaded</code>包先进行编译打包，需要注意的是，会存在CDH版本等等不同的hadoop版本。</li></ol><p>因为涉及到不同的CDH版本的包，所以这里添加下面仓库，防止找不到需要的包。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">profile</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">id</span>&gt;</span>vendor-repos<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">activation</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>vendor-repos<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">activation</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Add vendor maven repositories --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">repositories</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Cloudera --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">id</span>&gt;</span>cloudera-releases<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repository.cloudera.com/artifactory/cloudera-repos<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">releases</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">releases</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">snapshots</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">enabled</span>&gt;</span>false<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Hortonworks --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">id</span>&gt;</span>HDPReleases<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>HDP Releases<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repo.hortonworks.com/content/repositories/releases/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">snapshots</span>&gt;</span><span class="tag">&lt;<span class="name">enabled</span>&gt;</span>false<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span><span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">releases</span>&gt;</span><span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span><span class="tag">&lt;/<span class="name">releases</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">id</span>&gt;</span>HortonworksJettyHadoop<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>HDP Jetty<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repo.hortonworks.com/content/repositories/jetty-hadoop<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">snapshots</span>&gt;</span><span class="tag">&lt;<span class="name">enabled</span>&gt;</span>false<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span><span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">releases</span>&gt;</span><span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span><span class="tag">&lt;/<span class="name">releases</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- MapR --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">id</span>&gt;</span>mapr-releases<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repository.mapr.com/maven/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">snapshots</span>&gt;</span><span class="tag">&lt;<span class="name">enabled</span>&gt;</span>false<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span><span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">releases</span>&gt;</span><span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span><span class="tag">&lt;/<span class="name">releases</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">profile</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>CDH示例：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn  clean install -DskipTests -Drat.skip=true -Pvendor-repos  -Dhadoop.version=2.6.0-cdh5.16.1</span><br></pre></td></tr></table></figure><p>新版本的Flink 这个模块都需要自己编译和hadoop适配的版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/apache/flink-shaded.git</span><br></pre></td></tr></table></figure><p>或者在release里面下载某个特定版本，这个特定版本是什么版本呢，在报错里面的后缀可以找到版本，这个版本号和Flinkd版本并不相同，需要注意。</p><p>我是使用git下载的，所以首先要配置好git的代理</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global http.proxy &apos;socks5://127.0.0.1:1080&apos; </span><br><span class="line">git config --global https.proxy &apos;socks5://127.0.0.1:1080&apos;</span><br></pre></td></tr></table></figure><p>下载完成后，进入文件夹</p><p>查看远程分支</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">git branch -a</span><br><span class="line">* master</span><br><span class="line">  remotes/origin/HEAD -&gt; origin/master</span><br><span class="line">  remotes/origin/master</span><br><span class="line">  remotes/origin/release-1.0</span><br><span class="line">  remotes/origin/release-10.0</span><br><span class="line">  remotes/origin/release-11.0</span><br><span class="line">  remotes/origin/release-3.0</span><br><span class="line">  remotes/origin/release-4.0</span><br><span class="line">  remotes/origin/release-5.0</span><br><span class="line">  remotes/origin/release-6.0</span><br><span class="line">  remotes/origin/release-7.0</span><br><span class="line">  remotes/origin/release-8.0</span><br><span class="line">  remotes/origin/release-9.0</span><br></pre></td></tr></table></figure><p>查看本地分支</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git branch</span><br><span class="line">* master</span><br></pre></td></tr></table></figure><p>查看分支详细信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -va</span><br></pre></td></tr></table></figure><p>拉下缺少对应版本的shade，并且建立名为<code>v0.9</code>的分支，并且以这个分支为基础编辑</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b v9.0 origin/release-9.0</span><br></pre></td></tr></table></figure><p>然后选择合适的hadooop版本，用上面的命令编译即可。</p><p>后面出了个<code>flink-shaded-hadoop-2-uber</code>出了个差不多的问题，但是因为没有找到这个项目，所以直接下载了一个，然后用上面提到的命令安装到了maven仓库里面。</p><p><strong>Node权限(参考 版本并非最新)</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cd ~</span><br><span class="line">wget https://npm.taobao.org/mirrors/node/v10.14.1/node-v10.14.1-linux-x64.tar.gz</span><br><span class="line">tar zxvf node-v10.14.1-linux-x64.tar.gz</span><br><span class="line">mv node-v10.14.1-linux-x64 node</span><br><span class="line">ln -s ~/node/bin/node /usr/local/bin/node   </span><br><span class="line">ln -s ~/node/bin/npm /usr/local/bin/npm</span><br><span class="line"><span class="meta">#</span></span><br><span class="line">npm install -g cnpm --registry=https://registry.npm.taobao.org</span><br><span class="line"><span class="meta">#</span></span><br><span class="line">alias cnpm="npm --registry=https://registry.npm.taobao.org \</span><br><span class="line">--cache=$HOME/.npm/.cache/cnpm \</span><br><span class="line">--disturl=https://npm.taobao.org/dist \</span><br><span class="line">--userconfig=$HOME/.cnpmrc"</span><br><span class="line"><span class="meta">#</span> 处理 npm 权限</span><br><span class="line">npm config -g set unsafe-perm</span><br></pre></td></tr></table></figure><p>测试</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 输入 </span><br><span class="line">npm </span><br><span class="line"><span class="meta">#</span> 显示如下 则环境正常</span><br><span class="line">Usage: npm &lt;command&gt;</span><br><span class="line">where &lt;command&gt; is one of:</span><br></pre></td></tr></table></figure><h3 id="Maven命令"><a href="#Maven命令" class="headerlink" title="Maven命令"></a>Maven命令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn clean install -Dfast -DskipTests -Pvendor-repos -Drat.skip=true -Pinclude-hadoop -Dhadoop.version=2.7.6 -Dmaven.compile.fork=true -Dscala-2.11 -T 2C</span><br></pre></td></tr></table></figure><p>windows powershell下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn clean install -DskipTests -Dfast -Pvendor-repos '-Drat.skip=true' -Pinclude-hadoop '-Dhadoop.version=2.7.6' '-Dmaven.compile.fork=true' '-Dscala-2.11 -T 8C'</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> -Dscala-2.11     # 指定scala的版本为2.11</span><br><span class="line"><span class="meta">#</span> -Pvendor-repos   # 使用cdh、hdp 的hadoop 需要添加该参数</span><br><span class="line"><span class="meta">#</span> -Dfast  #在flink根目录下pom.xml文件中fast配置项目中含快速设置,其中包含了多项构建时的跳过参数. #例如apache的文件头(rat)合法校验，代码风格检查，javadoc生成的跳过等，详细可阅读pom.xml</span><br><span class="line"><span class="meta">#</span> install maven的安装命令</span><br><span class="line"><span class="meta">#</span> -T2C #支持多处理器或者处理器核数参数,加快构建速度,推荐Maven3.3及以上</span><br><span class="line"><span class="meta">#</span> -Dhadoop.version=2.6.0-cdh5.7.0  指定 hadoop 的版本</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Apache Maven 编译打包Flink&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/bec9bff2gy1gf9x6qsh2lj20tk0fnta2.jpg&quot; alt=&quot;微信截图_20200530031106.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;给爷狠狠得Success&lt;/p&gt;
    
    </summary>
    
      <category term="Apache" scheme="http://yoursite.com/categories/Apache/"/>
    
      <category term="Maven" scheme="http://yoursite.com/categories/Apache/Maven/"/>
    
    
      <category term="Apache Maven" scheme="http://yoursite.com/tags/Apache-Maven/"/>
    
  </entry>
  
  <entry>
    <title>HiveSQL 行列转换</title>
    <link href="http://yoursite.com/2020/05/28/HiveSQL%E8%A1%8C%E5%88%97%E8%BD%AC%E6%8D%A2/"/>
    <id>http://yoursite.com/2020/05/28/HiveSQL行列转换/</id>
    <published>2020-05-28T03:45:59.069Z</published>
    <updated>2020-06-02T04:43:35.897Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>此中应用场景常见于特征值表</p></blockquote><a id="more"></a> <h1 id="HiveSQL-行列转换"><a href="#HiveSQL-行列转换" class="headerlink" title="HiveSQL 行列转换"></a>HiveSQL 行列转换</h1><h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p>特征值表：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf8058v9zwj20f0078mxe.jpg" alt="微信图片_20200528112630.png"></p><p>要求：表1 用hivesql变为表2 不能用union all 使用不止一种方法解</p><h3 id="UNION-ALL的解法"><a href="#UNION-ALL的解法" class="headerlink" title="UNION ALL的解法"></a>UNION ALL的解法</h3><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf86v1o38fj20xq0epwf0.jpg" alt="微信截图_20200528151916.png"></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">a, <span class="string">"k1"</span>,k1 <span class="keyword">as</span> sel</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">t_row_column</span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">a, <span class="string">"k2"</span>,k2 <span class="keyword">as</span> sel</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">t_row_column</span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">a, <span class="string">"k3"</span>,k3 <span class="keyword">as</span> sel</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">t_row_column</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">HIVE 的 UNION 和 UNION ALL</span><br><span class="line"></span><br><span class="line">UNION用于联合多个select语句的结果集，合并为一个独立的结果集，结果集去重。</span><br><span class="line"></span><br><span class="line">UNION ALL也是用于联合多个select语句的结果集。但是不能消除重复行。现在hive只支持UNION ALL。</span><br><span class="line"></span><br><span class="line">这里需要特别注意，每个select语句返回的列的数量和名字必须一样，同时字段类型必须完全匹配，否则会抛出语法错误。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">example</span><br><span class="line">例一：字段名完全一样</span><br><span class="line"></span><br><span class="line">select a,b,c from t1</span><br><span class="line"></span><br><span class="line">union all</span><br><span class="line"></span><br><span class="line">select a,b,c from t2</span><br><span class="line"></span><br><span class="line">例二：字段名前面有表名不一致，其他一致</span><br><span class="line"></span><br><span class="line">select t1.a,t2.b,t2.c from t1</span><br><span class="line"></span><br><span class="line">inner join t2 on t1.a = t2.a</span><br><span class="line"></span><br><span class="line">union all</span><br><span class="line"></span><br><span class="line">select t3.a,t4.b,t4.c from t3</span><br><span class="line"></span><br><span class="line">inner join t4 on t3.a = t4.a</span><br><span class="line"></span><br><span class="line">这两个例子都不报错</span><br><span class="line"></span><br><span class="line">但</span><br><span class="line"></span><br><span class="line">例三：第一个查询第二个字段重命名为k，与第二个查询字段名不一样了，此时会报错</span><br><span class="line"></span><br><span class="line">select a,&apos;&apos; as k,c from t1</span><br><span class="line"></span><br><span class="line">union all</span><br><span class="line"></span><br><span class="line">select a,b,c from t2</span><br><span class="line"></span><br><span class="line">会报编译错误</span><br><span class="line"></span><br><span class="line">编译错误：SemanticException The abstract syntax tree is null</span><br></pre></td></tr></table></figure><h3 id="使用行列转换SQL"><a href="#使用行列转换SQL" class="headerlink" title="使用行列转换SQL"></a>使用行列转换SQL</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">a,<span class="keyword">key</span>,<span class="keyword">value</span></span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">t_row_column</span><br><span class="line"><span class="keyword">LATERAL</span> <span class="keyword">VIEW</span></span><br><span class="line"><span class="keyword">explode</span>(<span class="keyword">map</span>(<span class="string">'k1'</span>,k1,<span class="string">'k2'</span>,k2,<span class="string">'k3'</span>,k3)) tmp</span><br><span class="line"><span class="keyword">as</span></span><br><span class="line"><span class="keyword">key</span>,<span class="keyword">value</span>;</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gfdug3wd4dj20xn0aiaab.jpg" alt="微信截图_20200602124207.png"></p><p><strong>建表语句</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_row_column (</span><br><span class="line">    a <span class="built_in">int</span>,</span><br><span class="line">    k1 <span class="built_in">int</span>,</span><br><span class="line">    k2 <span class="built_in">int</span>,</span><br><span class="line">    k3 <span class="built_in">int</span></span><br><span class="line">) </span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span>;</span><br></pre></td></tr></table></figure><h2 id="拓展知识"><a href="#拓展知识" class="headerlink" title="拓展知识"></a>拓展知识</h2><h3 id="collect-list-和-collect-set"><a href="#collect-list-和-collect-set" class="headerlink" title="collect_list 和 collect_set"></a>collect_list 和 collect_set</h3><p><strong>建表语句：</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_visit_video (</span><br><span class="line">    username <span class="keyword">string</span>,</span><br><span class="line">    video_name <span class="keyword">string</span></span><br><span class="line">) partitioned <span class="keyword">by</span> (<span class="keyword">day</span> <span class="keyword">string</span>)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span>;</span><br></pre></td></tr></table></figure><p><strong>文件内容：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">张三,大唐双龙传</span><br><span class="line">李四,天下无贼</span><br><span class="line">张三,神探狄仁杰</span><br><span class="line">李四,霸王别姬</span><br><span class="line">李四,霸王别姬</span><br><span class="line">王五,机器人总动员</span><br><span class="line">王五,放牛班的春天</span><br><span class="line">王五,盗梦空间</span><br></pre></td></tr></table></figure><p><strong>加载数据:</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> inpath <span class="string">'/tmp/visit.data'</span> <span class="keyword">into</span> <span class="keyword">table</span> t_visit_video</span><br></pre></td></tr></table></figure><p><strong>数据展示:</strong></p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf80b4ce9bj20xl0eoaah.jpg" alt="微信截图_20200528113224.png"></p><p><strong>按用户分组，取出每个用户每天看过的所有视频的名字：</strong></p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf80e2x6ozj20xb0avq3a.jpg" alt="微信截图_20200528113521.png"></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> username, collect_list(video_name)[<span class="number">0</span>] <span class="keyword">from</span> t_visit_video <span class="keyword">group</span> <span class="keyword">by</span> username;</span><br><span class="line"><span class="comment"># 这个结果稍微有一些问题，应为里面某个元素 霸王别姬出现了两次</span></span><br></pre></td></tr></table></figure><p><strong>优化：</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">username, collect_set(video_name)</span><br><span class="line"><span class="keyword">FROM</span> t_visit_video</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> username</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf80jehbtbj20ya0abq39.jpg" alt="微信截图_20200528114031.png"></p><p>如果希望第二列仅出现一个数值的话：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> username, collect_list(video_name)[<span class="number">0</span>] <span class="keyword">from</span> t_visit_video <span class="keyword">group</span> <span class="keyword">by</span> username;</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf80kx6kc3j20y50cdjrs.jpg" alt="微信截图_20200528114201.png"></p><h3 id="concat-和-concat-ws"><a href="#concat-和-concat-ws" class="headerlink" title="concat 和 concat_ws"></a>concat 和 concat_ws</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select concat(&apos;大&apos;,&apos;小&apos;) as size from 表</span><br><span class="line">查询出结果为：大小</span><br><span class="line">select concat(&apos;大&apos;, NULL) as size from 表</span><br><span class="line">查询出结果为：null</span><br><span class="line">concat中又一个参数为NULL，查出来的就为NULL</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select concat_ws(&apos;_&apos;,&apos;大&apos;,&apos;小&apos;,&apos;中&apos;) as size from 表</span><br><span class="line">查询出结果为：大_小_中</span><br><span class="line">select concat_ws(&apos;_&apos;,&apos;大&apos;,&apos;小&apos;,NULL) as size from 表</span><br><span class="line">查询出结果为：大_小</span><br></pre></td></tr></table></figure><h3 id="explode"><a href="#explode" class="headerlink" title="explode"></a>explode</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># explode有两种基本使用方式：</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">explode</span>(<span class="built_in">array</span>(<span class="string">'liubei'</span>,<span class="string">'zhangfei'</span>,<span class="string">'guanyu'</span>));</span><br><span class="line">+<span class="comment">-----------+--+</span></span><br><span class="line">|    col    |</span><br><span class="line">+<span class="comment">-----------+--+</span></span><br><span class="line">| liubei    |</span><br><span class="line">| zhangfei  |</span><br><span class="line">| guanyu    |</span><br><span class="line">+<span class="comment">-----------+--+</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">explode</span>(<span class="keyword">map</span>(<span class="string">'liubei'</span>,<span class="string">'18'</span>,<span class="string">'zhangfei'</span>,<span class="string">'19'</span>));</span><br><span class="line">+<span class="comment">-----------+--------+--+</span></span><br><span class="line">|    key    | value  |</span><br><span class="line">+<span class="comment">-----------+--------+--+</span></span><br><span class="line">| liubei    | 18     |</span><br><span class="line">| zhangfei  | 19     |</span><br><span class="line">+<span class="comment">-----------+--------+--+</span></span><br></pre></td></tr></table></figure><p>但是如果我们直接查询</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span>  movie，<span class="keyword">explode</span>(<span class="keyword">category</span>) <span class="keyword">from</span> movie_info;</span><br></pre></td></tr></table></figure><p>这样会报错，因为movie的查询结果只有三条，但是explode()出来有多条语句，两者数量无法对齐</p><p>那么，我们由此引入LATERAL VIEW函数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">LATERAL VIEW:</span><br><span class="line">1.Lateral View 用于和UDTF函数【explode,split】结合来使用。</span><br><span class="line">2.首先通过UDTF函数将数据拆分成多行，再将多行结果组合成一个支持别名的虚拟表。</span><br><span class="line">3.主要解决在select使用UDTF做查询的过程中查询只能包含单个UDTF，不能包含其它字段以及多个UDTF的情况。</span><br><span class="line">4.语法：LATERAL VIEW udtf(expression) tableAlias AS columnAlias (&apos;,&apos; columnAlias)</span><br></pre></td></tr></table></figure><p>示例：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> movie,category_name </span><br><span class="line"><span class="keyword">from</span> movie_info</span><br><span class="line"><span class="keyword">LATERAL</span> <span class="keyword">VIEW</span> <span class="keyword">explode</span>(<span class="keyword">category</span>) tmpTable <span class="keyword">as</span> category_name;</span><br><span class="line"><span class="comment">-- category_name 是给 explode(category) 列起的别名</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;此中应用场景常见于特征值表&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="SQL" scheme="http://yoursite.com/categories/SQL/"/>
    
      <category term="HiveSQL" scheme="http://yoursite.com/categories/SQL/HiveSQL/"/>
    
    
      <category term="SQL" scheme="http://yoursite.com/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>Flink CEP 文档</title>
    <link href="http://yoursite.com/2020/05/27/Flink%20CEP%E6%96%87%E6%A1%A3/"/>
    <id>http://yoursite.com/2020/05/27/Flink CEP文档/</id>
    <published>2020-05-27T09:39:24.147Z</published>
    <updated>2020-05-27T09:39:24.263Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>1.5版本</p></blockquote><a id="more"></a> <h1 id="Flink-CEP"><a href="#Flink-CEP" class="headerlink" title="Flink CEP"></a>Flink CEP</h1><h2 id="0-本文概述简介"><a href="#0-本文概述简介" class="headerlink" title="0. 本文概述简介"></a>0. 本文概述简介</h2><p>FlinkCEP是在Flink之上实现的复杂事件处理（CEP）库。 它允许你在无界的事件流中检测事件模式，让你有机会掌握数据中重要的事项。</p><p>本文描述了Flink CEP中可用的API调用。 首先介绍Pattern API，它允许你指定要在流中检测的模式，然后介绍如何检测匹配事件序列并对其进行操作。 然后，我们将介绍CEP库在处理事件时间延迟时所做的假设。</p><h2 id="1-入门"><a href="#1-入门" class="headerlink" title="1.入门"></a>1.入门</h2><p>首先是要在你的pom.xml文件中，引入CEP库。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-cep_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.5.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>注意要应用模式匹配的DataStream中的事件必须实现正确的equals（）和hashCode（）方法，因为FlinkCEP使用它们来比较和匹配事件。</p><p>第一个demo如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Event&gt; input = ...</span><br><span class="line"></span><br><span class="line">Pattern&lt;Event, ?&gt; pattern = Pattern.&lt;Event&gt;begin(<span class="string">"start"</span>).where(</span><br><span class="line">        <span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> event.getId() == <span class="number">42</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ).next(<span class="string">"middle"</span>).subtype(SubEvent.class).where(</span><br><span class="line">        <span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(SubEvent subEvent)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> subEvent.getVolume() &gt;= <span class="number">10.0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ).followedBy(<span class="string">"end"</span>).where(</span><br><span class="line">         <span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> event.getName().equals(<span class="string">"end"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">PatternStream&lt;Event&gt; patternStream = CEP.pattern(input, pattern);</span><br><span class="line"></span><br><span class="line">DataStream&lt;Alert&gt; result = patternStream.select(</span><br><span class="line">    <span class="keyword">new</span> PatternSelectFunction&lt;Event, Alert&gt; &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Alert <span class="title">select</span><span class="params">(Map&lt;String, List&lt;Event&gt;&gt; pattern)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> createAlertFrom(pattern);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h2 id="2-Pattern-API"><a href="#2-Pattern-API" class="headerlink" title="2.Pattern API"></a>2.Pattern API</h2><p>Pattern API允许你定义要从输入流中提取的复杂模式序列。</p><p>每个复杂模式序列都是由多个简单模式组成，即寻找具有相同属性的单个事件的模式。我们可以先定义一些简单的模式，然后组合成复杂的模式序列。 可以将模式序列视为此类模式的结构图，基于用户指定的条件从一个模式转换到下一个模式，例如， event.getName().equals(“start”)。 匹配是一系列输入事件，通过一系列有效的模式转换访问复杂模式图中的所有模式。</p><p>注意每个模式必须具有唯一的名称，以便后续可以使用该名称来标识匹配的事件。</p><p>注意模式名称不能包含字符“：”。</p><p>在本节接下来的部分，我们将首先介绍如何定义单个模式，然后如何将各个模式组合到复杂模式中。</p><h3 id="2-1-单个模式"><a href="#2-1-单个模式" class="headerlink" title="2.1 单个模式"></a>2.1 单个模式</h3><p>Pattern可以是单单个，也可以是循环模式。单个模式接受单个事件，而循环模式可以接受多个事件。在模式匹配符号中，模式“a b + c？d”（或“a”，后跟一个或多个“b”，可选地后跟“c”，后跟“d”），a，c ？，和d是单例模式，而b +是循环模式。 默认情况下，模式是单个模式，您可以使用Quantifiers将其转换为循环模式。每个模式可以有一个或多个条件，基于它接受事件。</p><h4 id="2-1-1-Quantifiers"><a href="#2-1-1-Quantifiers" class="headerlink" title="2.1.1 Quantifiers"></a>2.1.1 Quantifiers</h4><p>在FlinkCEP中，您可以使用以下方法指定循环模式：pattern.oneOrMore（），用于期望一个或多个事件发生的模式（例如之前提到的b +）;和pattern.times（#ofTimes）， 用于期望给定类型事件的特定出现次数的模式，例如4个;和patterntimes（#fromTimes，＃toTimes），用于期望给定类型事件的最小出现次数和最大出现次数的模式，例如， 2-4。</p><p>您可以使用pattern.greedy（）方法使循环模式变得贪婪，但是还不能使组模式变得贪婪。您可以使用pattern.optional（）方法使得所有模式，循环与否，变为可选。</p><p>对于名为start的模式，以下是有效的Quantifiers：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// expecting 4 occurrences</span></span><br><span class="line">start.times(<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0 or 4 occurrences</span></span><br><span class="line">start.times(<span class="number">4</span>).optional();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 2, 3 or 4 occurrences</span></span><br><span class="line">start.times(<span class="number">2</span>, <span class="number">4</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 2, 3 or 4 occurrences and repeating as many as possible</span></span><br><span class="line">start.times(<span class="number">2</span>, <span class="number">4</span>).greedy();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0, 2, 3 or 4 occurrences</span></span><br><span class="line">start.times(<span class="number">2</span>, <span class="number">4</span>).optional();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0, 2, 3 or 4 occurrences and repeating as many as possible</span></span><br><span class="line">start.times(<span class="number">2</span>, <span class="number">4</span>).optional().greedy();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 1 or more occurrences</span></span><br><span class="line">start.oneOrMore();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 1 or more occurrences and repeating as many as possible</span></span><br><span class="line">start.oneOrMore().greedy();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0 or more occurrences</span></span><br><span class="line">start.oneOrMore().optional();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0 or more occurrences and repeating as many as possible</span></span><br><span class="line">start.oneOrMore().optional().greedy();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 2 or more occurrences</span></span><br><span class="line">start.timesOrMore(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 2 or more occurrences and repeating as many as possible</span></span><br><span class="line">start.timesOrMore(<span class="number">2</span>).greedy();</span><br><span class="line"></span><br><span class="line"><span class="comment">// expecting 0, 2 or more occurrences and repeating as many as possible</span></span><br><span class="line">start.timesOrMore(<span class="number">2</span>).optional().greedy();</span><br></pre></td></tr></table></figure><h4 id="2-1-2-Conditions-条件"><a href="#2-1-2-Conditions-条件" class="headerlink" title="2.1.2 Conditions-条件"></a>2.1.2 Conditions-条件</h4><p>在每个模式中，从一个模式转到下一个模式，可以指定其他条件。您可以将使用下面这些条件：</p><ol><li>传入事件的属性，例如其值应大于5，或大于先前接受的事件的平均值。</li><li>匹配事件的连续性，例如检测模式a，b，c，序列中间不能有任何非匹配事件。</li></ol><h4 id="2-1-3-Conditions-on-Properties关于属性的条件"><a href="#2-1-3-Conditions-on-Properties关于属性的条件" class="headerlink" title="2.1.3 Conditions on Properties关于属性的条件"></a>2.1.3 Conditions on Properties关于属性的条件</h4><p>可以通过pattern.where（），pattern.or（）或pattern.until（）方法指定事件属性的条件。 条件可以是IterativeConditions或SimpleConditions。</p><ol><li><strong>迭代条件：</strong></li></ol><p>这是最常见的条件类型。 你可以指定一个条件，该条件基于先前接受的事件的属性或其子集的统计信息来接受后续事件。</p><p>下面代码说的是：如果名称以“foo”开头同时如果该模式的先前接受的事件的价格总和加上当前事件的价格不超过该值 5.0，则迭代条件接受名为“middle”的模式的下一个事件，。 迭代条件可以很强大的，尤其是与循环模式相结合，例如， oneOrMore()。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">middle.oneOrMore().where(<span class="keyword">new</span> IterativeCondition&lt;SubEvent&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(SubEvent value, Context&lt;SubEvent&gt; ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!value.getName().startsWith(<span class="string">"foo"</span>)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">double</span> sum = value.getPrice();</span><br><span class="line">        <span class="keyword">for</span> (Event event : ctx.getEventsForPattern(<span class="string">"middle"</span>)) &#123;</span><br><span class="line">            sum += event.getPrice();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> Double.compare(sum, <span class="number">5.0</span>) &lt; <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>注意对context.getEventsForPattern（…）的调用,将为给定潜在匹配项查找所有先前接受的事件。 此操作的代价可能会变化巨大，因此在使用条件时，请尽量减少其使用。</p><ol start="2"><li><strong>简单条件：</strong></li></ol><p>这种类型的条件扩展了前面提到的IterativeCondition类，并且仅根据事件本身的属性决定是否接受事件。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">start.where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> value.getName().startsWith(<span class="string">"foo"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>最后，还可以通过pattern.subtype（subClass）方法将接受事件的类型限制为初始事件类型的子类型。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">start.subtype(SubEvent.class).where(<span class="keyword">new</span> SimpleCondition&lt;SubEvent&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(SubEvent value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// some condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><ol start="3"><li><strong>组合条件：</strong></li></ol><p>如上所示，可以将子类型条件与其他条件组合使用。 这适用于所有条件。 您可以通过顺序调用where（）来任意组合条件。 最终结果将是各个条件的结果的逻辑AND。 要使用OR组合条件，可以使用or（）方法，如下所示。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">pattern.where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// some condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;).or(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ... <span class="comment">// or condition</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><ol start="4"><li><strong>停止条件：</strong></li></ol><p>在循环模式（oneOrMore()和oneOrMore().optional()）的情况下，还可以指定停止条件，例如： 接受值大于5的事件，直到值的总和小于50。</p><p>为了更好的理解，可以看看下面的例子：</p><p>给定模式：(a+ until b)，b之前，要出现一个或者多个a。</p><p>给定输入序列：a1，c，a2，b，a3</p><p>输出结果: {a1 a2}{a1}{a2}{a3}</p><p>可以看到{a1,a2,a3},{a2,a3}这两个并没有输出，这就是停止条件的作用。</p><ol start="5"><li><strong>连续事件条件</strong><br>FlinkCEP支持事件之间以下形式进行连续：</li></ol><p>严格连续性：希望所有匹配事件一个接一个地出现，中间没有任何不匹配的事件。</p><p>宽松连续性：忽略匹配的事件之间出现的不匹配事件。 不能忽略两个事件之间的匹配事件。</p><p>非确定性轻松连续性：进一步放宽连续性，允许忽略某些匹配事件的其他匹配。</p><p>为了解释上面的内容，我们举个例子。假如有个模式序列”a+ b”，输入序列”a1,c,a2,b”，不同连续条件下有不同的区别：</p><p>严格连续性：{a2 b} - 由于c的存在导致a1被废弃</p><p>宽松连续性：{a1,b}和{a1 a2 b} - c被忽略</p><p>非确定性宽松连续性：{a1 b}, {a2 b}, 和 {a1 a2 b}</p><p>对于循环模式（例如oneOrMore()和times()），默认是宽松的连续性。 如果你想要严格的连续性，你必须使用consecutive()显式指定它， 如果你想要非确定性的松弛连续性，你可以使用allowCombinations()方法。</p><p>注意在本节中，我们讨论的是单个循环模式中的连续性，并且需要在该上下文中理解consecutive()和allowCombinations()。 稍后在讲解组合模式时，我们将讨论其他方法，例如next（）和followedBy（），用于指定模式之间的连续条件。</p><h4 id="2-1-4-API简介"><a href="#2-1-4-API简介" class="headerlink" title="2.1.4 API简介"></a>2.1.4 API简介</h4><ol><li>where(condition)</li></ol><p>定义当前模式的条件。 为了匹配模式，事件必须满足条件。 多个连续的where()，其条件为AND：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pattern.where(new IterativeCondition&lt;Event&gt;() &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public boolean filter(Event value, Context ctx) throws Exception &#123;</span><br><span class="line">        return ... // some condition</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><ol start="2"><li>or(condition)</li></ol><p>添加与现有条件进行OR运算的新条件。 只有在至少通过其中一个条件时，事件才能匹配该模式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">pattern.where(new IterativeCondition&lt;Event&gt;() &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public boolean filter(Event value, Context ctx) throws Exception &#123;</span><br><span class="line">        return ... // some condition</span><br><span class="line">    &#125;</span><br><span class="line">&#125;).or(new IterativeCondition&lt;Event&gt;() &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public boolean filter(Event value, Context ctx) throws Exception &#123;</span><br><span class="line">        return ... // alternative condition</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><ol start="3"><li>until(condition)</li></ol><p>指定循环模式的停止条件。 意味着如果匹配给定条件的事件发生，则不再接受该模式中的事件。</p><p>仅适用于oneOrMore（）</p><p>注意：它允许在基于事件的条件下清除相应模式的状态。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pattern.oneOrMore().until(new IterativeCondition&lt;Event&gt;() &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public boolean filter(Event value, Context ctx) throws Exception &#123;</span><br><span class="line">        return ... // alternative condition</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><ol start="4"><li>subtype(subClass)</li></ol><p>定义当前模式的子类型条件。 如果事件属于此子类型，则事件只能匹配该模式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pattern.subtype(SubEvent.class);</span><br></pre></td></tr></table></figure><ol start="5"><li>oneOrMore()</li></ol><p>指定此模式至少发生一次匹配事件。</p><p>默认情况下，使用宽松的内部连续性。</p><p>注意：建议使用until（）或within（）来启用状态清除</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pattern.oneOrMore().until(new IterativeCondition&lt;Event&gt;() &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public boolean filter(Event value, Context ctx) throws Exception &#123;</span><br><span class="line">        return ... // alternative condition</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><ol start="6"><li>timesOrMore(#times)</li></ol><p>指定此模式至少需要#times次出现匹配事件。</p><p>默认情况下，使用宽松的内部连续性（在后续事件之间）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pattern.timesOrMore(2);</span><br></pre></td></tr></table></figure><ol start="7"><li>times(#ofTimes)</li></ol><p>指定此模式需要匹配事件的确切出现次数。</p><p>默认情况下，使用宽松的内部连续性（在后续事件之间）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pattern.times(2);</span><br></pre></td></tr></table></figure><ol start="8"><li>times(#fromTimes, #toTimes)</li></ol><p>指定此模式期望在匹配事件的#fromTimes次和#toTimes次之间出现。</p><p>默认情况下，使用宽松的内部连续性。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pattern.times(2, 4);</span><br></pre></td></tr></table></figure><ol start="9"><li>optional()</li></ol><p>指定此模式是可选的，即有可能根本不会发生。 这适用于所有上述量词。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pattern.oneOrMore().optional();</span><br></pre></td></tr></table></figure><ol start="10"><li>greedy()</li></ol><p>指定此模式是贪婪的，即它将尽可能多地重复。 这仅适用于quantifiers，目前不支持组模式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pattern.oneOrMore().greedy();</span><br></pre></td></tr></table></figure><ol start="11"><li>consecutive()</li></ol><p>与oneOrMore（）和times（）一起使用并在匹配事件之间强加严格的连续性，即任何不匹配的元素都会中断匹配。</p><p>如果不使用，则使用宽松的连续性（如followBy（））。</p><p>例如，这样的模式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Pattern.&lt;Event&gt;begin(&quot;start&quot;).where(new SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  @Override</span><br><span class="line">  public boolean filter(Event value) throws Exception &#123;</span><br><span class="line">    return value.getName().equals(&quot;c&quot;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line">.followedBy(&quot;middle&quot;).where(new SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  @Override</span><br><span class="line">  public boolean filter(Event value) throws Exception &#123;</span><br><span class="line">    return value.getName().equals(&quot;a&quot;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;).oneOrMore().consecutive()</span><br><span class="line">.followedBy(&quot;end1&quot;).where(new SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  @Override</span><br><span class="line">  public boolean filter(Event value) throws Exception &#123;</span><br><span class="line">    return value.getName().equals(&quot;b&quot;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>针对上面的模式，我们假如输入序列如：C D A1 A2 A3 D A4 B</p><p>使用consecutive：{C A1 B}, {C A1 A2 B}, {C A1 A2 A3 B}</p><p>不使用:{C A1 B}, {C A1 A2 B}, {C A1 A2 A3 B}, {C A1 A2 A3 A4 B}</p><ol start="12"><li>allowCombinations()</li></ol><p>与oneOrMore（）和times（）一起使用，并在匹配事件之间强加非确定性宽松连续性（如 followedByAny()）。</p><p>如果不应用，则使用宽松的连续性（如followBy()）。</p><p>例如,这样的模式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Pattern.&lt;Event&gt;begin(&quot;start&quot;).where(new SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  @Override</span><br><span class="line">  public boolean filter(Event value) throws Exception &#123;</span><br><span class="line">    return value.getName().equals(&quot;c&quot;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line">.followedBy(&quot;middle&quot;).where(new SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  @Override</span><br><span class="line">  public boolean filter(Event value) throws Exception &#123;</span><br><span class="line">    return value.getName().equals(&quot;a&quot;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;).oneOrMore().allowCombinations()</span><br><span class="line">.followedBy(&quot;end1&quot;).where(new SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">  @Override</span><br><span class="line">  public boolean filter(Event value) throws Exception &#123;</span><br><span class="line">    return value.getName().equals(&quot;b&quot;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>针对上面的模式，我们假如输入序列如：C D A1 A2 A3 D A4 B</p><p>使用allowCombinations：{C A1 B}, {C A1 A2 B}, {C A1 A3 B}, {C A1 A4 B}, {C A1 A2 A3 B}, {C A1 A2 A4 B}, {C A1 A3 A4 B}, {C A1 A2 A3 A4 B}</p><p>不使用:{C A1 B}, {C A1 A2 B}, {C A1 A2 A3 B}, {C A1 A2 A3 A4 B}</p><h3 id="2-2-组合模式"><a href="#2-2-组合模式" class="headerlink" title="2.2 组合模式"></a>2.2 组合模式</h3><h4 id="2-2-1-简介"><a href="#2-2-1-简介" class="headerlink" title="2.2.1 简介"></a>2.2.1 简介</h4><p>已经了解了单个模式的样子，现在是时候看看如何将它们组合成一个完整的模式序列。</p><p>模式序列必须以初始模式开始，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; start = Pattern.&lt;Event&gt;begin(&quot;start&quot;);</span><br></pre></td></tr></table></figure><p>接下来，您可以通过指定它们之间所需的连续条件，为模式序列添加更多模式。 在上一节中，我们描述了Flink支持的不同邻接模式，即严格，宽松和非确定性宽松，以及如何在循环模式中应用它们。 要在连续模式之间应用它们，可以使用：</p><blockquote><p>next() 对应 严格, followedBy() 对应 宽松连续性 followedByAny() 对应 非确定性宽松连续性</p></blockquote><p>亦或</p><blockquote><p>notNext() 如果不希望一个事件类型紧接着另一个类型出现。 notFollowedBy() 不希望两个事件之间任何地方出现该事件。</p></blockquote><blockquote><p>注意 模式序列不能以notFollowedBy（）结束。</p></blockquote><blockquote><p>注意 NOT模式前面不能有可选模式。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">// strict contiguity</span><br><span class="line">Pattern&lt;Event, ?&gt; strict = start.next(&quot;middle&quot;).where(...);</span><br><span class="line"></span><br><span class="line">// relaxed contiguity</span><br><span class="line">Pattern&lt;Event, ?&gt; relaxed = start.followedBy(&quot;middle&quot;).where(...);</span><br><span class="line"></span><br><span class="line">// non-deterministic relaxed contiguity</span><br><span class="line">Pattern&lt;Event, ?&gt; nonDetermin = start.followedByAny(&quot;middle&quot;).where(...);</span><br><span class="line"></span><br><span class="line">// NOT pattern with strict contiguity</span><br><span class="line">Pattern&lt;Event, ?&gt; strictNot = start.notNext(&quot;not&quot;).where(...);</span><br><span class="line"></span><br><span class="line">// NOT pattern with relaxed contiguity</span><br><span class="line">Pattern&lt;Event, ?&gt; relaxedNot = start.notFollowedBy(&quot;not&quot;).where(...);</span><br></pre></td></tr></table></figure><p>宽松连续性指的是仅第一个成功匹配的事件会被匹配到，然而非确定性宽松连续性，相同的开始会有多个匹配结果发出。距离，如果一个模式是”a b”，给定输入序列是”a c b1 b2”。对于不同连续性会有不同输出。</p><ol><li>a和b之间严格连续性，将会返回{},也即是没有匹配。因为c的出现导致a，抛弃了。</li><li>a和b之间宽松连续性，返回的是{a，b1},因为宽松连续性将会抛弃为匹配成功的元素，直至匹配到下一个要匹配的事件。</li><li>a和b之间非确定性宽松连续性，返回的是{a,b1},{a,b2}。</li></ol><p>也可以为模式定义时间约束。 例如，可以通过pattern.within（）方法定义模式应在10秒内发生。 时间模式支持处理和事件时间。 注意模式序列只能有一个时间约束。 如果在不同的单独模式上定义了多个这样的约束，则应用最小的约束。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">next.within(Time.seconds(10));</span><br></pre></td></tr></table></figure><p>可以为begin，followBy，followByAny和next定义一个模式序列作为条件。模式序列将被逻辑地视为匹配条件，而且将返回GroupPattern并且 可对GroupPattern使用oneOrMore（），times（#ofTimes），times（＃fromTimes，＃toTimes），optional（），consecutive（）， allowCombinations（）等方法。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">PatternPatte &lt;Event, ?&gt; start = Pattern.begin(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(&quot;start&quot;).where(...).followedBy(&quot;start_middle&quot;).where(...)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">// strict contiguity</span><br><span class="line">Pattern&lt;Event, ?&gt; strict = start.next(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(&quot;next_start&quot;).where(...).followedBy(&quot;next_middle&quot;).where(...)</span><br><span class="line">).times(3);</span><br><span class="line"></span><br><span class="line">// relaxed contiguity</span><br><span class="line">Pattern&lt;Event, ?&gt; relaxed = start.followedBy(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(&quot;followedby_start&quot;).where(...).followedBy(&quot;followedby_middle&quot;).where(...)</span><br><span class="line">).oneOrMore();</span><br><span class="line"></span><br><span class="line">// non-deterministic relaxed contiguity</span><br><span class="line">Pattern&lt;Event, ?&gt; nonDetermin = start.followedByAny(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(&quot;followedbyany_start&quot;).where(...).followedBy(&quot;followedbyany_middle&quot;).where(...)</span><br><span class="line">).optional();</span><br></pre></td></tr></table></figure><h4 id="2-2-2-API"><a href="#2-2-2-API" class="headerlink" title="2.2.2 API"></a>2.2.2 API</h4><ol><li>begin(#name)</li></ol><p>定义一个开始模式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; start = Pattern.&lt;Event&gt;begin(&quot;start&quot;);</span><br></pre></td></tr></table></figure><ol><li>begin(#pattern_sequence)</li></ol><p>定义一个开始模式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; start = Pattern.&lt;Event&gt;begin(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(&quot;start&quot;).where(...).followedBy(&quot;middle&quot;).where(...)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><ol><li>next(#name)</li></ol><p>追加一个新的模式。匹配事件必须直接跟着先前的匹配事件（严格连续性）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; next = start.next(&quot;middle&quot;);</span><br></pre></td></tr></table></figure><ol><li>next(#pattern_sequence)</li></ol><p>追加一个新的模式。匹配事件必须直接接着先前的匹配事件（严格连续性）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; next = start.next(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(&quot;start&quot;).where(...).followedBy(&quot;middle&quot;).where(...)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><ol><li>followedBy(#name)</li></ol><p>追加加新模式。 匹配事件和先前匹配事件（宽松连续）之间可能发生其他非匹配事件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; followedBy = start.followedBy(&quot;middle&quot;);</span><br></pre></td></tr></table></figure><ol><li>followedBy(#pattern_sequence)</li></ol><p>追加新模式。 匹配事件和先前匹配事件（宽松连续）之间可能发生其他非匹配事件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; followedBy = start.followedBy(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(&quot;start&quot;).where(...).followedBy(&quot;middle&quot;).where(...)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><ol><li>followedByAny(#name)</li></ol><p>添加新模式。 匹配事件和先前匹配事件之间可能发生其他事件，并且将针对每个备选匹配事件（非确定性放松连续性）呈现替代匹配：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; followedByAny = start.followedByAny(&quot;middle&quot;);</span><br></pre></td></tr></table></figure><ol><li>followedByAny(#pattern_sequence)</li></ol><p>添加新模式。 匹配事件和先前匹配事件之间可能发生其他事件，并且将针对每个备选匹配事件（非确定性放松连续性）呈现替代匹配：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; followedByAny = start.followedByAny(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(&quot;start&quot;).where(...).followedBy(&quot;middle&quot;).where(...)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><ol><li>notNext()</li></ol><p>添加新的否定模式。 匹配（否定）事件必须直接跟着先前的匹配事件（严格连续性）才能丢弃部分匹配：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; notNext = start.notNext(&quot;not&quot;);</span><br></pre></td></tr></table></figure><ol><li>notFollowedBy()</li></ol><p>追加一个新的否定模式匹配。即使在匹配（否定）事件和先前匹配事件（宽松连续性）之间发生其他事件，也将丢弃部分匹配事件序列：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; notFollowedBy = start.notFollowedBy(&quot;not&quot;);</span><br></pre></td></tr></table></figure><ol><li>within(time)</li></ol><p>定义事件序列进行模式匹配的最大时间间隔。 如果未完成的事件序列超过此时间，则将其丢弃：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pattern.within(Time.seconds(10));</span><br></pre></td></tr></table></figure><h3 id="2-3-匹配后的跳过策略"><a href="#2-3-匹配后的跳过策略" class="headerlink" title="2.3 匹配后的跳过策略"></a>2.3 匹配后的跳过策略</h3><p>对于给定模式，可以将同一事件分配给多个成功匹配。 要控制将分配事件的匹配数，需要指定名为AfterMatchSkipStrategy的跳过策略。 跳过策略有四种类型，如下所示：</p><ul><li>NO_SKIP：将发出每个可能的匹配。</li><li>SKIP_PAST_LAST_EVENT：丢弃包含匹配事件的每个部分匹配。</li><li>SKIP_TO_FIRST：丢弃包含PatternName第一个之前匹配事件的每个部分匹配。</li><li>SKIP_TO_LAST：丢弃包含PatternName最后一个匹配事件之前的每个部分匹配。</li></ul><p>请注意，使用SKIP_TO_FIRST和SKIP_TO_LAST跳过策略时，还应指定有效的PatternName。</p><p>例如，对于给定模式a b {2}和数据流ab1，ab2，ab3，ab4，ab5，ab6，这四种跳过策略之间的差异如下：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf7530gz4bj20oq0gktcy.jpg" alt="undefined"></p><p>要指定要使用的跳过策略，只需调用以下命令创建AfterMatchSkipStrategy：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf754c9zi6j20oi06uabd.jpg" alt="undefined"></p><p>使用方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">AfterMatchSkipStrategy skipStrategy = ...</span><br><span class="line">Pattern.begin(&quot;patternName&quot;, skipStrategy);</span><br></pre></td></tr></table></figure><h3 id="2-4-检测模式-Detecting-Patterns"><a href="#2-4-检测模式-Detecting-Patterns" class="headerlink" title="2.4 检测模式-Detecting Patterns"></a>2.4 检测模式-Detecting Patterns</h3><p>指定要查找的模式序列后，就可以将其应用于输入流以检测潜在匹配。 要针对模式序列运行事件流，必须创建PatternStream。 给定输入流 input，模式 pattern 和可选的比较器 comparator，用于在EventTime的情况下对具有相同时间戳的事件进行排序或在同一时刻到达，通过调用以下命令创建PatternStream：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Event&gt; input = ...</span><br><span class="line">Pattern&lt;Event, ?&gt; pattern = ...</span><br><span class="line">EventComparator&lt;Event&gt; comparator = ... // optional</span><br><span class="line"></span><br><span class="line">PatternStream&lt;Event&gt; patternStream = CEP.pattern(input, pattern, comparator);</span><br></pre></td></tr></table></figure><p>根据实际情况，创建的流可以是有key，也可以是无key的。</p><p>请注意，在无key的流上使用模式，将导致job的并行度为1。</p><h3 id="2-5-Selecting-from-Patterns"><a href="#2-5-Selecting-from-Patterns" class="headerlink" title="2.5 Selecting from Patterns"></a>2.5 Selecting from Patterns</h3><p>获得PatternStream后，您可以通过select或flatSelect方法从检测到的事件序列中进行查询。</p><p>select（）方法需要PatternSelectFunction的实现。 PatternSelectFunction具有为每个匹配事件序列调用的select方法。 它以Map &lt;String，List &gt;的形式接收匹配，其中key是模式序列中每个模式的名称，值是该模式的所有已接受事件的列表（IN是输入元素的类型）。 给定模式的事件按时间戳排序。 返回每个模式的接受事件列表的原因是当使用循环模式（例如oneToMany（）和times（））时，对于给定模式可以接受多个事件。 选择函数只返回一个结果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">class MyPatternSelectFunction&lt;IN, OUT&gt; implements PatternSelectFunction&lt;IN, OUT&gt; &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public OUT select(Map&lt;String, List&lt;IN&gt;&gt; pattern) &#123;</span><br><span class="line">        IN startEvent = pattern.get(&quot;start&quot;).get(0);</span><br><span class="line">        IN endEvent = pattern.get(&quot;end&quot;).get(0);</span><br><span class="line">        return new OUT(startEvent, endEvent);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>PatternFlatSelectFunction类似于PatternSelectFunction，唯一的区别是它可以返回任意数量的结果。 为此，select方法有一个额外的Collector参数，用于将输出元素向下游转发。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">class MyPatternFlatSelectFunction&lt;IN, OUT&gt; implements PatternFlatSelectFunction&lt;IN, OUT&gt; &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public void flatSelect(Map&lt;String, List&lt;IN&gt;&gt; pattern, Collector&lt;OUT&gt; collector) &#123;</span><br><span class="line">        IN startEvent = pattern.get(&quot;start&quot;).get(0);</span><br><span class="line">        IN endEvent = pattern.get(&quot;end&quot;).get(0);</span><br><span class="line"></span><br><span class="line">        for (int i = 0; i &lt; startEvent.getValue(); i++ ) &#123;</span><br><span class="line">            collector.collect(new OUT(startEvent, endEvent));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-6-处理超时部分模式"><a href="#2-6-处理超时部分模式" class="headerlink" title="2.6 处理超时部分模式"></a>2.6 处理超时部分模式</h3><p>每当模式具有通过within关键字附加的时间窗口长度时，部分事件序列可能因为超出时间窗口长度而被丢弃。 为了对这些超时的部分匹配作出相应的处理，select和flatSelect API调用允许指定超时处理程序。 为每个超时的部分事件序列调用此超时处理程序。 超时处理程序接收到目前为止由模式匹配的所有事件，以及检测到超时时的时间戳。</p><p>为了处理部分模式，select和flatSelect API提供了一个带参数的重载版本</p><ul><li>PatternTimeoutFunction/ PatternFlatTimeoutFunction。</li><li>OutputTag 超时的匹配将会在其中返回。</li><li>PatternSelectFunction / PatternFlatSelectFunction。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">PatternStreamPatte &lt;Event&gt; patternStream = CEP.pattern(input, pattern);</span><br><span class="line"></span><br><span class="line">OutputTag&lt;String&gt; outputTag = new OutputTag&lt;String&gt;(&quot;side-output&quot;)&#123;&#125;;</span><br><span class="line"></span><br><span class="line">SingleOutputStreamOperator&lt;ComplexEvent&gt; result = patternStream.select(</span><br><span class="line">    new PatternTimeoutFunction&lt;Event, TimeoutEvent&gt;() &#123;...&#125;,</span><br><span class="line">    outputTag,</span><br><span class="line">    new PatternSelectFunction&lt;Event, ComplexEvent&gt;() &#123;...&#125;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">DataStream&lt;TimeoutEvent&gt; timeoutResult = result.getSideOutput(outputTag);</span><br><span class="line"></span><br><span class="line">SingleOutputStreamOperator&lt;ComplexEvent&gt; flatResult = patternStream.flatSelect(</span><br><span class="line">    new PatternFlatTimeoutFunction&lt;Event, TimeoutEvent&gt;() &#123;...&#125;,</span><br><span class="line">    outputTag,</span><br><span class="line">    new PatternFlatSelectFunction&lt;Event, ComplexEvent&gt;() &#123;...&#125;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">DataStream&lt;TimeoutEvent&gt; timeoutFlatResult = flatResult.getSideOutput(outputTag);</span><br></pre></td></tr></table></figure><h3 id="2-7-事件事件模式下处理滞后数据"><a href="#2-7-事件事件模式下处理滞后数据" class="headerlink" title="2.7 事件事件模式下处理滞后数据"></a>2.7 事件事件模式下处理滞后数据</h3><p>在CEP中，元素处理的顺序很重要。为了保证在采用事件事件时以正确的顺序处理事件，最初将传入的事件放入缓冲区，其中事件基于它们的时间戳以升序排序， 并且当watermark到达时，处理该缓冲区中时间戳小于watermark时间的所有元素。这意味着watermark之间的事件按事件时间顺序处理。</p><p>请注意，在采用事件时间时，CEP library会假设watermark是正确的。</p><p>为了保证跨watermark的记录按照事件事件顺序处理，Flink的CEP库假定watermark是正确的，并将时间戳小于上次可见watermark的时间视为滞后事件。滞后事件不会被进一步处理。</p><h3 id="2-8-栗子"><a href="#2-8-栗子" class="headerlink" title="2.8 栗子"></a>2.8 栗子</h3><p>以下示例检测事件的带key数据流上的模式start，middle（name =“error”） - &gt; end（name =“critical”）。 事件的key是其id，并且有效模式必须在10秒内发生。 整个处理是用事件时间完成的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = ...</span><br><span class="line">env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);</span><br><span class="line"></span><br><span class="line">DataStream&lt;Event&gt; input = ...</span><br><span class="line"></span><br><span class="line">DataStream&lt;Event&gt; partitionedInput = input.keyBy(new KeySelector&lt;Event, Integer&gt;() &#123;</span><br><span class="line">@Override</span><br><span class="line">public Integer getKey(Event value) throws Exception &#123;</span><br><span class="line">return value.getId();</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">Pattern&lt;Event, ?&gt; pattern = Pattern.&lt;Event&gt;begin(&quot;start&quot;)</span><br><span class="line">.next(&quot;middle&quot;).where(new SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">@Override</span><br><span class="line">public boolean filter(Event value) throws Exception &#123;</span><br><span class="line">return value.getName().equals(&quot;error&quot;);</span><br><span class="line">&#125;</span><br><span class="line">&#125;).followedBy(&quot;end&quot;).where(new SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">@Override</span><br><span class="line">public boolean filter(Event value) throws Exception &#123;</span><br><span class="line">return value.getName().equals(&quot;critical&quot;);</span><br><span class="line">&#125;</span><br><span class="line">&#125;).within(Time.seconds(10));</span><br><span class="line"></span><br><span class="line">PatternStream&lt;Event&gt; patternStream = CEP.pattern(partitionedInput, pattern);</span><br><span class="line"></span><br><span class="line">DataStream&lt;Alert&gt; alerts = patternStream.select(new PatternSelectFunction&lt;Event, Alert&gt;() &#123;</span><br><span class="line">@Override</span><br><span class="line">public Alert select(Map&lt;String, List&lt;Event&gt;&gt; pattern) throws Exception &#123;</span><br><span class="line">return createAlert(pattern);</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;1.5版本&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Flink CEP" scheme="http://yoursite.com/categories/Flink-CEP/"/>
    
    
      <category term="Flink CEP" scheme="http://yoursite.com/tags/Flink-CEP/"/>
    
  </entry>
  
  <entry>
    <title>Flink Sabre</title>
    <link href="http://yoursite.com/2020/05/27/Flink%20Sabre/"/>
    <id>http://yoursite.com/2020/05/27/Flink Sabre/</id>
    <published>2020-05-27T08:42:25.448Z</published>
    <updated>2020-05-27T08:42:25.533Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Flink CEP在奇安信的拓展</p><p>此 Flink CEP 改版应用场景：安全检测和数据分析</p></blockquote><a id="more"></a> <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>自下而上分为四个业务处理流程，分别是数据的<strong>采集</strong>、<strong>解析</strong>、<strong>处理</strong>和<strong>展示</strong>结果，这其中<strong>最核心的是第三层数据处理</strong>。<strong>该产品的用户主要是安全规则团队</strong>，其可以<strong>使用规则编辑器来对安全规则进行添加、删除、编辑和查找操作</strong>，并可<strong>批量启动/停用多个规则</strong>，<strong>同时可以将处于启动状态的有效规则统一发送给产品</strong>。</p><p>在数据规模方面，<strong>产品解决的不是一个或几个大型数据集群的问题</strong>，<strong>而是数以百计的中小型数据集群的运维问题</strong>。在 B2B 领域，<strong>由于产品是直接部署到客户方</strong>，很多客户使用的是内部隔离网，无法连接外网，且没有专门人员负责集群的运维，这种情况下哪怕一个小升级都会耗费大量时间。因此，<strong>产品更多关注该领域下数据集群可运维性问题的解决</strong>。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf5tunz99ej20zk0igmyt.jpg" alt="undefined"></p><h2 id="痛点"><a href="#痛点" class="headerlink" title="痛点"></a>痛点</h2><h3 id="1-不能进行语义优化、不便于动态更新规则。"><a href="#1-不能进行语义优化、不便于动态更新规则。" class="headerlink" title="1.不能进行语义优化、不便于动态更新规则。"></a>1.不能进行语义优化、不便于动态更新规则。</h3><p>网络安全事件井喷式发生的今天，安全需求迅速扩展。为了能够在有限时间内对特定语义的快速支持，关联引擎的整体架构必须异常灵活，才能适应未来安全分析场景的各种需求，而基于开源关联引擎实现的产品会在激烈的需求变化时遇到很多问题。</p><h3 id="2-状态监控-amp-高可用支持不足。"><a href="#2-状态监控-amp-高可用支持不足。" class="headerlink" title="2.状态监控 &amp; 高可用支持不足。"></a>2.状态监控 &amp; 高可用支持不足。</h3><p>面向企业级的网络安全监测引擎具有一些特定需求，当前解决方案对此支持较差。</p><ul><li>比如，现实情况中客户对算子实例和 Taskmanager 概念较为模糊，真正关心的运行状态的基本单位是规则。Flink 监控页面显示的是算子实例及 Task manager 进程整体内存的运行状态，而在网络安全监控的业务场景中，对运行状态和资源的监控均需要细化到规则层面。</li><li>其次，在算子层面，Flink 原生 Window 算子，没有较好的资源（CPU / 内存）保护机制，且存在大量重复告警，不符合网络安全监测领域的业务需求。</li><li>再次，Flink 缺乏一些必要算子，例如不支持“不发生算子”。一个较为常见的应用场景，某条规则指定在较长时间内没收到某台服务器的系统日志，则认为此台服务器发生了异常，需要及时通知用户。</li></ul><h3 id="3-CEP-网络负载高、CPU-利用率低"><a href="#3-CEP-网络负载高、CPU-利用率低" class="headerlink" title="3.CEP 网络负载高、CPU 利用率低"></a>3.CEP 网络负载高、CPU 利用率低</h3><p>和互联网企业内部使用的大型集群相比，奇安信面向的企业级应用集群规模较小，硬件资源受限，且客户的定制需求较多，导致安全监测的规则要求更严格，引擎发布成本较高。但是，现有的 Flink 开源解决方案，或者需要根据业务需求进行改造，或者性能较差，均不能较好地解决上述问题。</p><ul><li>首先，原生 Flink 只提供了函数式编程模式，即需要手动编写复合特定业务需求的固定程序代码，由此导致开发测试周期较长，不便于动态更新规则，可复用性较弱，且不能从全局语义层面进行优化，性能较差。</li><li>其次，Flink-CEP 仅是一个受限的序列算子，在运行时需要将所有数据传输到 CEP 算子，然后在 CEP 算子中串行执行各个条件语句。这种汇集到单点的运行模式，较多的冗余数据需要执行条件匹配，由此产生了不必要的网络负载，而且降低了 CPU 利用率。</li><li>再次，还存在一些非官方开源的轻量级 CEP 引擎，比如 Flink-siddhi，功能简单，不是一个完整的解决方案。</li></ul><p>其他的痛点问题还包括不支持空值窗口出发、以及聚合不保存原始数据等。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf5u75m23tj20zk0imgng.jpg" alt="undefined"></p><h2 id="架构改动"><a href="#架构改动" class="headerlink" title="架构改动"></a>架构改动</h2><p>为了解决上述问题，奇安信在 Flink 的基础上推出了一种全新的 CEP 引擎， Sabre。其整体架构如下图所示，其中包含三大核心模块，左侧是<strong>配置端</strong>，中间是 <strong>Sabre-server</strong>，右侧是 <strong>Sabre 运行端</strong>。核心数据流存在两条主线，红线表示规则的<strong>提交</strong>、<strong>编译</strong>、<strong>发布</strong>和<strong>运行</strong>流程。绿线表示状态监控的<strong>生成</strong>、<strong>收集</strong>、<strong>统计</strong>和<strong>展示</strong>流程。如图所示，此架构与 Hive 极为相似，是一种通用的大数据 OLAP 系统架构。下面详细介绍三大核心模块和两大核心数据流。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf5ud5rdx7j22bb1av7d4.jpg" alt="undefined"></p><ul><li>首先，通过规则配置端创建规则，采用性能保护配置端修改性能保护策略；</li><li>然后，将任务所属的规则文件和性能保护策略文件一并推送到 Sabre-server 提供的 REST 接口，该接口会调用文件解析及优化方法构建规则有向无环图。</li><li>接着，执行词法语法分析方法，将规则有向无环图中各个节点的 EPL 转换为与其对应的 AST（AbstractSyntax Tree，抽象语法树），再将 AST 翻译为任务 java 代码。</li><li>最后，调用 maven 命令打包 java 代码为任务 jar 包，并将任务 jar 包及基础运行库一并提交到 Flink-on-YARN 集群。</li></ul><p><strong>Flink 有多种运行模式（例如 standalone Flink cluster、Flink cluster on YARN、Flink job on YARN 等）</strong>，Sabre 采用了“Flink job on YARN”模式，在奇安信 NGSOC 应用的特定场景下，采用 YARN 可统一维护硬件资源，并且使用 Flink job on YARN 可与 Hadoop 平台进行无缝对接，以此很好的实现了任务间资源隔离。</p><p>在 Sabre 任务执行过程中，<strong>Kafka 数据源向引擎提供原始事件</strong>。引擎处理结果分为回注事件和告警事件两类。告警事件会输出到目的 Kafka，供下级应用消费。回注事件表示一条规则的处理结果可直接回注到下级规则，作为下级规则的数据源事件，由此可实现规则的相互引用。</p><p>绿线流程表示任务执行过程中会定时输出节点的运行监控消息到 Sabre-server 的监控消息缓存器，然后监控消息统计器再汇总各个规则实例的运行监控消息，统计为整条规则的运行监控状态，最后通过 Sabre-server 提供的 REST 接口推送给规则监控端。</p><h3 id="组件依赖与版本"><a href="#组件依赖与版本" class="headerlink" title="组件依赖与版本"></a>组件依赖与版本</h3><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf5uupr3mdj20zk0k0q5i.jpg" alt="undefined"></p><ul><li>大多数情况下，奇安信会以黑盒的方式发布产品，但是如果用户方已经部署大数据处理平台，则产品会以 APP 的方式提供使用。</li><li>由于客户规模较大，项目种类较多，部署环境较为复杂，或者存在多种 Yarn 集群版本，或者 Sabre 需作为单一 Flink 应用发布到客户已部署的 Flink 集群。</li><li>如何节省成本及提高实施效率，快速适配上述复杂的部署环境是个亟需解决的问题，为此 Sabre 的设计原则是仅采用 Flink 的分布式计算能力，业务代码尽可能减少对 API 层的依赖，以便于兼容多种 Flink 版本。</li></ul><p>如图所示，Deploy、Core、APIs、Libraries 四层是大家熟知的 Flink 基本的组件栈。Sabre 对 API 层的依赖降到了最低，只引用了 DataStream、KeyedStream 和 SplitStream 三种数据流 API。函数依赖只包括 DataStream 的 assignTimestamps、flatMap、union、keyBy、split、process、addSink 等函数，KeyedStream 最基础的 process 函数，以及 SplitStream 的 select 函数。由于依赖的 Flink API 较少，Sabre 可以很容易适配到各个 Flink 版本，从而具有良好的 Flink 版本兼容性。</p><h3 id="重构"><a href="#重构" class="headerlink" title="重构"></a>重构</h3><p>在算子方面，Sabre 对 Flink 进行了一系列的重构，下图展示了这 Flink 和 Sabre 这二者之间的对比关系，其中主要包含三列，即 Flink 原生算子、Sabre 算子和两者之间的比较结果。比较结果主要有四种情况，相同（Same）、实现（Implement）、优化(优化)和新增（New）。Sabre 共有 13 种完全自研的核心算子，其中 Datasource、CustomKafkaSink 和 CustomDatabase 按照 Flink 接口要求做了具体实现，Filter、Key、Join 和 Aggregation 按照 Flink 原有算子的语义做了重新实现，CustomWindow 和 Sequence 在 Flink 原有算子语义的基础上做了优化实现。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf5uynys4oj20zk0k0ju4.jpg" alt="undefined"></p><p>下图展示了 Sabre 的规则与 EPL 设计。序列 Sequence、聚合 Aggregation、不发生 NotOccur、流式机器学习 StreamML 和连接 Join 均属于 Window 执行时间包含的计算性算子。蓝色虚线表示引用动态数据（Dynamic data），紫色虚线表示 Filter 无须经过 Window 可直连输出组件。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf5uyswqdej20zk0imdih.jpg" alt="undefined"></p><h3 id="windows算子"><a href="#windows算子" class="headerlink" title="windows算子"></a>windows算子</h3><p>众所周知，Join 和 Aggregation 的时间范围由 Window 限定，而 Flink 原有 Window 算子不适合网络安全监测需求，为此 Sabre 设计了一种“自定义 Window 算子”，且重新实现了与“自定义 Window 算子”相匹配的 Join 和 Aggregation 算子。全新的 Window 具有以下六个主要特点：</p><ul><li>实时触发、即刻匹配：其目的是为了满足自动化实时响应的需求，一旦告警发出，会及时触发响应；</li><li>匹配不重复：重复告警对于规则引擎来讲是一个常见问题，大量重复告警会增加安全人员的工作量，而该算子会将整个窗口与告警相关的事件全部清空，以此减少重复告警的数量；</li><li>纠正乱序：将 Window 窗口以特定单位为边界切成一个个的时间槽，一旦发现乱序情况，插入乱序事件时可直接定位时间槽，基于流式状态机进行局部计算，并且窗口事件超时，同步更新计算性算子的值，并入 count 算子，删除超时事件的同时，同步减少 count 值；</li><li>实时资源和状态监控：由于 Window 对与内存和 CPU 的影响比较大，因此需要对该类资源进行特别监控以及保护；</li><li>流量控制：主要是为了更好地保护下级应用。</li></ul><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf5vypwqujj20zk0gct9s.jpg" alt="undefined"></p><h3 id="Sequence-序列算子"><a href="#Sequence-序列算子" class="headerlink" title="Sequence 序列算子"></a>Sequence 序列算子</h3><p>Sabre 用 EPL 对 Flink CEP 实现的序列算子进行了重新设计，左边是 Flink CEP 官方代码展示，采用程序代码的方式拼凑“NFA 自动机”。右边是 Sabre 中 Sequence 算子的实现方式，其中包含了三个不同的 filter,通过正则表达式的使用来提升其表达的能力，并且，Sabre 将 filter 前置，无效事件不会传输到 window 算子，从而较少了不必要的网络负载。并且，只有较少的有效数据需要执行正则匹配，降低了 CPU 利用率（filter 可以并行）。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf5w0byssvj20zk0ipmys.jpg" alt="undefined"></p><h3 id="NotOccur-不发生算子"><a href="#NotOccur-不发生算子" class="headerlink" title="NotOccur 不发生算子"></a>NotOccur 不发生算子</h3><p>NotOccur 是 Sabre 在 Flink 基础上新增的一个算子，支持空事件触发。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf5w2ch3b9j20zk0hywg9.jpg" alt="undefined"></p><h3 id="Trigger-全局算子"><a href="#Trigger-全局算子" class="headerlink" title="Trigger 全局算子"></a>Trigger 全局算子</h3><p>Sabre 还实现了一种针对窗口的全局触发器 Trigger，Trigger 能够将多个子计算性算子组合为复杂表达式，并实现了具有GroupBy/Distinct 功能的 Key 算子以适配此 Trigger 算子。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf5w38hws1j20zk0ibdh9.jpg" alt="undefined"></p><h3 id="Dynamic-Data"><a href="#Dynamic-Data" class="headerlink" title="Dynamic Data"></a>Dynamic Data</h3><p>Dynamicdata 可以映射为数据库中的一个表，但是对这个表要进行特别的优化，具体来讲，如果一个事件的 IP 在威胁情报列表中，而这个威胁情报有可能比较长，比如十几万行甚至更长，这种情况下需要对该表数据结构进行优化以提升效率。Dynamic data 可以在其他算子中使用，如 Filter、Join 等。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf5w45t1kjj20zk0igmym.jpg" alt="undefined"></p><h3 id="流式统计与机器学习-StreamML"><a href="#流式统计与机器学习-StreamML" class="headerlink" title="流式统计与机器学习 StreamML"></a>流式统计与机器学习 StreamML</h3><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf5w8doz5uj20zk0igtad.jpg" alt="undefined"></p><p>机器学习在网络异常检测上已经越来越重要，为适应实时检测的需求，Sabre 没有使用 Flink MachineLearning，而是引入了自研的流式机器学习算子 StreamML。</p><p>Flink MachineLearning 是一种基于批模式 DataSetApi 实现的机器学习函数库，而 StreamML 是一种流式的机器学习算子，其目的是为了满足网络安全监测的特定需求。与阿里巴巴开源的 Alink 相比，StreamML 允许机器学习算法工程师通过配置规则的方式即可快速验证算法模型，无需编写任何程序代码。并且，流式机器学习算子 StreamML 实现了“模型训练/更新”与“模型使用”统一的理念。其核心功能是通过算法、技术及模型实现数据训练及对新数据检测。该流式机器学习算子 StreamML 引入的输入有三类，分别是：事件流、检测对象和对象属性；输出也包含三类，分别是：事件、告警和预警。</p><p>流式机器学习算子 StreamML 的组件栈包含三部分，从下往上依次为：机器学习方法、应用场景和产品业务。通过基本的机器学习算法（比如：统计学习算法、序列分析算法、聚类分析算法），流式机器学习算子 StreamML 可满足具体特定的安全监测应用场景（比如：行为特征异常检测、时间序列异常检测、群组聚类分析），进而为用户提供可理解的产品业务（比如：基线、用户及实体行为分析 UEBA）。</p><ul><li>行为特征异常检测：根据采集的样本数据（长时间）对统计分析对象建立行为基线，并以此基线为准，检测发现偏离正常行为模式的行为。例如：该用户通常从哪里发起连接？哪个运营商？哪个国家？哪个地区？这个用户行为异常在组织内是否为常见异常？</li><li>时间序列异常检测：根据某一个或多个统计属性，判断按时间顺序排列的数值序列是否异常，由此通过监测指标变化来发现安全事件。例如：监测某网站每小时的访问量以防止 DDOS 攻击；建模每个账号传输文件大小的平均值，检测出传输文件大小的平均值离群的账号。</li><li>群组聚类分析：对数据的特征属性间潜在相关性进行挖掘，将具有类似特征值的数据进行分组聚类。例如：该用户是否拥有任何特殊特征？可执行权限/特权用户？基于执行的操作命令和可访问的实体，来识别IT管理员、DBA 和其它高权限用户。</li></ul><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf5whemng3j20zk0igmym.jpg" alt="undefined"></p><p>因为采用了 Flink 作为底层运行组件，所以 Sabre 具有与 Flink 等同的执行性能。并且，针对网络安全监测领域的特定需求，Sabre 还在以下方面进行了性能优化：</p><ul><li>全局组件（数据源、动态表）引用优化。由于 Kafka 类型的数据源 topic 有限，而规则数量可动态扩展，导致多个规则会有极大概率共用同一个数据源，根据 EPL 语义等价原则合并相同的数据源，进而可以减少数据输入总量及线程总数。</li><li>全新的匹配引擎。序列 Sequence 算子采用了新颖的流式状态机引擎，复用了状态机缓存的状态，提升了匹配速度。类似优化还包含大规模 IP 匹配引擎和大规模串匹配引擎。在流量、日志中存在大规模 IP 和字符串匹配需求，通过 IP 匹配引擎和大规模串匹配引擎进行优化以提高效率。</li><li>表计算表达式优化。对于规则中引用的动态表，会根据表达式的具体特性构建其对应的最优计算数据结构，以避免扫描全表数据，进而确保了执行的时间复杂度为常量值。</li><li>自定义流式 Window 算子。采用“时间槽”技术实现了乱序纠正功能，并具有可以实时输出无重复、无遗漏告警的特性。</li><li>图上字段自动推导，优化事件结构。根据规则前后逻辑关系，推导出规则中标注使用的原始日志相关字段，无须输出所有字段，以此优化输出事件结构，减少了输出事件大小。</li><li>图上数据分区自动推导，优化流拓扑。由于特定的功能需要，Window 往往会缓存大量数据，以致消耗较多内存。通过对全局窗口 Hash 优化，避免所有全局窗口都分配到同一个 Taskmanager 进程，由此提高了引擎整体内存的利用率。</li></ul><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf5wi109c0j20zk0ikabf.jpg" alt="undefined"></p><p>上图是 Sabre 流式状态机引擎的表示，其主要负责的功能是序列匹配。图中左边是标准的正则引擎，通常的流程可以从 Pattern 到语法树到 NFA 再到 DFA，也可以从 Paterrn 直接到 NFA；图左下侧是一个正则表达式的 NFA 表示，右侧是该正则表达式的 DFA 表示，使用该 DFA 的时候进行了改进（如图中绿色线）。其目的是为了在出现乱序的时候提升处理性能，在乱序发生在正则表达式后半段的时候，该改进对于性能提升的效果最好。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf73cbq36rj20zk0ibgmm.jpg" alt="undefined"></p><p>大规模正则引擎主要使用了两种互补的方法（图上半侧和下半侧）。在将 NFA 转向 DFA 的时候，很多情况下是不成功的，这种情况下往往会生成 DFA 的半成品，称为Unfinished-DFA，第一种方法属于混合状态自动机，包含 NFA 和 DFA，其适用于Pattern 量少于 1000 的情况。而第二种方法适用于 Pattern 量大于 1000 甚至上万的情况，该方法中首先需要寻找锚点，再做匹配，以降低整体的时间复杂度。这两种方法相结合能够较好地解决大规模正则匹配的问题。</p><h3 id="产品运维"><a href="#产品运维" class="headerlink" title="产品运维"></a>产品运维</h3><h4 id="多级规则"><a href="#多级规则" class="headerlink" title="多级规则"></a>多级规则</h4><p>多级规则是产品运维的一个显著特点。如下图所示，为满足复杂场景需求，一种规则的输出可直接作为另一种规则的输入。通过这种规则拆分的方式，能分层构造较为复杂的“多级规则”。如：图中的“暴力探测”规则结果可以直接回注到下面的“登陆成功 ”规则，而无须额外的通信组件，由此实现更为复杂的“暴力破解”规则。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf73cylk82j20zk0gnab5.jpg" alt="undefined"></p><h4 id="服务化-多租户-资源监控"><a href="#服务化-多租户-资源监控" class="headerlink" title="服务化/多租户/资源监控"></a>服务化/多租户/资源监控</h4><p>产品采用微服务架构，使用多租户、多任务来满足多个规则引擎的使用场景，同时对资源进行了实时监控来保证系统的稳定运行。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf73e5qsfnj20zk0hlgmw.jpg" alt="undefined"></p><h4 id="规则级的状态-资源监控"><a href="#规则级的状态-资源监控" class="headerlink" title="规则级的状态/资源监控"></a>规则级的状态/资源监控</h4><p>规则级的状态和资源监控是非常重要的产品需求，产品采用分布式监控，提供三级分布式监控能力（用户、任务和规则），并支持吞吐量、EPS、CPU 和内存的监控。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf73eick1mj20zk0ieta4.jpg" alt="undefined"></p><h4 id="整体系统保护"><a href="#整体系统保护" class="headerlink" title="整体系统保护"></a>整体系统保护</h4><p>整体系统保护主要涉及两方面，即流量控制和自我保护。</p><ul><li>流量控制：为了增强 Sabre 引擎的健壮性，避免因规则配置错误，导致生成大量无效告警，在输出端做了流量控制，以更好地保护下级应用。当下级抗压能力较弱时（例如数据库），整个系统会做输出降级。</li><li>自我保护：跑在 JVM 上的程序，经常会遇到由于长时间 Full GC 导致 OOM 的错误，并且此时 CPU 占用率往往非常高，Flink 同样存在上述问题。自我保护功能采用了同时兼顾“Window隶属规则的优先级”及“Window引用规则数量”两个条件的加权算法，以此根据全局规则语义实现自动推导 Window 优先级，并根据此优先级确定各个 Window 的自我保护顺序。实时监控 CPU 及内存占用，当超过一定阈值时，智能优化事件分布，以防出现 CPU 长期过高或内存使用率过大而导致的 OOM 问题。</li></ul><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gf73euyybhj20zk0gwq46.jpg" alt="undefined"></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Flink CEP在奇安信的拓展&lt;/p&gt;
&lt;p&gt;此 Flink CEP 改版应用场景：安全检测和数据分析&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Flink CEP" scheme="http://yoursite.com/categories/Flink-CEP/"/>
    
    
      <category term="Flink CEP" scheme="http://yoursite.com/tags/Flink-CEP/"/>
    
  </entry>
  
  <entry>
    <title>Effective Java</title>
    <link href="http://yoursite.com/2020/05/23/EffectiveJava/"/>
    <id>http://yoursite.com/2020/05/23/EffectiveJava/</id>
    <published>2020-05-23T13:10:41.184Z</published>
    <updated>2020-05-23T13:42:25.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote></blockquote><p>摘录自《高效Java第四版》</p><a id="more"></a> <h1 id="Effective-Java"><a href="#Effective-Java" class="headerlink" title="Effective Java"></a>Effective Java</h1><h2 id="创建和销毁对象"><a href="#创建和销毁对象" class="headerlink" title="创建和销毁对象"></a>创建和销毁对象</h2><h3 id="【01】考虑以静态工厂方法代替构造函数"><a href="#【01】考虑以静态工厂方法代替构造函数" class="headerlink" title="【01】考虑以静态工厂方法代替构造函数"></a>【01】考虑以静态工厂方法代替构造函数</h3><p>demo:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Boolean <span class="title">valueOf</span><span class="params">(<span class="keyword">boolean</span> b)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> b ? Boolean.TRUE : Boolean.FALSE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>静态工厂方法与构造函数相比的第一个优点，静态工厂方法有确切名称。</strong></p><p><strong>静态工厂方法与构造函数相比的第二个优点，静态工厂方法不需要在每次调用时创建新对象。</strong></p><p><strong>静态工厂方法与构造函数相比的第三个优点，可以通过静态工厂方法获取返回类型的任何子类的对象。</strong></p><p><strong>静态工厂的第四个优点是，返回对象的类可以随调用的不同而变化，作为输入参数的函数。</strong></p><p><strong>静态工厂的第五个优点是，当编写包含方法的类时，返回对象的类不需要存在。</strong></p><p><strong>仅提供静态工厂方法的主要局限是，没有公共或受保护构造函数的类不能被子类化。</strong> </p><p><strong>静态工厂方法的第二个缺点是程序员很难找到它们。</strong></p><h3 id="【02】当构造函数有多个参数时，考虑改用Builder"><a href="#【02】当构造函数有多个参数时，考虑改用Builder" class="headerlink" title="【02】当构造函数有多个参数时，考虑改用Builder"></a>【02】当构造函数有多个参数时，考虑改用Builder</h3><p><strong>可伸缩构造函数模式可以工作，但是当有很多参数时，编写客户端代码是很困难的，而且读起来更困难。</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Builder Pattern</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NutritionFacts</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servingSize;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servings;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> calories;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> fat;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> sodium;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> carbohydrate;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Builder</span> </span>&#123;</span><br><span class="line">        <span class="comment">// Required parameters</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servingSize;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servings;</span><br><span class="line">        <span class="comment">// Optional parameters - initialized to default values</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> calories = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> fat = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> sodium = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> carbohydrate = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Builder</span><span class="params">(<span class="keyword">int</span> servingSize, <span class="keyword">int</span> servings)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.servingSize = servingSize;</span><br><span class="line">            <span class="keyword">this</span>.servings = servings;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Builder <span class="title">calories</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">            calories = val;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Builder <span class="title">fat</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">            fat = val;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Builder <span class="title">sodium</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">            sodium = val;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Builder <span class="title">carbohydrate</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">            carbohydrate = val;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> NutritionFacts <span class="title">build</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> NutritionFacts(<span class="keyword">this</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">NutritionFacts</span><span class="params">(Builder builder)</span> </span>&#123;</span><br><span class="line">        servingSize = builder.servingSize;</span><br><span class="line">        servings = builder.servings;</span><br><span class="line">        calories = builder.calories;</span><br><span class="line">        fat = builder.fat;</span><br><span class="line">        sodium = builder.sodium;</span><br><span class="line">        carbohydrate = builder.carbohydrate;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>NutritionFacts 类是不可变的，所有参数默认值都在一个位置。构建器的 setter 方法返回构建器本身，这样就可以链式调用，从而得到一个流畅的 API。下面是客户端代码的样子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">NutritionFacts cocaCola = <span class="keyword">new</span> NutritionFacts.Builder(<span class="number">240</span>, <span class="number">8</span>)</span><br><span class="line">    .calories(<span class="number">100</span>)</span><br><span class="line">    .sodium(<span class="number">35</span>)</span><br><span class="line">    .carbohydrate(<span class="number">27</span>)</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure><h3 id="【03】使用私有构造函数或枚举类型实施单例属性"><a href="#【03】使用私有构造函数或枚举类型实施单例属性" class="headerlink" title="【03】使用私有构造函数或枚举类型实施单例属性"></a>【03】使用私有构造函数或枚举类型实施单例属性</h3>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;/blockquote&gt;
&lt;p&gt;摘录自《高效Java第四版》&lt;/p&gt;
    
    </summary>
    
      <category term="Reading Note" scheme="http://yoursite.com/categories/Reading-Note/"/>
    
    
      <category term="Reading Note" scheme="http://yoursite.com/tags/Reading-Note/"/>
    
  </entry>
  
  <entry>
    <title>macOS安装Hadoop3</title>
    <link href="http://yoursite.com/2020/05/22/mac%E5%AE%89%E8%A3%85hadoop3/"/>
    <id>http://yoursite.com/2020/05/22/mac安装hadoop3/</id>
    <published>2020-05-22T10:29:38.591Z</published>
    <updated>2020-05-22T10:29:38.734Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Mac上的Hadoop一直没有安装。。。Flink总是跑在local模式上，实在不太好，于是在mac上面安装了Hadoop3，随便安装了一下，默认就是最新版本的，安装过程被zsh坑了不少，今后凡是安装模式，还是最好切换到原先的bash模式。</p></blockquote><a id="more"></a> <h1 id="macOS安装Hadoop3"><a href="#macOS安装Hadoop3" class="headerlink" title="macOS安装Hadoop3"></a>macOS安装Hadoop3</h1><h2 id="第一步是java环境"><a href="#第一步是java环境" class="headerlink" title="第一步是java环境"></a>第一步是java环境</h2><h3 id="bash环境"><a href="#bash环境" class="headerlink" title="bash环境"></a>bash环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">安装Java，配置环境变量</span><br><span class="line">打开vi ~/.bash_profile</span><br><span class="line">输入i在文件末尾添加export JAVA_HOME=$(/usr/libexec/java_home)，并按esc，输入:wq!保存。</span><br><span class="line">在~/目录下，执行source ~/.bash_profile</span><br></pre></td></tr></table></figure><h3 id="zsh"><a href="#zsh" class="headerlink" title="zsh"></a>zsh</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">zsh</span><br><span class="line"></span><br><span class="line">打开vi ~/.zshrc</span><br><span class="line">输入i在文件末尾添加export JAVA_HOME=$(/usr/libexec/java_home)，并按esc，输入:wq!保存。</span><br><span class="line">在~/目录下，执行source ~/.zshrc</span><br></pre></td></tr></table></figure><h3 id="ssh配置"><a href="#ssh配置" class="headerlink" title="ssh配置"></a>ssh配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">生成ssh公钥</span><br><span class="line">终端输入cat ~/.ssh/id_rsa.pub拷贝，cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">系统设置(System Preferences) -&gt; 共享(sharing) -&gt; 远程登录(Remote Login)</span><br><span class="line">终端测试ssh localhost</span><br></pre></td></tr></table></figure><h3 id="可能出现的错误"><a href="#可能出现的错误" class="headerlink" title="可能出现的错误"></a>可能出现的错误</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Q:host key verification failed</span><br><span class="line"></span><br><span class="line">A:cd ~/.ssh 然后rm known_hosts。随后出现Are you sure you want to continue connecting(yes/no)，输入yes</span><br><span class="line"></span><br><span class="line">Q：Warning:” Permission denied (publickey,password,keyboard-interactive)”</span><br><span class="line"></span><br><span class="line">A:cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys 若有多个秘钥，也需使用id_rsa.pub</span><br></pre></td></tr></table></figure><h3 id="安装安装配置Hadoop"><a href="#安装安装配置Hadoop" class="headerlink" title="安装安装配置Hadoop"></a>安装安装配置Hadoop</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">终端输入brew install hadoop，此时Hadoop被安装到/usr/local/Cellar/hadoop下。</span><br><span class="line"></span><br><span class="line">这边直接安装hadoop会下载一个openJDK14，我们需要修改一下jdk依赖，然后就可以卸载掉这个JDK</span><br><span class="line"></span><br><span class="line">若计算机原先安装前端框架yarn则会出现命名冲突name conflict，此时执行brew uninstall yarn即可</span><br><span class="line"></span><br><span class="line">终端输入cd $JAVA_HOME进入JDK目录，pwd查看JDK路径。</span><br><span class="line"></span><br><span class="line">更改Hadoop配置文件信息</span><br><span class="line"></span><br><span class="line">cd /usr/local/Cellar/hadoop</span><br><span class="line"></span><br><span class="line">ls查看Hadoop版本，本机为3.1.2</span><br><span class="line"></span><br><span class="line">cd /3.1.2/libexec/etc/hadoop</span><br><span class="line"></span><br><span class="line">用vscode打开open hadoop-env.sh，找到其中一行：</span><br><span class="line"></span><br><span class="line">export HADOOP_OPTS=&quot;$HADOOP_OPTS -Djava.net.preferIPv4Stack=true&quot;</span><br><span class="line"></span><br><span class="line">将其修改为：</span><br><span class="line"></span><br><span class="line">export HADOOP_OPTS=&quot;$HADOOP_OPTS -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc=&quot;</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=&quot;/Library/Java/JavaVirtualMachines/jdk1.8.0_211.jdk/Contents/Home&quot; #改为自己JDK目录</span><br></pre></td></tr></table></figure><h3 id="配置HDFS"><a href="#配置HDFS" class="headerlink" title="配置HDFS"></a>配置HDFS</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/Cellar/hadoop/3.1.2/libexec/etc/hadoop，打开open core-site.xml，填写&lt;configutation&gt;&lt;\configutation&gt;之间的内容。</span><br><span class="line"></span><br><span class="line">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><span class="line"> &lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/usr/local/Cellar/hadoop/hdfs/tmp&lt;/value&gt;</span><br><span class="line">      &lt;description&gt;A base for other temporary directories.&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;fs.default.name&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;hdfs://localhost:8020&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h3 id="设置MAP-REDUCE中JOBTRACKER的地址和端口号"><a href="#设置MAP-REDUCE中JOBTRACKER的地址和端口号" class="headerlink" title="设置MAP-REDUCE中JOBTRACKER的地址和端口号"></a>设置MAP-REDUCE中JOBTRACKER的地址和端口号</h3><p><code>cd /usr/local/Cellar/hadoop/3.1.2/libexec/etc/hadoop</code>，打开<code>mapred-site.xml</code>，填写<code>&lt;\configutation&gt;</code>之间的内容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">      &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapred.job.tracker&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;localhost:8021&lt;/value&gt;</span><br><span class="line">      &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h3 id="更改HDFS的默认备份方式-默认为3"><a href="#更改HDFS的默认备份方式-默认为3" class="headerlink" title="更改HDFS的默认备份方式(默认为3)"></a>更改HDFS的默认备份方式(默认为3)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/Cellar/hadoop/3.1.2/libexec/etc/hadoop，打开hdfs-site.xml，填写&lt;configutation&gt;&lt;\configutation&gt;之间的内容。</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">     &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h3 id="格式化新安装的HDFS"><a href="#格式化新安装的HDFS" class="headerlink" title="格式化新安装的HDFS"></a>格式化新安装的HDFS</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/Cellar/hadoop/3.1.2/libexec/etc/hadoop，在该目录下执行hdfs namenode -format</span><br><span class="line"></span><br><span class="line">查看控制台，若出现ERROR，则需检查配置文件内容是否出错。</span><br></pre></td></tr></table></figure><h3 id="启动后台程序"><a href="#启动后台程序" class="headerlink" title="启动后台程序"></a>启动后台程序</h3><p><code>cd /usr/local/Cellar/hadoop/3.1.2/sbin</code>，在该目录下执行以下命令：</p><ul><li><p><code>./start-dfs.sh</code> or <code>./stop-dfs.sh</code>启动或关闭hdfs</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Starting namenodes on [localhost]</span><br><span class="line">Starting datanodes</span><br><span class="line">Starting secondary namenodes [MacBook-Pro.local]</span><br><span class="line">2019-05-18 10:04:32,583 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br></pre></td></tr></table></figure><p>说明成功启动本地服务，此时在浏览器输入如下网址:<code>http://localhost:9870</code>，查看Resource Manager。(<strong>Hadoop版本不同，端口号也不同</strong>)</p></li><li><p><code>./start-yarn.sh</code> or <code>./stop-yarn.sh</code>启动或关闭yarn</p><p>JobTracker <code>http://localhost:8088</code></p><p>Specific Node Information <code>http://localhost:8042</code></p></li><li><p><code>./start-all.sh</code> or <code>./stop-all.sh</code>启动或关闭Hadoop，该命令可同时开启或关闭以上三个服务。</p></li></ul><h3 id="环境配置错误"><a href="#环境配置错误" class="headerlink" title="环境配置错误"></a>环境配置错误</h3><p>Error：Invalid HADOOP_COMMON_HOME</p><p>在<code>~/.bash_profile</code>里面配置环境变量HADOOP_COMMON_HOME<br><code>HADOOP_COMMON_HOME=$HADOOP_HOME</code>，HADOOP_HOME是配置的Hadoop的安装目录，修改完之后执行：source ~/.bash_profile</p><h3 id="其他错误"><a href="#其他错误" class="headerlink" title="其他错误"></a>其他错误</h3><p>输入命令时终端未响应=&gt;<code>ssh localhost</code></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Mac上的Hadoop一直没有安装。。。Flink总是跑在local模式上，实在不太好，于是在mac上面安装了Hadoop3，随便安装了一下，默认就是最新版本的，安装过程被zsh坑了不少，今后凡是安装模式，还是最好切换到原先的bash模式。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Apache" scheme="http://yoursite.com/categories/Apache/"/>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Apache/Hadoop/"/>
    
    
      <category term="macOS" scheme="http://yoursite.com/tags/macOS/"/>
    
  </entry>
  
  <entry>
    <title>数仓总览</title>
    <link href="http://yoursite.com/2020/05/11/%E6%95%B0%E4%BB%93%E6%80%BB%E8%A7%88/"/>
    <id>http://yoursite.com/2020/05/11/数仓总览/</id>
    <published>2020-05-11T06:39:48.127Z</published>
    <updated>2020-05-11T06:39:48.247Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>数仓要深入了解的话，可能还是得从那几本书入手，这里仅收入几篇经典的总览文，不包含之前已经收录过的美团数仓数据质量</p></blockquote><a id="more"></a> <h1 id="数据仓库介绍与实时数仓案例"><a href="#数据仓库介绍与实时数仓案例" class="headerlink" title="数据仓库介绍与实时数仓案例"></a>数据仓库介绍与实时数仓案例</h1><h2 id="1-数据仓库简介"><a href="#1-数据仓库简介" class="headerlink" title="1.数据仓库简介"></a>1.数据仓库简介</h2><p>数据仓库是一个面向主题的（Subject Oriented）、集成的（Integrate）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策。</p><p>数据仓库是伴随着企业信息化发展起来的，在企业信息化的过程中，随着信息化工具的升级和新工具的应用，数据量变的越来越大，数据格式越来越多，决策要求越来越苛刻，数据仓库技术也在不停的发展。</p><p>数据仓库的趋势：</p><p>实时数据仓库以满足实时化&amp;自动化决策需求；<br>大数据&amp;数据湖以支持大量&amp;复杂数据类型（文本、图像、视频、音频）；<br><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1geohhu6tncj20od0dv413.jpg" alt="undefined"></p><h2 id="2-数据仓库的发展"><a href="#2-数据仓库的发展" class="headerlink" title="2.数据仓库的发展"></a>2.数据仓库的发展</h2><p>数据仓库有两个环节：数据仓库的构建与数据仓库的应用。</p><p>早期数据仓库构建主要指的是把企业的业务数据库如ERP、CRM、SCM等数据按照决策分析的要求建模并汇总到数据仓库引擎中，其应用以报表为主，目的是支持管理层和业务人员决策（中长期策略型决策）。</p><p>随着业务和环境的发展，这两方面都在发生着剧烈变化。</p><p>随着IT技术走向互联网、移动化，数据源变得越来越丰富，在原来业务数据库的基础上出现了非结构化数据，比如网站log，IoT设备数据，APP埋点数据等，这些数据量比以往结构化的数据大了几个量级，对ETL过程、存储都提出了更高的要求；<br>互联网的在线特性也将业务需求推向了实时化，随时根据当前客户行为而调整策略变得越来越常见，比如大促过程中库存管理，运营管理等（即既有中远期策略型，也有短期操作型）；同时公司业务互联网化之后导致同时服务的客户剧增，有些情况人工难以完全处理，这就需要机器自动决策。比如欺诈检测和用户审核。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1geohi8sf82j20ou0e3q68.jpg" alt="undefined"></p><p>总结来看，对数据仓库的需求可以抽象成两方面：<strong>实时产生结果、处理和保存大量异构数据</strong>。</p><blockquote><p>注：这里不讨论数据湖技术。</p></blockquote><h2 id="3-数据仓库建设方法论"><a href="#3-数据仓库建设方法论" class="headerlink" title="3.数据仓库建设方法论"></a>3.数据仓库建设方法论</h2><h3 id="1）面向主题"><a href="#1）面向主题" class="headerlink" title="1）面向主题"></a>1）面向主题</h3><p>从公司业务出发，是分析的宏观领域，比如供应商主题、商品主题、客户主题和仓库主题</p><h3 id="2）为多维数据分析服务"><a href="#2）为多维数据分析服务" class="headerlink" title="2）为多维数据分析服务"></a>2）为多维数据分析服务</h3><p>数据报表；数据立方体，上卷、下钻、切片、旋转等分析功能。</p><h3 id="3）反范式数据模型"><a href="#3）反范式数据模型" class="headerlink" title="3）反范式数据模型"></a>3）反范式数据模型</h3><p>以事实表和维度表组成的星型数据模型</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1geohis0o2pj20i90hdgqb.jpg" alt="undefined"></p><blockquote><p>注：图片来自51CTO</p></blockquote><h2 id="4-数据仓库架构的演变"><a href="#4-数据仓库架构的演变" class="headerlink" title="4.数据仓库架构的演变"></a>4.数据仓库架构的演变</h2><p>数据仓库概念是Inmon于1990年提出并给出了完整的建设方法。随着互联网时代来临，数据量暴增，开始使用大数据工具来替代经典数仓中的传统工具。此时仅仅是工具的取代，架构上并没有根本的区别，可以把这个架构叫做离线大数据架构。</p><p>后来随着业务实时性要求的不断提高，人们开始在离线大数据架构基础上加了一个加速层，使用流处理技术直接完成那些实时性要求较高的指标计算，这便是Lambda架构。</p><p>再后来，实时的业务越来越多，事件化的数据源也越来越多，实时处理从次要部分变成了主要部分，架构也做了相应调整，出现了以实时事件处理为核心的Kappa架构。<br><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1geohjng8opj20h00hsgnb.jpg" alt="undefined"></p><h3 id="4-1离线大数据架构"><a href="#4-1离线大数据架构" class="headerlink" title="4.1离线大数据架构"></a>4.1离线大数据架构</h3><p>数据源通过离线的方式导入到离线数仓中。</p><p>下游应用根据业务需求选择直接读取DM或加一层数据服务，比如mysql 或 redis。</p><p>数据仓库从模型层面分为三层：</p><p>ODS，操作数据层，保存原始数据；<br>DWD，数据仓库明细层，根据主题定义好事实与维度表，保存最细粒度的事实数据；<br>DM，数据集市/轻度汇总层，在DWD层的基础之上根据不同的业务需求做轻度汇总；<br>典型的数仓存储是HDFS/Hive，ETL可以是MapReduce脚本或HiveSQL。<br><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1geohk0t0djj20mk0hndi2.jpg" alt="undefined"></p><h3 id="4-2-Lambda架构"><a href="#4-2-Lambda架构" class="headerlink" title="4.2 Lambda架构"></a>4.2 Lambda架构</h3><p>随着大数据应用的发展，人们逐渐对系统的实时性提出了要求，为了计算一些实时指标，就在原来离线数仓的基础上增加了一个实时计算的链路，并对数据源做流式改造（即把数据发送到消息队列），实时计算去订阅消息队列，直接完成指标增量的计算，推送到下游的数据服务中去，由数据服务层完成离线&amp;实时结果的合并。</p><p>注：流处理计算的指标批处理依然计算，最终以批处理为准，即每次批处理计算后会覆盖流处理的结果。（这仅仅是流处理引擎不完善做的折中）</p><h4 id="Lambda架构问题："><a href="#Lambda架构问题：" class="headerlink" title="Lambda架构问题："></a>Lambda架构问题：</h4><p>1.同样的需求需要开发两套一样的代码<br>这是Lambda架构最大的问题，两套代码不仅仅意味着开发困难（同样的需求，一个在批处理引擎上实现，一个在流处理引擎上实现，还要分别构造数据测试保证两者结果一致），后期维护更加困难，比如需求变更后需要分别更改两套代码，独立测试结果，且两个作业需要同步上线。<br>2.资源占用增多：同样的逻辑计算两次，整体资源占用会增多（多出实时计算这部分）</p><h3 id="4-3-Kappa架构"><a href="#4-3-Kappa架构" class="headerlink" title="4.3 Kappa架构"></a>4.3 Kappa架构</h3><p>Lambda架构虽然满足了实时的需求，但带来了更多的开发与运维工作，其架构背景是流处理引擎还不完善，流处理的结果只作为临时的、近似的值提供参考。后来随着Flink等流处理引擎的出现，流处理技术很成熟了，这时为了解决两套代码的问题，LickedIn 的Jay Kreps提出了Kappa架构</p><p>Kappa架构可以认为是Lambda架构的简化版（只要移除lambda架构中的批处理部分即可）。</p><p>在Kappa架构中，需求修改或历史数据重新处理都通过上游重放完成。</p><p>Kappa架构最大的问题是流式重新处理历史的吞吐能力会低于批处理，但这个可以通过增加计算资源来弥补。<br><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1geohl59dz3j20oh0hfjua.jpg" alt="undefined"></p><h4 id="Kappa架构的重新处理过程"><a href="#Kappa架构的重新处理过程" class="headerlink" title="Kappa架构的重新处理过程"></a>Kappa架构的重新处理过程</h4><p>重新处理是人们对Kappa架构最担心的点，但实际上并不复杂：</p><p>1.选择一个具有重放功能的、能够保存历史数据并支持多消费者的消息队列，根据需求设置历史数据保存的时长，比如Kafka，可以保存全部历史数据。<br>2.当某个或某些指标有重新处理的需求时，按照新逻辑写一个新作业，然后从上游消息队列的最开始重新消费，把结果写到一个新的下游表中。<br>3.当新作业赶上进度后，应用切换数据源，读取2中产生的新结果表。<br>4.停止老的作业，删除老的结果表。<br><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1geohljejt5j20lt065q4e.jpg" alt="undefined"></p><h3 id="4-4-Lambda架构与Kappa架构的对比"><a href="#4-4-Lambda架构与Kappa架构的对比" class="headerlink" title="4.4 Lambda架构与Kappa架构的对比"></a>4.4 Lambda架构与Kappa架构的对比</h3><p>对比项    Lambda架构    Kappa架构<br>实时性    实时    实时<br>计算资源    批和流同时运行，资源开销大    只有流处理，仅针对新需求开发阶段运行两个作业，资源开销小<br>重新计算时吞吐    批式全量处理，吞吐较高    流式全量处理，吞吐较批处理低<br>开发、测试    每个需求都需要两套不同代码，开发、测试、上线难度较大    只需实现一套代码，开发、测试、上线难度相对较小<br>运维成本    维护两套系统（引擎），运维成本大    只需维护一套系统（引擎），运维成本小<br>在真实的场景中，很多时候并不是完全规范的Lambda架构或Kappa架构，可以是两者的混合，比如大部分实时指标使用Kappa架构完成计算，少量关键指标（比如金额相关）使用Lambda架构用批处理重新计算，增加一次校对过程。（1）</p><p>Kappa架构并不是中间结果完全不落地，现在很多大数据系统都需要支持机器学习（离线训练），所以实时中间结果需要落地对应的存储引擎供机器学习使用，另外有时候还需要对明细数据查询，这种场景也需要把实时明细层写出到对应的引擎中。（2）参考后面的案例</p><p>另外，随着数据多样性的发展，数据仓库这种提前规定schema的模式显得越来难以支持灵活的探索&amp;分析需求，这时候便出现了一种数据湖技术，即把原始数据全部缓存到某个大数据存储上，后续分析时再根据需求去解析原始数据。简单的说，数据仓库模式是schema on write，数据湖模式是schema on read。（3）<br><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1geohlxfcxnj20ho0ngdiw.jpg" alt="undefined"></p><h2 id="5-实时数仓案例"><a href="#5-实时数仓案例" class="headerlink" title="5.实时数仓案例"></a>5.实时数仓案例</h2><p>菜鸟仓配实时数据仓库<br>本案例参考自菜鸟仓配团队的分享，涉及全局设计、数据模型、数据保障等几个方面。</p><p>注：特别感谢缘桥同学的无私分享。</p><h3 id="5-1-整体设计"><a href="#5-1-整体设计" class="headerlink" title="5.1 整体设计"></a>5.1 整体设计</h3><p>整体设计如右图，基于业务系统的数据，数据模型采用中间层的设计理念，建设仓配实时数仓；计算引擎，选择更易用、性能表现更佳的实时计算作为主要的计算引擎；数据服务，选择天工数据服务中间件，避免直连数据库，且基于天工可以做到主备链路灵活配置秒级切换；数据应用，围绕大促全链路，从活动计划、活动备货、活动直播、活动售后、活动复盘五个维度，建设仓配大促数据体系。<br><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1geohmaxiwvj20o70ftq5z.jpg" alt="undefined"></p><h3 id="5-2-数据模型"><a href="#5-2-数据模型" class="headerlink" title="5.2 数据模型"></a>5.2 数据模型</h3><p>不管是从计算成本，还是从易用性，还是从复用性，还是从一致性……，我们都必须避免烟囱式的开发模式，而是以中间层的方式建设仓配实时数仓。与离线中间层基本一致，我们将实时中间层分为两层。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1geohnzr8cdj20ki0alq5k.jpg" alt="undefined"></p><p><strong>第一层DWD公共实时明细层</strong></p><p>实时计算订阅业务数据消息队列，然后通过数据清洗、多数据源join、流式数据与离线维度信息等的组合，将一些相同粒度的业务系统、维表中的维度属性全部关联到一起，增加数据易用性和复用性，得到最终的实时明细数据。这部分数据有两个分支，一部分直接落地到ADS，供实时明细查询使用，一部分再发送到消息队列中，供下层计算使用；</p><p><strong>第二层DWS公共实时汇总层</strong></p><p>以数据域+业务域的理念建设公共汇总层，与离线数仓不同的是，这里汇总层分为轻度汇总层和高度汇总层，并同时产出，轻度汇总层写入ADS，用于前端产品复杂的olap查询场景，满足自助分析和产出报表的需求；高度汇总层写入Hbase，用于前端比较简单的kv查询场景，提升查询性能，比如实时大屏等；</p><p>注：</p><p>1.ADS是一款提供OLAP分析服务的引擎。开源提供类似功能的有，Elastic Search、Kylin、Druid等；<br>2.案例中选择把数据写入到Hbase供KV查询，也可根据情况选择其他引擎，比如数据量不多，查询压力也不大的话，可以用mysql<br>3.因主题建模与业务关系较大，这里不做描述</p><h3 id="5-3-数据保障"><a href="#5-3-数据保障" class="headerlink" title="5.3 数据保障"></a>5.3 数据保障</h3><p>集团每年都有双十一等大促，大促期间流量与数据量都会暴增。</p><p>实时系统要保证实时性，相对离线系统对数据量要更敏感，对稳定性要求更高。</p><p>所以为了应对这种场景，还需要在这种场景下做两种准备：</p><p>大促前的系统压测；<br>大促中的主备链路保障；<br><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1geohpiixpsj20mu0gljto.jpg" alt="undefined"></p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1geohpptwlsj20o10guad9.jpg" alt="undefined"></p><h2 id="6-实时数仓与离线数仓的对比"><a href="#6-实时数仓与离线数仓的对比" class="headerlink" title="6. 实时数仓与离线数仓的对比"></a>6. 实时数仓与离线数仓的对比</h2><p>  在看过前面的叙述与菜鸟案例之后，我们看一下实时数仓与离线数仓在几方面的对比：</p><p>首先，从架构上，实时数仓与离线数仓有比较明显的区别，实时数仓以Kappa架构为主，而离线数仓以传统大数据架构为主。Lambda架构可以认为是两者的中间态。</p><p>其次，从建设方法上，实时数仓和离线数仓基本还是沿用传统的数仓主题建模理论，产出事实宽表。另外实时数仓中实时流数据的join有隐藏时间语义，在建设中需注意。</p><p>最后，从数据保障看，实时数仓因为要保证实时性，所以对数据量的变化较为敏感。在大促等场景下需要提前做好压测和主备保障工作，这是与离线数据的一个较为明显的区别。</p><p>系列文章：</p><p><a href="https://mp.weixin.qq.com/s/FJBBmlSOj5Gq5ywo3M2TIQ" target="_blank" rel="noopener">数据仓库发展趋势与架构演进（1996-2020)</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=Mzg3NjIyNjQwMg==&amp;mid=2247483934&amp;idx=1&amp;sn=76b249d26aa2f726ea9c5310d2da9777&amp;chksm=cf343013f843b9056a718ba64b181ee1c6400781ddf747ce38d2c2058b57347bca08275b107c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">系列 | 漫谈数仓第一篇NO.1 『基础架构』</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=Mzg3NjIyNjQwMg==&amp;mid=2247483973&amp;idx=1&amp;sn=3e5aecbdb26c312b21ae9073cdb0345b&amp;chksm=cf343048f843b95e7a1b3cbcbcb832e3bde9ca416025107b053b7e05319261fde7212ee6302a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">系列 | 漫谈数仓第二篇NO.2 数据模型（维度建模）</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=Mzg3NjIyNjQwMg==&amp;mid=2247484034&amp;idx=1&amp;sn=6a77c2d5c1f09ad87c10f045cedfaa21&amp;chksm=cf34308ff843b999f87ba9b0bc89fec52173b06e7f9e0f70b07430d603c99593f23c6ca75e12&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">系列 | 漫谈数仓第三篇NO.3 『数据魔法』ETL</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=Mzg3NjIyNjQwMg==&amp;mid=2247484163&amp;idx=1&amp;sn=f90ff0031e419853948ddaf75db48642&amp;chksm=cf34310ef843b818956ee1a99edf6be754758dd2a0a90a590b95844d72ee6c75afc6215d645a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">系列 | 漫谈数仓第四篇NO.4 『数据应用』（BI&amp;OLAP）</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=Mzg3NjIyNjQwMg==&amp;mid=2247485171&amp;idx=1&amp;sn=b0ecff938e7236325f2c9d3cdbfcbca0&amp;chksm=cf3434fef843bde88d868aa5952ed043764637513dbde6e6df0a2cb6e62e6c3d006e041f35ed&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">企业数据治理七把利剑</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;数仓要深入了解的话，可能还是得从那几本书入手，这里仅收入几篇经典的总览文，不包含之前已经收录过的美团数仓数据质量&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
      <category term="数仓" scheme="http://yoursite.com/categories/Hadoop/%E6%95%B0%E4%BB%93/"/>
    
    
      <category term="数仓总览" scheme="http://yoursite.com/tags/%E6%95%B0%E4%BB%93%E6%80%BB%E8%A7%88/"/>
    
  </entry>
  
  <entry>
    <title>Java高并发</title>
    <link href="http://yoursite.com/2020/05/11/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    <id>http://yoursite.com/2020/05/11/java多线程与高并发/</id>
    <published>2020-05-11T06:02:56.661Z</published>
    <updated>2020-05-11T06:02:56.801Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>此处暂时收集一些常见的面试题，以后针对这块的收集从此处延伸下去并补全</p></blockquote><a id="more"></a> <p>（1）synchronized的CPU原语级别是如何实现的？</p><p>（2）<strong>无锁、偏向锁、轻量级锁、重量级锁</strong>有什么差别，升级过程如何？</p><p>（3）<strong>线程</strong>间通信，<strong>同机器进程</strong>间通信，<strong>跨机器进程</strong>间通信，各有什么方法？</p><p>（4）下列三种业务，应该如何使用线程池：</p><ul><li><strong>高并发、任务执行时间短</strong>的业务</li><li><strong>并发不高、任务执行时间长</strong>的业务</li><li><strong>并发高、业务执行时间长</strong>的业务</li></ul><p>（5）秒杀系统，如何能够撑住100W级别TPS（淘宝最高54万TPS）？</p><p>下面是某网课的内容，笑笑就好</p><p>1、synchronized关键字的字节码原语；</p><p>2、volatile关键字的字节码原语；</p><p>3、synchronized与volatile的硬件级实现；</p><p>4、无锁、偏向锁、轻量级锁、重量级锁的升级过程；</p><p>5、内存屏障的基本概念；</p><p>6、JVM规范如何要求内存屏障；</p><p>7、硬件层级内存屏障如何帮助java实现高并发；</p><p>8、面试第3题（线程间通讯）的8种解法；</p><p>9、作业；</p><p>1、线程池的学与思；</p><p>2、使用线程池的好与不好；</p><p>3、为什么阿里开发手册建议自定义线程池；</p><p>4、自定义线程池的最佳实践；</p><p>5、常见线程池类型与应用场景：</p><p>   1）CachedPool</p><p>   2）FixedThreadPool</p><p>   3）ScheduledPool</p><p>   4）WorkStealingPool</p><p>   5）ForkJoinPool</p><p>6、比线程更牛X的线程，压测结果展现纤程的威力；</p><p>7、总结；</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;此处暂时收集一些常见的面试题，以后针对这块的收集从此处延伸下去并补全&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="java" scheme="http://yoursite.com/categories/java/"/>
    
    
      <category term="多线程与高并发" scheme="http://yoursite.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>美团数据质量监管平台实践</title>
    <link href="http://yoursite.com/2020/05/07/%E7%BE%8E%E5%9B%A2%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F/"/>
    <id>http://yoursite.com/2020/05/07/美团数据质量/</id>
    <published>2020-05-07T10:20:59.401Z</published>
    <updated>2020-05-07T10:29:23.888Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>数据质量干货中的干货</p></blockquote><p> <a href="https://tech.meituan.com/2018/03/21/mtdp-dataman.html" target="_blank" rel="noopener">DataMan-美团旅行数据质量监管平台实践</a></p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gek26x62b7j20ao0ar74e.jpg" alt="undefined"></p><a id="more"></a> <h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>数据，已经成为互联网企业非常依赖的新型重要资产。数据质量的好坏直接关系到信息的精准度，也影响到企业的生存和竞争力。Michael Hammer（《Reengineering the Corporation》一书的作者）曾说过，看起来不起眼的数据质量问题，实际上是拆散业务流程的重要标志。 数据质量管理是测度、提高和验证质量，以及整合组织数据的方法等一套处理准则，而体量大、速度快和多样性的特点，决定了大数据质量所需的处理，有别于传统信息治理计划的质量管理方式。</p><p>本文将基于美团点评大数据平台，通过对数据流转过程中各阶段数据质量检测结果的采集分析、规则引擎、评估反馈和再监测的闭环管理过程出发，从面临挑战、建设思路、技术方案、呈现效果及总结等方面，介绍美团平台酒旅事业群（以下简称美旅）数据质量监管平台DataMan的搭建思路和建设实践。</p><h2 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h2><p>美旅数据中心日均处理的离线和实时作业高达数万量级， 如何更加合理、高效的监控每类作业的运行状态，并将原本分散、孤岛式的监控日志信息通过规则引擎集中共享、关联、处理；洞察关键信息，形成事前预判、事中监控、事后跟踪的质量管理闭环流程；沉淀故障问题，搭建解决方案的知识库体系。在数据质量监管平台的规划建设中，面临如下挑战：</p><ul><li>缺乏统一监控视图，离线和实时作业监控分散，影响性、关联性不足。</li><li>数据质量的衡量标准缺失，数据校验滞后，数据口径不统一。</li><li>问题故障处理流程未闭环，“点”式解决现象常在；缺乏统一归档，没有形成体系的知识库。</li><li>数据模型质量监控缺失，模型重复，基础模型与应用模型的关联度不足，形成信息孤岛。</li><li>数据存储资源增长过快，不能监控细粒度资源内容。</li></ul><p>DataMan质量监管平台研发正基于此，以下为具体建设方案。</p><h2 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h2><h3 id="整体框架"><a href="#整体框架" class="headerlink" title="整体框架"></a>整体框架</h3><p>构建美旅大数据质量监控平台，从可实践运用的视角出发，整合平台资源、技术流程核心要点，重点着力平台支持、技术控制、流程制度、知识体系形成等方向建设，确保质量监控平台敏捷推进落地的可行性。数据质量监控平台整体框架如图1所示：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gek27gduukj219k10sgpi.jpg" alt="undefined"></p><h3 id="建设方法"><a href="#建设方法" class="headerlink" title="建设方法"></a>建设方法</h3><p>以数据质量检核管理PDCA方法论，基于美团大数据平台，对数据质量需求和问题进行全质量生命周期的管理，包括质量问题的定义、检核监控、发现分析、跟踪反馈及知识库沉淀。数据质量PDCA流程图如图2所示：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gek27y11kbj21eq0loacq.jpg" alt="undefined"></p><p><strong>关键流程：</strong></p><p>质量监管平台建设实践应用及价值体现，离不开管理流程、技术实现和组织人员的紧密结合，主要包含如下8大流程步骤：</p><ol><li>质量需求：发现数据问题；信息提报、收集需求；检核规则的需求等。</li><li>提炼规则：梳理规则指标、确定有效指标、检核指标准确度和衡量标准。</li><li>规则库构建：检核对象配置、调度配置、规则配置、检核范围确认、检核标准确定等。</li><li>执行检核：调度配置、调度执行、检核代码。</li><li>问题检核：检核问题展示、分类、质量分析、质量严重等级分类等。</li><li>分析报告：数据质量报告、质量问题趋势分析，影响度分析，解决方案达成共识。</li><li>落实处理：方案落实执行、跟踪管理、解决方案Review及标准化提炼。</li><li>知识库体系形成：知识经验总结、标准方案沉淀、知识库体系建设。</li></ol><h3 id="质量检核标准"><a href="#质量检核标准" class="headerlink" title="质量检核标准"></a>质量检核标准</h3><ul><li>完整性：主要包括实体缺失、属性缺失、记录缺失和字段值缺失四个方面；</li><li>准确性：一个数据值与设定为准确的值之间的一致程度，或与可接受程度之间的差异；</li><li>合理性：主要包括格式、类型、值域和业务规则的合理有效；</li><li>一致性：系统之间的数据差异和相互矛盾的一致性，业务指标统一定义，数据逻辑加工结果一致性；</li><li>及时性：数据仓库ETL、应用展现的及时和快速性，Jobs运行耗时、运行质量、依赖运行及时性。</li></ul><p>大数据平台下的质量检核标准更需考虑到大数据的快变化、多维度、定制化及资源量大等特性，如数仓及应用BI系统的质量故障等级分类、数据模型热度标准定义、作业运行耗时标准分类等和数仓模型逻辑分层及主题划分组合如下图3所示。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gek287x6r7j21j00sagoa.jpg" alt="undefined"></p><p>美旅数仓划分为客服、流量、运营、订单、门店、产品、参与人、风控、结算和公用等十大主题，按Base、Fact、Topic、App逻辑分层，形成体系化的物理模型。从数据价值量化、存储资源优化等指标评估，划分物理模型为热、温、冷、冰等四类标准，结合应用自定义其具体标准范围，实现其灵活性配置；作业运行耗时分为：优、良、一般、关注、耗时等，每类耗时定义的标准范围既符合大数据的特性又可满足具体分析需要，且作业耗时与数仓主题和逻辑分层深度整合，实现多角度质量洞察评估；针对数万的作业信息从数据时效性、作业运行等级、服务对象范围等视角，将其故障等级分为：</p><ul><li>S1：严重度极高；</li><li>S2：严重度高；</li><li>S3：严重度中；</li><li>S4：严重度低等四项标准。</li></ul><p>各项均对应具体的实施策略。整体数据质量的检核对象包括离线数仓和实时数据。</p><h3 id="监管核心点"><a href="#监管核心点" class="headerlink" title="监管核心点"></a>监管核心点</h3><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gek28hn1nlj20yc0tm77v.jpg" alt="undefined"></p><p>数据质量功能模块设计的主要功能如上图4所示，包括：监控对象管理、检核指标管理、数据质量过程监控、问题跟踪管理、推荐优化管理、知识库管理及系统管理等。其中过程监控包括离线数据监控、实时数据监控；问题跟踪处理由问题发现（支持自动检核、人工录入）、问题提报、任务推送、故障定级、故障处理、知识库沉淀等形成闭环流程。</p><h3 id="管理流程"><a href="#管理流程" class="headerlink" title="管理流程"></a>管理流程</h3><p>流程化管理是推进数据问题从发现、跟踪、解决到总结提炼的合理有效工具。质量管理流程包括：数据质量问题提报、数据质量问题分析、故障跟踪、解决验证、数据质量评估分析等主要环节步骤；从干系人员的角度分析包括数据质量管理人员、数据质量检查人员、数据平台开发人员、业务及BI商分人员等，从流程步骤到管理人员形成职责和角色的矩阵图。如图5所示：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gek28rlex5j227o0zidkb.jpg" alt="undefined"></p><p><strong>问题汇总</strong>：数据质量提报、ETL处理及监控过程上报、数据质量检查点等多方来源，其中ETL处理部分为程序自动化上报，减少人为干预。 <strong>问题分析</strong>：通过规定的角色和岗位的人员对汇总问题分析和评估，由统一公共账号自动推送提醒消息至责任人。 <strong>问题工单</strong>：对采集的问题经过分析归类，主要划为信息提示和故障问题两大类，信息提示无需工单生成，故障问题将产生对应的工单，后推送至工单处理人。 <strong>故障定级</strong>： 针对生成的问题工单判断其故障级别，其级别分为：S1、S2、S3、S4等四类（如图3所述），针对尤为严重的故障问题需Review机制并持续跟踪CaseStudy总结。 <strong>知识库体系</strong>：从由数据问题、解决方案、典型案例等内容中，提炼总结形成标准化、完备知识库体系，以质量问题中提炼价值，形成标准，更加有效的指导业务、规范业务，提高源头数据质量，提升业务服务水平。</p><p><strong>质量流程管理：</strong></p><ul><li><strong>流程原则</strong>：统一流程、步骤稳定。</li><li><strong>权限控制</strong>：流程节点与人员账户号绑定，若节点未设置人员账户即面向所有人员，否则为规定范围的人员。</li><li><strong>权限管理</strong>：可结合美团平台的UPM系统权限管理机制。</li></ul><h2 id="技术方案"><a href="#技术方案" class="headerlink" title="技术方案"></a>技术方案</h2><h3 id="总体架构"><a href="#总体架构" class="headerlink" title="总体架构"></a>总体架构</h3><p>DataMan系统建设总体方案基于美团的大数据技术平台。自底向上包括：检测数据采集、质量集市处理层；质量规则引擎模型存储层；系统功能层及系统应用展示层等。整个数据质量检核点基于技术性、业务性检测，形成完整的数据质量报告与问题跟踪机制，创建质量知识库，确保数据质量的完整性（Completeness）、正确性（Correctness）、当前性（Currency）、一致性（Consistency）。</p><p><strong>总体架构图如图6所示：</strong></p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gek297pe8qj212k0pa0z1.jpg" alt="undefined"></p><ul><li><strong>数据源及集市层</strong>：首先采集数据平台质量相关的元数据信息、监控日志信息、实时日志、检测配置中心日志、作业日志及调度平台日志等关键的质量元数据；经数据质量集市的模型设计、监控对象的分类，加工形成完整、紧关联、多维度、易分析的数据质量基础数据模型，为上层质量应用分析奠定数据基础。数据来源自大数据平台、实时数仓、调度平台等，涉及到Hive、 Spark、Storm、 Kafka、MySQL及BI应用等相关平台数据源；</li><li><strong>存储模型层</strong>：主要功能包括规则引擎数据配置、质量模型结果存储；以数据质量监控、影响关联、全方位监控等目标规则引擎的推动方式，将加工结果数据存储至关系型数据库中，构成精简高质数据层；</li><li><strong>系统功能层</strong>：包括配置管理、过程监控、问题跟踪、故障流程管理、实时数据监控、知识库体系的创建等；处理的对象包括日志运行作业、物理监控模型、业务监控模型等主要实体；</li><li><strong>系统展示层</strong>：通过界面化方式管理、展示数据质量状态，包括质量监控界面、推荐优化模块、质量分析、信息展示、问题提报、故障跟踪及测量定级、系统权限管理等功能。</li></ul><h3 id="技术框架"><a href="#技术框架" class="headerlink" title="技术框架"></a>技术框架</h3><h4 id="前后端技术"><a href="#前后端技术" class="headerlink" title="前后端技术"></a>前后端技术</h4><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gek29h0s2vj222i0s6q5e.jpg" alt="undefined"></p><p>DataMan应用系统其前端框架（如上图7）基于Bootstrap开发，模板引擎为FreeMarker，Tomcat（开发环境）作为默认Web容器，通过MVC的方式实现与应用服务层对接。Bootstrap的优势基于jQuery，丰富的CSS、JS组件，兼容多种浏览器，界面风格统一等；FreeMarker为基于模板用来生成输出文本的引擎。后台基于开源框架Spring4，Spring Boot，Hibernate搭建，其集成了Druid，Apache系列和Zebra等数据库访问中间件等，为系统的功能开发带来更多选择和便利。</p><h4 id="Zebra中间件"><a href="#Zebra中间件" class="headerlink" title="Zebra中间件"></a>Zebra中间件</h4><p>系统数据库连接采用中间件Zebra，这是美团点评DBA团队推荐的官方数据源组件，基于JDBC、API协议上开发出的高可用、高性能的数据库访问层解决方案；提供如动态配置、监控、读写分离、分库分表等功能。Zebra整体架构如图8所示：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gek29q9kb8j213e0aaq3z.jpg" alt="undefined"></p><p>Zebra客户端会据路由配置直连到MySQL数据库进行读写分离和负载均衡。RDS是一站式的数据库管理平台，提供Zebra的路由配置信息的维护；MHA组件和从库监控服务分别负责主库和从库的高可用。Zebra支持丰富的底层连接池；统一源数据配置管理；读写分离和分库分表；数据库的高可用。</p><h3 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h3><p>整个质量监管平台数据流向为数据质量元数据信息采集于美团平台，包括数据仓库元数据信息、质量检测元数据、调度平台日志信息、监控日志及实时元数据信息等，加工形成独立数据质量的集市模型，以此支撑应用层系统的数据需求。应用层系统数据库采用关系型数据库存储的方式，主要包含了规则配置管理信息、数据质量结果库等信息内容。数据流向层级关系图如下：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gek2aduwn6j20zq0pk0ug.jpg" alt="undefined"></p><p><strong>数据平台层</strong>：基于美团大数据平台的数据质量元数据是质量分析和监管的来源，是整个系统最基础重要资源信息，此数据主要包括：数仓元数据信息，如数仓模型表基本信息、表存储空间资源信息、表分区信息、节点信息、数据库meta信息、数据库资源信息等；运行作业调度日志信息，如作业基本信息、作业运行资源信息、作业调度状态信息、作业依赖关系信息及作业调度日志监控信息等；质量检测元数据信息主要来源于SLA、DQC（美团内部系统）检测结果的信息。实时元数据采集于调度平台实时作业运行的API接口调用分析。</p><p><strong>质量集市层</strong>：DM数据质量集市的独立创建是依托基础元数据信息，根据质量监管平台配置的引擎规则ETL加工形成。规则库引擎如数仓应用主题的划分规则、数仓逻辑分层约束、数据库引擎分类、模型使用热度等级、模型存储空间分类、资源增长等级、历史周期分类、作业重要级别、作业运行耗时等级、作业故障分类、及数据质量标准化定义等；在管理方向上，如模型或作业所属的业务条线、组织架构、开发人员等；在时效上分为离线监控数据、实时数据集市等。从多个维度交叉组合分析形成模型类、作业类、监控日志类、实时类等主题的等易理解、简单、快捷的数据质量集市层，强有力的支撑上层应用层功能的数据需求。数据质量集市DM主要模型如图10所示：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gek2apc2nvj20uu10mtc8.jpg" alt="undefined"></p><ul><li>模型设计：“统一规范、简单快捷、快速迭代、保障质量”，基于美团平台元数据、平台日志、实时数据接口等来源，通过制定的规则、标准，形成可衡量、可评估的数据质量集市层，主要包含公共维度类、模型分析类、作业监控类、平台监控类等主要内容；</li><li>实时数据：针对实时作业的监控通过API接口调用，后落地数据，实时监控作业运行日志状态；</li><li>数据加工：基于美团平台离线Hive、Spark引擎执行调度，以数仓模型分层、数仓十大主题规则和数据质量规则库等为约束条件，加工形成独立的数据集市层。</li></ul><p><strong>应用分析层</strong>：应用层系统数据采用关系型数据库（MySQL）存储的方式，主要包含了规则配置管理信息、数据质量分析结果、实时API落地数据、故障问题数据、知识库信息、流程管理及系统管理类等信息内容，直接面对前端界面的展示和管理。</p><h2 id="系统展示"><a href="#系统展示" class="headerlink" title="系统展示"></a>系统展示</h2><p>数据质量DataMan监控系统一期建设主要实现的功能包括：个人工作台、信息监控、推荐信息、信息提报、故障管理、配置管理及权限系统管理等。系统效果如图11所示：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gek2b855vuj21zk0wgdkz.jpg" alt="undefined"></p><h3 id="个人工作台"><a href="#个人工作台" class="headerlink" title="个人工作台"></a>个人工作台</h3><p>在系统中将个人待关注、待处理、待优化、待总结等与个人相关的问题和任务形成统一的工作平台入口，通过公共账号推送的方式，第一时间提醒个人，通知反馈问题的提出者，保障问题可跟踪，进度可查询，责任到人的工作流程机制。</p><h3 id="离线监控"><a href="#离线监控" class="headerlink" title="离线监控"></a>离线监控</h3><p>系统可定时执行模型监控、作业监控、平台日志监控等元数据质量规则引擎，开展数据仓库主题模型、逻辑层级作业、存储资源空间、作业耗时、CPU及内存资源等细化深度分析和洞察；按照质量分析模型，以时间、增长趋势、同环比、历史基线点等多维度、全面整合打造统一监控平台。</p><h3 id="实时监控"><a href="#实时监控" class="headerlink" title="实时监控"></a>实时监控</h3><p>从应用角度将作业按照业务条线、数仓分层、数仓主题、组织结构和人员等维度划分，结合作业基线信息，实时监控正在运行的作业质量，并与作业基线形成对比参照，预警不符合标准的指标信息，第一时间通知责任人。实时作业运行与基线对比监控效果如图12所示：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gek2bkc9p3j21iy11o43f.jpg" alt="undefined"></p><h3 id="推荐信息"><a href="#推荐信息" class="headerlink" title="推荐信息"></a>推荐信息</h3><p>系统通过规则引擎的设置和自动调度的执行，从存储资源配置、数据模型优化、作业优化、日志错误超时、预警通知等方面考虑，以制定的质量标准为评估依据，自动检测评估，汇总问题，形成可靠的推荐优化内容，并在达到阈值条件后主动推送消息，触发后续任务开展。</p><h3 id="公共账号"><a href="#公共账号" class="headerlink" title="公共账号"></a>公共账号</h3><p>通过“数据治理公共账号”机器人发送消息模式，将预判触发的预警通知、任务分配、任务提醒和风险评估等信息第一时间通知相应的负责人员，开启工作流程。</p><h3 id="故障处理"><a href="#故障处理" class="headerlink" title="故障处理"></a>故障处理</h3><p>支持自动提报和人工填报两种模式，以闭环工作流方式开展工作，确保问题故障可跟踪、可查询、可定级、可考核、可量化，以责任到人、落地可行的处理模式，严控数据质量，从根本上提高数据质量，提升业务服务水平。</p><p>DataMan质量监管系统的投入运营，优化数据存储资源、提高作业性能、降低任务耗时、推进了管理工作的规范化和精细化。信息推荐功能以推送通知的形式将待优化、存风险和超时故障信息第一时间发送个人工作台，以工作流机制推动开展；模型监控、作业监控功能在数据存储、模型建设、作业耗时等场景合理的控制资源，节省了投资成本。 问题提报和故障管理功能的有效结合，将问题发现、提报、任务分配、处理完成及Review总结沉淀等形成了责任到人、问题可询的闭环流程。随着系统的深入运行，将在实时数据监控、质量故障统计管理、数据质量考核机制、数据资产质量权威报告、知识库体系标准化及流程深化管理等功能方面持续推进和发挥价值。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>数据质量是数据治理建设的重要一环，与元数据管理、数据标准化及数据服务管理等共同构建了数据治理的体系框架。建设一个完整DataMan质量监管平台，将从监控、标准、流程制度等方面提升信息管理能力，优先解决所面临的数据质量和数据服务问题，其效果体现以下几个方面：</p><ul><li>监控数据资产质量状态，为优化数据平台和数据仓库性能、合理配置数据存储资源提供决策支持；</li><li>持续推动数据质量监控优化预警、实时监控的机制；</li><li>重点优先监控关键核心数据资产，管控优化20%核心资源，可提升80%需求应用性能；</li><li>规范了问题故障的跟踪、Review、优化方案。从数据中提炼价值，从方案中形成标准化的知识体系；</li><li>由技术检测到业务监督，形成闭环工作流机制，提高整体数据质量，全面提升服务业务水平。</li></ul><p>数据质量是数据仓库建设、数据应用建设和决策支持的关键因素，可通过完善组织架构和管理流程，加强部门间衔接和协调，严格按照标准或考核指标执行落地，确保数据质量方能将数据的商业价值最大化，进而提升企业的核心竞争力和保持企业的可持续发展。</p><h2 id="招聘"><a href="#招聘" class="headerlink" title="招聘"></a>招聘</h2><p>最后插播一个招聘广告，我们是一群擅长大数据领域数据建设、数仓建设、数据治理及数据BI应用建设的工程师，期待更多能手加入，有兴趣的同学可以发邮件给yangguang09#meituan.com，zhangdexiao#meituan.com。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h2><ul><li>德晓，美团点评数仓专家、大数据高级工程师，长期从事数据仓库、数据建模、数据治理、大数据方向系统实践建设等，现为美团点评大交通数据仓库建设负责人。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;数据质量干货中的干货&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt; &lt;a href=&quot;https://tech.meituan.com/2018/03/21/mtdp-dataman.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;DataMan-美团旅行数据质量监管平台实践&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/bec9bff2gy1gek26x62b7j20ao0ar74e.jpg&quot; alt=&quot;undefined&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Reading Notes" scheme="http://yoursite.com/categories/Reading-Notes/"/>
    
    
      <category term="数据质量" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F/"/>
    
  </entry>
  
  <entry>
    <title>Flink Table &amp; SQL</title>
    <link href="http://yoursite.com/2020/05/07/Flink%20Table%20&amp;%20SQL%20%E6%A6%82%E8%A7%88/"/>
    <id>http://yoursite.com/2020/05/07/Flink Table &amp; SQL 概览/</id>
    <published>2020-05-07T02:43:53.432Z</published>
    <updated>2020-05-07T06:38:51.053Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Flink Table 和 SQL 整体的脉络</p></blockquote><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gejppurwd5j20ib046t9h.jpg" alt="3.png"></p><a id="more"></a> <h1 id="Flink-Table-amp-SQL"><a href="#Flink-Table-amp-SQL" class="headerlink" title="Flink Table &amp; SQL"></a>Flink Table &amp; SQL</h1><h2 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h2><p>依赖没啥好说的，要想一下的是Zeppelin是否需要手动把这些依赖全都加上去</p><h2 id="两种Planner的区别"><a href="#两种Planner的区别" class="headerlink" title="两种Planner的区别"></a>两种Planner的区别</h2><ul><li>最大区别 流批一体，blink不支持和dataset之间的转换了</li><li>取消了BatchTableSource，使用有界的StreamTableSource</li><li>Blink只支持全新的catalog，旧的ExternalCatalog不再支持</li><li>基于字符串的键值配置选项仅适用于Blink planner</li><li>PlannerConfig在两个planner中的实现不同</li><li>Blink planner会将多个sink优化在一个DAG中（仅在TableEnvironment上受支持，而在StreamTableEnvironment上不受支持）。而旧planner的优化总是将每一个sink放在一个新的DAG中，其中所有DAG彼此独立</li><li>旧的planner不支持目录统计，而Blink planner支持</li></ul><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><h3 id="基本程序结构"><a href="#基本程序结构" class="headerlink" title="基本程序结构"></a>基本程序结构</h3><p>Table API 和 SQL 的程序结构，与流式处理的程序结构类似；也可以近似地认为有这么几步：首先创建执行环境，然后定义source、transform和sink</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tableEnv = ...     <span class="comment">// 创建表的执行环境</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一张表，用于读取数据</span></span><br><span class="line">tableEnv.connect(...).createTemporaryTable(<span class="string">"inputTable"</span>)</span><br><span class="line"><span class="comment">// 注册一张表，用于把计算结果输出</span></span><br><span class="line">tableEnv.connect(...).createTemporaryTable(<span class="string">"outputTable"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过 Table API 查询算子，得到一张结果表</span></span><br><span class="line"><span class="keyword">val</span> result = tableEnv.from(<span class="string">"inputTable"</span>).select(...)</span><br><span class="line"><span class="comment">// 通过 SQL查询语句，得到一张结果表</span></span><br><span class="line"><span class="keyword">val</span> sqlResult  = tableEnv.sqlQuery(<span class="string">"SELECT ... FROM inputTable ..."</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将结果表写入输出表中</span></span><br><span class="line">result.insertInto(<span class="string">"outputTable"</span>)</span><br></pre></td></tr></table></figure><h3 id="创建表环境"><a href="#创建表环境" class="headerlink" title="创建表环境"></a>创建表环境</h3><p>创建表环境最简单的方式，就是基于流处理执行环境，调create方法直接创建:</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">StreamTableEnvironment</span>.create(env)</span><br></pre></td></tr></table></figure><p>表环境（TableEnvironment）是flink中集成Table API &amp; SQL的核心概念。它负责:</p><ul><li>注册catalog</li><li>在内部 catalog 中注册表</li><li>执行SQL查询</li><li>注册用户自定义函数</li><li>将DataStream或DataSet转换成表</li><li>保存对ExecutionEnvironment或者StreamExecutionEnvironment的引用</li></ul><p>在创建TableEnv的时候，可以多传入一个EnvironmentSettings 或者 TableConfig 参数，可以用来配置tEnv的一些特性</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> settings = <span class="type">EnvironmentSettings</span>.newInstance()</span><br><span class="line">  .useOldPlanner()      <span class="comment">// 使用老版本planner</span></span><br><span class="line">  .inStreamingMode()    <span class="comment">// 流处理模式</span></span><br><span class="line">  .build()</span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">StreamTableEnvironment</span>.create(env, settings)</span><br></pre></td></tr></table></figure><p>基于老版本的批处理环境（Flink-Batch-Query）</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> batchEnv = <span class="type">ExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="keyword">val</span> batchTableEnv = <span class="type">BatchTableEnvironment</span>.create(batchEnv)</span><br></pre></td></tr></table></figure><p>基于blink版本的流处理环境(Blink-Streaming-Query):</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> bsSettings = <span class="type">EnvironmentSettings</span>.newInstance()</span><br><span class="line">.useBlinkPlanner()</span><br><span class="line">.inStreamingMode().build()</span><br><span class="line"><span class="keyword">val</span> bsTableEnv = <span class="type">StreamTableEnvironment</span>.create(env, bsSettings)</span><br></pre></td></tr></table></figure><p>基于Blink版本的批处理环境(Blink-Batch-Query)</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> bbSettings = <span class="type">EnvironmentSettings</span>.newInstance()</span><br><span class="line">.useBlinkPlanner()</span><br><span class="line">.inBatchMode().build()</span><br><span class="line"><span class="keyword">val</span> bbTableEnv = <span class="type">TableEnvironment</span>.create(bbSettings)</span><br></pre></td></tr></table></figure><h3 id="注册表"><a href="#注册表" class="headerlink" title="注册表"></a>注册表</h3><p>TableEnvironment可以注册目录Catalog，并可以基于Catalog注册表。它会维护一个Catalog-Table表之间的map。</p><p>表（Table）是由一个“标识符”来指定的，由3部分组成：Catalog名、数据库（database）名和对象名（表名）。如果没有指定目录或数据库，就使用当前的默认值。</p><p>表可以是常规的（Table，表），或者虚拟的（View，视图）。常规表（Table）一般可以用来描述外部数据，比如文件、数据库表或消息队列的数据，也可以直接从 DataStream转换而来。视图可以从现有的表中创建，通常是table API或者SQL查询的一个结果。</p><h3 id="连接到文件系统（CSV）"><a href="#连接到文件系统（CSV）" class="headerlink" title="连接到文件系统（CSV）"></a>连接到文件系统（CSV）</h3><p>连接外部系统在Catalog中注册表，直接调用tableEnv.connect()就可以，里面参数要传入一个ConnectorDescriptor，也就是connector描述器。对于文件系统的connector而言，flink内部已经提供了，就叫做FileSystem()。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tableEnv</span><br><span class="line">.connect( <span class="keyword">new</span> <span class="type">FileSystem</span>().path(<span class="string">"sensor.txt"</span>))  <span class="comment">// 定义表数据来源，外部连接</span></span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">OldCsv</span>())    <span class="comment">// 定义从外部系统读取数据之后的格式化方法</span></span><br><span class="line">  .withSchema( <span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">    .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">    .field(<span class="string">"timestamp"</span>, <span class="type">DataTypes</span>.<span class="type">BIGINT</span>())</span><br><span class="line">    .field(<span class="string">"temperature"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">  )    <span class="comment">// 定义表结构</span></span><br><span class="line">  .createTemporaryTable(<span class="string">"inputTable"</span>)    <span class="comment">// 创建临时表</span></span><br></pre></td></tr></table></figure><p>这是旧版本的csv格式描述器。由于它是非标的，跟外部系统对接并不通用，所以将被弃用，以后会被一个符合RFC-4180标准的新format描述器取代。新的描述器就叫Csv()，但flink没有直接提供，需要引入依赖flink-csv：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;flink-csv&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.10.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>代码非常类似，只需要把withFormat里的OldCsv改成Csv就可以了。</p><h3 id="连接到Kafka"><a href="#连接到Kafka" class="headerlink" title="连接到Kafka"></a>连接到Kafka</h3><p>kafka的连接器flink-kafka-connector中，1.10版本的已经提供了Table API的支持。我们可以在 connect方法中直接传入一个叫做Kafka的类，这就是kafka连接器的描述器ConnectorDescriptor</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.connect(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Kafka</span>()</span><br><span class="line">    .version(<span class="string">"0.11"</span>) <span class="comment">// 定义kafka的版本</span></span><br><span class="line">    .topic(<span class="string">"sensor"</span>) <span class="comment">// 定义主题</span></span><br><span class="line">    .property(<span class="string">"zookeeper.connect"</span>, <span class="string">"localhost:2181"</span>) </span><br><span class="line">    .property(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>)</span><br><span class="line">)</span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">Csv</span>())</span><br><span class="line">  .withSchema(<span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">  .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">  .field(<span class="string">"timestamp"</span>, <span class="type">DataTypes</span>.<span class="type">BIGINT</span>())</span><br><span class="line">  .field(<span class="string">"temperature"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">)</span><br><span class="line">  .createTemporaryTable(<span class="string">"kafkaInputTable"</span>)</span><br></pre></td></tr></table></figure><p>当然也可以连接到ElasticSearch、MySql、HBase、Hive等外部系统，实现方式基本上是类似的。</p><h3 id="表的查询"><a href="#表的查询" class="headerlink" title="表的查询"></a>表的查询</h3><p>利用外部系统的连接器connector，我们可以读写数据，并在环境的Catalog中注册表。接下来就可以对表做查询转换了。</p><p>Flink给我们提供了两种查询方式：Table API和 SQL。</p><h3 id="TableAPI的调用"><a href="#TableAPI的调用" class="headerlink" title="TableAPI的调用"></a>TableAPI的调用</h3><p>Table API是集成在Scala和Java语言内的查询API。与SQL不同，Table API的查询不会用字符串表示，而是在宿主语言中一步一步调用完成的。</p><p>Table API基于代表一张“表”的Table类，并提供一整套操作处理的方法API。这些方法会返回一个新的Table对象，这个对象就表示对输入表应用转换操作的结果。有些关系型转换操作，可以由多个方法调用组成，构成链式调用结构。例如table.select(…).filter(…)，其中select（…）表示选择表中指定的字段，filter(…)表示筛选条件。</p><p>代码中的实现如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorTable: <span class="type">Table</span> = tableEnv.from(<span class="string">"inputTable"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultTable: <span class="type">Table</span> = senorTable</span><br><span class="line">.select(<span class="string">"id, temperature"</span>)</span><br><span class="line">.filter(<span class="string">"id ='sensor_1'"</span>)</span><br></pre></td></tr></table></figure><h3 id="SQL查询"><a href="#SQL查询" class="headerlink" title="SQL查询"></a>SQL查询</h3><p>Flink的SQL集成，基于的是<code>ApacheCalcite</code>，</p><p>它实现了SQL标准。</p><p>在Flink中，用常规字符串来定义SQL查询语句。</p><p>SQL 查询的结果，是一个新的 Table。</p><p>代码如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> resultSqlTable: <span class="type">Table</span> = tableEnv.sqlQuery(<span class="string">"select id, temperature from inputTable where id ='sensor_1'"</span>)</span><br></pre></td></tr></table></figure><p>或者：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> resultSqlTable: <span class="type">Table</span> = tableEnv.sqlQuery(</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |select id, temperature</span></span><br><span class="line"><span class="string">    |from inputTable</span></span><br><span class="line"><span class="string">    |where id = 'sensor_1'</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin)</span><br></pre></td></tr></table></figure><p>当然，也可以加上聚合操作，比如我们统计每个sensor温度数据出现的个数，做个count统计：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val aggResultTable = sensorTable</span><br><span class="line">    .groupBy(&apos;id)</span><br><span class="line">    .select(&apos;id, &apos;id.count as &apos;count)</span><br></pre></td></tr></table></figure><p>SQL:</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> aggResultSqlTable = tableEnv.sqlQuery(<span class="string">"select id, count(id) as cnt from inputTable group by id"</span>)</span><br></pre></td></tr></table></figure><p>这里Table API里指定的字段，前面加了一个单引号’，这是Table API中定义的Expression类型的写法，可以很方便地表示一个表中的字段。</p><p>字段可以直接全部用双引号引起来，也可以用半边单引号+字段名的方式。以后的代码中，一般都用后一种形式。</p><h3 id="将DataStream转换成表"><a href="#将DataStream转换成表" class="headerlink" title="将DataStream转换成表"></a>将DataStream转换成表</h3><p>Flink允许我们把Table和DataStream做转换：</p><p>我们可以基于一个DataStream，</p><p>先流式地读取数据源，</p><p>然后map成样例类，</p><p>再把它转成Table。</p><p>Table的列字段（column fields），</p><p>就是样例类里的字段，</p><p>这样就不用再麻烦地定义schema了。</p><p><strong>Code</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">val inputStream: DataStream[String] = env.readTextFile(&quot;sensor.txt&quot;)</span><br><span class="line">val dataStream: DataStream[SensorReading] = inputStream</span><br><span class="line">  .map(data =&gt; &#123;</span><br><span class="line">    val dataArray = data.split(&quot;,&quot;)</span><br><span class="line">    SensorReading(dataArray(0), dataArray(1).toLong, dataArray(2).toDouble)</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">val sensorTable: Table = tableEnv.fromDataStream(dataStream)</span><br><span class="line"></span><br><span class="line">val sensorTable2 = tableEnv.fromDataStream(dataStream, &apos;id, &apos;timestamp as &apos;ts)</span><br></pre></td></tr></table></figure><h3 id="数据类型与-Table-schema的对应"><a href="#数据类型与-Table-schema的对应" class="headerlink" title="数据类型与 Table schema的对应"></a>数据类型与 Table schema的对应</h3><p>在上面的例子中，DataStream 中的数据类型，与表的 Schema 之间的对应关系，是按照样例类中的字段名来对应的（name-based mapping），所以还可以用as做重命名。</p><p>另外一种对应方式是，直接按照字段的位置来对应（position-based mapping），对应的过程中，就可以直接指定新的字段名了。</p><p><strong>基于名称的对应</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorTable = tableEnv.fromDataStream(dataStream, <span class="symbol">'timestamp</span> as <span class="symbol">'ts</span>, <span class="symbol">'id</span> as <span class="symbol">'myId</span>, <span class="symbol">'temperature</span>)</span><br></pre></td></tr></table></figure><p><strong>基于位置的对应</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorTable = tableEnv.fromDataStream(dataStream, <span class="symbol">'myId</span>, <span class="symbol">'ts</span>)</span><br></pre></td></tr></table></figure><p>Flink的DataStream和DataSet API支持多种类型。</p><p>组合类型，比如元组（内置Scala和Java元组）、POJO、Scala case类和Flink的Row类型等，允许具有多个字段的嵌套数据结构，这些字段可以在Table的表达式中访问。其他类型，则被视为原子类型。</p><p>元组类型和原子类型，一般用位置对应会好一些；如果非要用名称对应，也是可以的：</p><p>元组类型，默认的名称是 “_1”, “_2”；而原子类型，默认名称是 ”f0”。</p><h3 id="创建临时视图（Temporary-View）"><a href="#创建临时视图（Temporary-View）" class="headerlink" title="创建临时视图（Temporary View）"></a>创建临时视图（Temporary View）</h3><p>创建临时视图的第一种方式，就是直接从DataStream传唤而来。同样，可以直接对应字段转换；也可以在转换的时候，指定相应的字段。</p><p><strong>Code</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.createTemporaryView(<span class="string">"sensorView"</span>, dataStream)</span><br><span class="line">tableEnv.createTemporaryView(<span class="string">"sensorView"</span>, dataStream, <span class="symbol">'id</span>, <span class="symbol">'temperature</span>, <span class="symbol">'timestamp</span> as <span class="symbol">'ts</span>)</span><br></pre></td></tr></table></figure><p>另外，当然还可以基于Table创建视图：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.createTemporaryView(<span class="string">"sensorView"</span>, sensorTable)</span><br></pre></td></tr></table></figure><p>View和Table的Schema完全相同。事实上，在Table API中，可以认为View和Table是等价的。</p><h3 id="输出表"><a href="#输出表" class="headerlink" title="输出表"></a>输出表</h3><p>表的输出，是通过将数据写入 TableSink 来实现的。TableSink 是一个通用接口，可以支持不同的文件格式、存储数据库和消息队列。</p><p>具体实现，输出表最直接的方法，就是通过 Table.insertInto() 方法将一个 Table 写入注册过的 TableSink 中。</p><p>输出到文件</p><p><strong>Code</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 注册输出表</span></span><br><span class="line">tableEnv.connect(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">FileSystem</span>().path(<span class="string">"…\\resources\\out.txt"</span>)</span><br><span class="line">) <span class="comment">// 定义到文件系统的连接</span></span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">Csv</span>()) <span class="comment">// 定义格式化方法，Csv格式</span></span><br><span class="line">  .withSchema(<span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">  .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">  .field(<span class="string">"temp"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">) <span class="comment">// 定义表结构</span></span><br><span class="line">  .createTemporaryTable(<span class="string">"outputTable"</span>) <span class="comment">// 创建临时表</span></span><br><span class="line"></span><br><span class="line">resultSqlTable.insertInto(<span class="string">"outputTable"</span>)</span><br></pre></td></tr></table></figure><h3 id="更新模式"><a href="#更新模式" class="headerlink" title="更新模式"></a>更新模式</h3><p>在流处理过程中，表的处理并不像传统定义的那样简单。</p><p>对于流式查询（Streaming Queries），需要声明如何在（动态）表和外部连接器之间执行转换。与外部系统交换的消息类型，由<strong>更新模式</strong>（update mode）指定。</p><p>Flink Table API中的更新模式有以下三种：</p><p><strong>1) 追加模式 Append Mode</strong></p><p>在追加模式下，表（动态表）和外部连接器只插入（Insert）消息。</p><p><strong>2)撤回模式 Retract Mode</strong></p><p>撤回模式下，表和外部连接器交换的是：添加ADD 和撤回Retract 消息。</p><p>插入（Insert）会被编码为添加消息。</p><p>删除（Delete）则编码为撤回消息。</p><p>更新（Update）则会编码为。已更新行（上一行）的撤回消息，和更新行（新行）的添加消息。</p><p>从模式下，不能定义key，这一点跟upsert模式完全不同。</p><p><strong>3)更新插入模式 Upsert</strong></p><p>在Upsert模式下，动态表和外部连接器交换Upsert和Delete消息。</p><p>这个模式需要一个唯一的key，通过这个key可以传递更新消息。为了正确应用消息，外部连接器需要知道这个唯一key的属性。</p><ul><li><p>插入（Insert）和更新（Update）都被编码为Upsert消息；</p></li><li><p>删除（Delete）编码为Delete信息。</p></li></ul><p>这种模式和Retract模式的主要区别在于，Update操作是用单个消息编码的，所以效率会更高。</p><h3 id="输出到Kafka"><a href="#输出到Kafka" class="headerlink" title="输出到Kafka"></a>输出到Kafka</h3><p>除了输出到文件，也可以输出到Kafka。我们可以结合前面Kafka作为输入数据，构建数据管道，kafka进，kafka出</p><p><strong>Code</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.connect(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Kafka</span>()</span><br><span class="line">    .version(<span class="string">"0.11"</span>)</span><br><span class="line">    .topic(<span class="string">"sinkTest"</span>)</span><br><span class="line">    .property(<span class="string">"zookeeper.connect"</span>, <span class="string">"localhost:2181"</span>)</span><br><span class="line">    .property(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>)</span><br><span class="line">)</span><br><span class="line">  .withFormat( <span class="keyword">new</span> <span class="type">Csv</span>() )</span><br><span class="line">  .withSchema( <span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">    .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">    .field(<span class="string">"temp"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">  )</span><br><span class="line">  .createTemporaryTable(<span class="string">"kafkaOutputTable"</span>)</span><br><span class="line"></span><br><span class="line">resultTable.insertInto(<span class="string">"kafkaOutputTable"</span>)</span><br></pre></td></tr></table></figure><h3 id="输出到ES"><a href="#输出到ES" class="headerlink" title="输出到ES"></a>输出到ES</h3><p>ElasticSearch的connector可以在upsert（update+insert，更新插入）模式下操作，这样就可以使用Query定义的键（key）与外部系统交换UPSERT/DELETE消息。</p><p>另外，对于“仅追加”（append-only）的查询，connector还可以在append 模式下操作，这样就可以与外部系统只交换insert消息。</p><p>es目前支持的数据格式，只有Json，而flink本身并没有对应的支持，所以还需要引入依赖：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;flink-json&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.10.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p><strong>Code</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 输出到es</span></span><br><span class="line">tableEnv.connect(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Elasticsearch</span>()</span><br><span class="line">    .version(<span class="string">"6"</span>)</span><br><span class="line">    .host(<span class="string">"localhost"</span>, <span class="number">9200</span>, <span class="string">"http"</span>)</span><br><span class="line">    .index(<span class="string">"sensor"</span>)</span><br><span class="line">    .documentType(<span class="string">"temp"</span>)</span><br><span class="line">)</span><br><span class="line">  .inUpsertMode()           <span class="comment">// 指定是 Upsert 模式</span></span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">Json</span>())</span><br><span class="line">  .withSchema( <span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">    .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">    .field(<span class="string">"count"</span>, <span class="type">DataTypes</span>.<span class="type">BIGINT</span>())</span><br><span class="line">  )</span><br><span class="line">  .createTemporaryTable(<span class="string">"esOutputTable"</span>)</span><br><span class="line"></span><br><span class="line">aggResultTable.insertInto(<span class="string">"esOutputTable"</span>)</span><br></pre></td></tr></table></figure><h3 id="输出到MySQL"><a href="#输出到MySQL" class="headerlink" title="输出到MySQL"></a>输出到MySQL</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;flink-jdbc_2<span class="number">.11</span>&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;<span class="number">1.10</span><span class="number">.0</span>&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>jdbc连接的代码实现比较特殊，因为没有对应的java/scala类实现ConnectorDescriptor，所以不能直接tableEnv.connect()。不过Flink SQL留下了执行DDL的接口：tableEnv.sqlUpdate()。</p><p>对于jdbc的创建表操作，天生就适合直接写DDL来实现，所以我们的代码可以这样写：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 输出到 Mysql</span></span><br><span class="line"><span class="keyword">val</span> sinkDDL: <span class="type">String</span> =</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |create table jdbcOutputTable (</span></span><br><span class="line"><span class="string">    |  id varchar(20) not null,</span></span><br><span class="line"><span class="string">    |  cnt bigint not null</span></span><br><span class="line"><span class="string">    |) with (</span></span><br><span class="line"><span class="string">    |  'connector.type' = 'jdbc',</span></span><br><span class="line"><span class="string">    |  'connector.url' = 'jdbc:mysql://localhost:3306/test',</span></span><br><span class="line"><span class="string">    |  'connector.table' = 'sensor_count',</span></span><br><span class="line"><span class="string">    |  'connector.driver' = 'com.mysql.jdbc.Driver',</span></span><br><span class="line"><span class="string">    |  'connector.username' = 'root',</span></span><br><span class="line"><span class="string">    |  'connector.password' = '123456'</span></span><br><span class="line"><span class="string">    |)</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin</span><br><span class="line"></span><br><span class="line">tableEnv.sqlUpdate(sinkDDL)</span><br><span class="line">aggResultSqlTable.insertInto(<span class="string">"jdbcOutputTable"</span>)</span><br></pre></td></tr></table></figure><h3 id="Table转换为DataStream"><a href="#Table转换为DataStream" class="headerlink" title="Table转换为DataStream"></a>Table转换为DataStream</h3><p>表可以转换为DataStream或DataSet。这样，自定义流处理或批处理程序就可以继续在 Table API或SQL查询的结果上运行了。</p><p>将表转换为DataStream或DataSet时，需要指定生成的数据类型，即要将表的每一行转换成的数据类型。通常，最方便的转换类型就是Row。当然，因为结果的所有字段类型都是明确的，我们也经常会用元组类型来表示。</p><p>表作为流式查询的结果，是动态更新的。</p><p>所以，将这种动态查询转换成的数据流，同样需要对表的更新操作进行编码，</p><p>进而有不同的转换模式。</p><p>Table API中表到DataStream有两种模式</p><ul><li>追加 Append Mode</li></ul><p>用于表只会被插入（Insert）操作更改的场景。</p><ul><li>撤回 RetractMode</li></ul><p>得到的数据会增加一个Boolean类型的标识位（返回的第一个字段），用它来表示到底是新增的数据（Insert），还是被删除的数据（老数据， Delete）。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> resultStream: <span class="type">DataStream</span>[<span class="type">Row</span>] = tableEnv.toAppendStream[<span class="type">Row</span>](resultTable)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> aggResultStream: <span class="type">DataStream</span>[(<span class="type">Boolean</span>, (<span class="type">String</span>, <span class="type">Long</span>))] = </span><br><span class="line">tableEnv.toRetractStream[(<span class="type">String</span>, <span class="type">Long</span>)](aggResultTable)</span><br><span class="line"></span><br><span class="line">resultStream.print(<span class="string">"result"</span>)</span><br><span class="line">aggResultStream.print(<span class="string">"aggResult"</span>)</span><br></pre></td></tr></table></figure><p>所以，没有经过groupby之类聚合操作，可以直接用 toAppendStream 来转换；而如果经过了聚合，有更新操作，一般就必须用 toRetractDstream。</p><h3 id="Query的解释和执行"><a href="#Query的解释和执行" class="headerlink" title="Query的解释和执行"></a>Query的解释和执行</h3><p>Table API提供了一种机制来解释（Explain）计算表的逻辑和优化查询计划。这是通过TableEnvironment.explain（table）方法或TableEnvironment.explain（）方法完成的</p><p>explain方法会返回一个字符串，描述三个计划：</p><ul><li><p>未优化的逻辑查询计划</p></li><li><p>优化后的逻辑查询计划</p></li><li><p>实际执行计划</p></li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> explaination: <span class="type">String</span> = tableEnv.explain(resultTable)</span><br><span class="line">println(explaination)</span><br></pre></td></tr></table></figure><p>Query的解释和执行过程，老planner和blink planner大体是一致的，又有所不同。整体来讲，Query都会表示成一个逻辑查询计划，然后分两步解释：</p><p>1.优化查询计划</p><p>2.解释成DataStream或者DataSet程序</p><p>而Blink版本是批流统一的，所以所有的Query，只会被解释成DataStream程序；另外在批处理环境TableEnvironment下，Blink版本要到tableEnv.execute()执行调用才开始解释。</p><h2 id="流处理中的特殊概念"><a href="#流处理中的特殊概念" class="headerlink" title="流处理中的特殊概念"></a>流处理中的特殊概念</h2><p>Table API和SQL，本质上还是基于关系型表的操作方式；而关系型表、关系代数，以及SQL本身，一般是有界的，更适合批处理的场景。这就导致在进行流处理的过程中，理解会稍微复杂一些，需要引入一些特殊概念。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1geby8il5f3j20gj08g0sx.jpg" alt="1.png"></p><p>可以看到，其实关系代数（主要就是指关系型数据库中的表）和SQL，主要就是针对批处理的，这和流处理有天生的隔阂。</p><h3 id="Dynamic-Tables"><a href="#Dynamic-Tables" class="headerlink" title="Dynamic Tables"></a>Dynamic Tables</h3><p>因为流处理面对的数据，是连续不断的，这和我们熟悉的关系型数据库中保存的“表”完全不同。所以，如果我们把流数据转换成Table，然后执行类似于table的select操作，结果就不是一成不变的，而是随着新数据的到来，会不停更新。</p><p>我们可以随着新数据的到来，不停地在之前的基础上更新结果。这样得到的表，在Flink Table API概念里，就叫做“<strong>动态表</strong>”（Dynamic Tables）。</p><p>动态表是Flink对流数据的Table API和SQL支持的核心概念。与表示批处理数据的静态表不同，动态表是随时间变化的。动态表可以像静态的批处理表一样进行查询，查询一个动态表会产生持续查询（Continuous Query）。连续查询永远不会终止，并会生成另一个动态表。查询（Query）会不断更新其动态结果表，以反映其动态输入表上的更改。</p><h3 id="流式持续查询的过程"><a href="#流式持续查询的过程" class="headerlink" title="流式持续查询的过程"></a>流式持续查询的过程</h3><p>下图显示了流、动态表和连续查询的关系：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gebyby4r2yj20ji035jt2.jpg" alt="2.png"></p><p>流式持续查询的过程为：</p><ol><li><p>流被转换为动态表。</p></li><li><p>对动态表计算连续查询，生成新的动态表。</p></li><li><p>生成的动态表被转换回流。</p></li></ol><h3 id="将流转换成表（Table）"><a href="#将流转换成表（Table）" class="headerlink" title="将流转换成表（Table）"></a>将流转换成表（Table）</h3><p>为了处理带有关系查询的流，必须先将其转换为表。</p><p>从概念上讲，流的每个数据记录，都被解释为对结果表的插入（Insert）修改。因为流式持续不断的，而且之前的输出结果无法改变。本质上，我们其实是从一个、只有插入操作的changelog（更新日志）流，来构建一个表。</p><p>为了更好地说明动态表和持续查询的概念，我们来举一个具体的例子。</p><p>比如，我们现在的输入数据，就是用户在网站上的访问行为，数据类型（Schema）如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">  user:  VARCHAR,   // 用户名</span><br><span class="line">  cTime: TIMESTAMP, // 访问某个URL的时间戳</span><br><span class="line">  url:   VARCHAR    // 用户访问的URL</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>下图显示了如何将访问URL事件流，或者叫点击事件流（左侧）转换为表（右侧）。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gebyly5qi6j20ex05e74v.jpg" alt="3.png"></p><p>随着插入更多的访问事件流记录，生成的表将不断增长。</p><h3 id="持续查询（Continuous-Query）"><a href="#持续查询（Continuous-Query）" class="headerlink" title="持续查询（Continuous Query）"></a>持续查询（Continuous Query）</h3><p>持续查询，会在动态表上做计算处理，并作为结果生成新的动态表。与批处理查询不同，连续查询从不终止，并根据输入表上的更新更新其结果表。</p><p>在任何时间点，连续查询的结果在语义上，等同于在输入表的快照上，以批处理模式执行的同一查询的结果。</p><p>在下面的示例中，我们展示了对点击事件流中的一个持续查询。</p><p>这个Query很简单，是一个分组聚合做count统计的查询。它将用户字段上的clicks表分组，并统计访问的url数。图中显示了随着时间的推移，当clicks表被其他行更新时如何计算查询。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gebyo6k1awj20lr0aljsg.jpg" alt="4.png"></p><h3 id="将动态表转换成流"><a href="#将动态表转换成流" class="headerlink" title="将动态表转换成流"></a>将动态表转换成流</h3><p>与常规的数据库表一样，动态表可以通过插入（Insert）、更新（Update）和删除（Delete）更改，进行持续的修改。将动态表转换为流或将其写入外部系统时，需要对这些更改进行编码。Flink的Table API和SQL支持三种方式对动态表的更改进行编码：</p><p>1).仅追加（Append-only）流</p><p>仅通过插入（Insert）更改，来修改的动态表，可以直接转换为“仅追加”流。这个流中发出的数据，就是动态表中新增的每一行。</p><p>2).撤回（Retract）流</p><p>Retract流是包含两类消息的流，添加（Add）消息和撤回（Retract）消息。</p><p>动态表通过将INSERT 编码为add消息、DELETE 编码为retract消息、UPDATE编码为被更改行（前一行）的retract消息和更新后行（新行）的add消息，转换为retract流。</p><p>下图显示了将动态表转换为Retract流的过程。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gebyrhzrcdj20kf081t9b.jpg" alt="5.png"></p><p>3).Upsert（更新插入）流</p><p>Upsert流包含两种类型的消息：Upsert消息和delete消息。转换为upsert流的动态表，需要有唯一的键（key）。</p><p>通过将INSERT和UPDATE更改编码为upsert消息，将DELETE更改编码为DELETE消息，就可以将具有唯一键（Unique Key）的动态表转换为流。</p><p>下图显示了将动态表转换为upsert流的过程。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gebz2a1sjmj20kk089js9.jpg" alt="6.png"></p><p>这些概念我们之前都已提到过。需要注意的是，在代码里将动态表转换为DataStream时，仅支持Append和Retract流。而向外部系统输出动态表的TableSink接口，则可以有不同的实现，比如之前我们讲到的ES，就可以有Upsert模式。</p><h2 id="时间特性"><a href="#时间特性" class="headerlink" title="时间特性"></a>时间特性</h2><p>基于时间的操作（比如Table API和SQL中窗口操作），需要定义相关的时间语义和时间数据来源的信息。所以，Table可以提供一个逻辑上的时间字段，用于在表处理程序中，指示时间和访问相应的时间戳。</p><p>时间属性，可以是每个表schema的一部分。一旦定义了时间属性，它就可以作为一个字段引用，并且可以在基于时间的操作中使用。</p><p>时间属性的行为类似于常规时间戳，可以访问，并且进行计算。</p><h3 id="Processing-Time"><a href="#Processing-Time" class="headerlink" title="Processing Time"></a>Processing Time</h3><p>处理时间语义下，允许表处理程序根据机器的本地时间生成结果。它是时间的最简单概念。它既不需要提取时间戳，也不需要生成watermark。</p><p>定义处理时间属性有三种方法：在DataStream转化时直接指定；在定义Table Schema时指定；在创建表的DDL中指定。</p><h4 id="DataStream转换成Table时指定"><a href="#DataStream转换成Table时指定" class="headerlink" title="DataStream转换成Table时指定"></a>DataStream转换成Table时指定</h4><p>由DataStream转换成表的时候，可以在后面指定字段名来定义Schema。在定义Schema期间，可以使用.proctime定义处理时间字段。</p><p>注意，这个proctime属性只能通过附加逻辑字段，来拓展物理schema，因此，</p><p><strong>只能在schema定义的末尾定义它。</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义好schema</span></span><br><span class="line"><span class="keyword">val</span> inputStream: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">"\\sensor.txt"</span>)</span><br><span class="line"><span class="keyword">val</span> dataStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = inputStream</span><br><span class="line">  .map(data =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> dataArray = data.split(<span class="string">","</span>)</span><br><span class="line">    <span class="type">SensorReading</span>(dataArray(<span class="number">0</span>), dataArray(<span class="number">1</span>).toLong, dataArray(<span class="number">2</span>).toDouble)</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream转换为 Table，并指定时间字段</span></span><br><span class="line"><span class="keyword">val</span> sensorTable = tableEnv.fromDataStream(dataStream, <span class="symbol">'id</span>, <span class="symbol">'temperature</span>, <span class="symbol">'timestamp</span>, <span class="symbol">'pt</span>.proctime)</span><br></pre></td></tr></table></figure><h4 id="定义Table-Schema-时指定"><a href="#定义Table-Schema-时指定" class="headerlink" title="定义Table Schema 时指定"></a>定义Table Schema 时指定</h4><p>定义Schema的时候，加上一个新字段，指定成proctime就可以。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.connect(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">FileSystem</span>().path(<span class="string">"..\\sensor.txt"</span>))</span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">Csv</span>())</span><br><span class="line">  .withSchema(<span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">    .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">    .field(<span class="string">"timestamp"</span>, <span class="type">DataTypes</span>.<span class="type">BIGINT</span>())</span><br><span class="line">    .field(<span class="string">"temperature"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">    .field(<span class="string">"pt"</span>, <span class="type">DataTypes</span>.<span class="type">TIMESTAMP</span>(<span class="number">3</span>))</span><br><span class="line">      .proctime()    <span class="comment">// 指定 pt字段为处理时间</span></span><br><span class="line">  ) <span class="comment">// 定义表结构</span></span><br><span class="line">  .createTemporaryTable(<span class="string">"inputTable"</span>) <span class="comment">// 创建临时表</span></span><br></pre></td></tr></table></figure><h4 id="创建表的DDL中指定"><a href="#创建表的DDL中指定" class="headerlink" title="创建表的DDL中指定"></a>创建表的DDL中指定</h4><p>在创建表的DDL中，增加一个字段并指定成proctime，也可以指定当前的时间字段。</p><p>代码如下:</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sinkDDL: <span class="type">String</span> =</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |create table dataTable (</span></span><br><span class="line"><span class="string">    |  id varchar(20) not null,</span></span><br><span class="line"><span class="string">    |  ts bigint,</span></span><br><span class="line"><span class="string">    |  temperature double,</span></span><br><span class="line"><span class="string">    |  pt AS PROCTIME()</span></span><br><span class="line"><span class="string">    |) with (</span></span><br><span class="line"><span class="string">    |  'connector.type' = 'filesystem',</span></span><br><span class="line"><span class="string">    |  'connector.path' = 'file:///D:\\..\\sensor.txt',</span></span><br><span class="line"><span class="string">    |  'format.type' = 'csv'</span></span><br><span class="line"><span class="string">    |)</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin</span><br><span class="line"></span><br><span class="line">tableEnv.sqlUpdate(sinkDDL) <span class="comment">// 执行 DDL</span></span><br></pre></td></tr></table></figure><p>注意：运行这段DDL，必须使用Blink Planner。</p><h3 id="事件时间（Event-Time）"><a href="#事件时间（Event-Time）" class="headerlink" title="事件时间（Event Time）"></a>事件时间（Event Time）</h3><p>事件时间语义，允许表处理程序根据每个记录中包含的时间生成结果。这样即使在有乱序事件或者延迟事件时，也可以获得正确的结果。</p><p>为了处理无序事件，并区分流中的准时和迟到事件；Flink需要从事件数据中，提取时间戳，并用来推进事件时间的进展（watermark）。</p><h4 id="DataStream转化成Table时指定"><a href="#DataStream转化成Table时指定" class="headerlink" title="DataStream转化成Table时指定"></a>DataStream转化成Table时指定</h4><p>在DataStream转换成Table，schema的定义期间，使用.rowtime可以定义事件时间属性。</p><p>注意，必须在转换的数据流中分配时间戳和watermark。</p><p>在将数据流转换为表时，有两种定义时间属性的方法。根据指定的.rowtime字段名是否存在于数据流的架构中，timestamp字段可以：</p><ol><li><p><strong>作为新字段追加到schema</strong></p></li><li><p><strong>替换现有字段</strong></p></li></ol><p>在这两种情况下，定义的事件时间戳字段，都将保存DataStream中事件时间戳的值。</p><p>代码如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> inputStream: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">"\\sensor.txt"</span>)</span><br><span class="line"><span class="keyword">val</span> dataStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = inputStream</span><br><span class="line">    .map(data =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> dataArray = data.split(<span class="string">","</span>)</span><br><span class="line">        <span class="type">SensorReading</span>(dataArray(<span class="number">0</span>), dataArray(<span class="number">1</span>).toLong, dataArray(<span class="number">2</span>).toDouble)</span><br><span class="line">      &#125;)</span><br><span class="line">    .assignAscendingTimestamps(_.timestamp * <span class="number">1000</span>L)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream转换为 Table，并指定时间字段</span></span><br><span class="line"><span class="keyword">val</span> sensorTable = tableEnv.fromDataStream(dataStream, <span class="symbol">'id</span>, <span class="symbol">'timestamp</span>.rowtime, <span class="symbol">'temperature</span>)</span><br><span class="line"><span class="comment">// 或者，直接追加字段</span></span><br><span class="line"><span class="keyword">val</span> sensorTable2 = tableEnv.fromDataStream(dataStream, <span class="symbol">'id</span>, <span class="symbol">'temperature</span>, <span class="symbol">'timestamp</span>, <span class="symbol">'rt</span>.rowtime)</span><br></pre></td></tr></table></figure><h4 id="定义Schema时指定"><a href="#定义Schema时指定" class="headerlink" title="定义Schema时指定"></a>定义Schema时指定</h4><p>这种方法只要在定义Schema的时候，将事件时间指定，并指定成rowtime就可以了。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.connect(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">FileSystem</span>().path(<span class="string">"sensor.txt"</span>))</span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">Csv</span>())</span><br><span class="line">  .withSchema(<span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">    .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">    .field(<span class="string">"timestamp"</span>, <span class="type">DataTypes</span>.<span class="type">BIGINT</span>())</span><br><span class="line">      .rowtime(</span><br><span class="line">        <span class="keyword">new</span> <span class="type">Rowtime</span>()</span><br><span class="line">          .timestampsFromField(<span class="string">"timestamp"</span>)    <span class="comment">// 从字段中提取时间戳</span></span><br><span class="line">          .watermarksPeriodicBounded(<span class="number">1000</span>)    <span class="comment">// watermark延迟1秒</span></span><br><span class="line">      )</span><br><span class="line">    .field(<span class="string">"temperature"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">  ) <span class="comment">// 定义表结构</span></span><br><span class="line">  .createTemporaryTable(<span class="string">"inputTable"</span>) <span class="comment">// 创建临时表</span></span><br></pre></td></tr></table></figure><h4 id="创建表的DDL中指定-1"><a href="#创建表的DDL中指定-1" class="headerlink" title="创建表的DDL中指定"></a>创建表的DDL中指定</h4><p>事件时间属性，是使用CREATE TABLE DDL中的WARDMARK语句定义的。watermark语句，定义现有事件时间字段上的watermark生成表达式，该表达式将事件时间字段标记为事件时间属性。</p><p>代码如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sinkDDL: <span class="type">String</span> =</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |create table dataTable (</span></span><br><span class="line"><span class="string">    |  id varchar(20) not null,</span></span><br><span class="line"><span class="string">    |  ts bigint,</span></span><br><span class="line"><span class="string">    |  temperature double,</span></span><br><span class="line"><span class="string">    |  rt AS TO_TIMESTAMP( FROM_UNIXTIME(ts) ),</span></span><br><span class="line"><span class="string">    |  watermark for rt as rt - interval '1' second</span></span><br><span class="line"><span class="string">    |) with (</span></span><br><span class="line"><span class="string">    |  'connector.type' = 'filesystem',</span></span><br><span class="line"><span class="string">    |  'connector.path' = 'file:///D:\\..\\sensor.txt',</span></span><br><span class="line"><span class="string">    |  'format.type' = 'csv'</span></span><br><span class="line"><span class="string">    |)</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span>.stripMargin</span><br><span class="line"></span><br><span class="line">tableEnv.sqlUpdate(sinkDDL) <span class="comment">// 执行 DDL</span></span><br></pre></td></tr></table></figure><p>这里<em>FROM_UNIXTIME</em>是系统内置的时间函数，用来将一个整数（秒数）转换成“YYYY-MM-DD hh:mm:ss”格式（默认，也可以作为第二个String参数传入）的日期时间字符串（date time string）；然后再用<em>TO_TIMESTAMP</em>将其转换成Timestamp。</p><h2 id="窗口（Windows）"><a href="#窗口（Windows）" class="headerlink" title="窗口（Windows）"></a>窗口（Windows）</h2><p>时间语义，要配合窗口操作才能发挥作用。最主要的用途，当然就是开窗口、根据时间段做计算了。下面我们就来看看Table API和SQL中，怎么利用时间字段做窗口操作。</p><p>在Table API和SQL中，主要有两种窗口：Group Windows和Over Windows</p><h4 id="分组窗口"><a href="#分组窗口" class="headerlink" title="分组窗口"></a>分组窗口</h4><p>分组窗口（Group Windows）会根据时间或行计数间隔，将行聚合到有限的组（Group）中，并对每个组的数据执行一次聚合函数。</p><p>Table API中的Group Windows都是使用.window（w:GroupWindow）子句定义的，并且必须由as子句指定一个别名。为了按窗口对表进行分组，窗口的别名必须在group by子句中，像常规的分组字段一样引用。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> table = input</span><br><span class="line">  .window([w: <span class="type">GroupWindow</span>] as <span class="symbol">'w</span>) <span class="comment">// 定义窗口，别名 w</span></span><br><span class="line">  .groupBy(<span class="symbol">'w</span>, <span class="symbol">'a</span>)  <span class="comment">// 以属性a和窗口w作为分组的key </span></span><br><span class="line">  .select(<span class="symbol">'a</span>, <span class="symbol">'b</span>.sum)  <span class="comment">// 聚合字段b的值，求和</span></span><br></pre></td></tr></table></figure><p>或者，还可以把窗口的相关信息，作为字段添加到结果表中：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> table = input</span><br><span class="line">  .window([w: <span class="type">GroupWindow</span>] as <span class="symbol">'w</span>) </span><br><span class="line">  .groupBy(<span class="symbol">'w</span>, <span class="symbol">'a</span>) </span><br><span class="line">  .select(<span class="symbol">'a</span>, <span class="symbol">'w</span>.start, <span class="symbol">'w</span>.end, <span class="symbol">'w</span>.rowtime, <span class="symbol">'b</span>.count)</span><br></pre></td></tr></table></figure><p>Table API提供了一组具有特定语义的预定义Window类，这些类会被转换为底层DataStream或DataSet的窗口操作。</p><p>Table API支持的窗口定义，和我们熟悉的一样，主要也是三种：滚动（Tumbling）、滑动（Sliding）和会话（Session）。</p><h4 id="滚动窗口"><a href="#滚动窗口" class="headerlink" title="滚动窗口"></a>滚动窗口</h4><p>滚动窗口（Tumbling windows）要用Tumble类来定义，另外还有三个方法：</p><p>over：定义窗口长度</p><p>on：用来分组（按时间间隔）或者排序（按行数）的时间字段</p><p>as：别名，必须出现在后面的groupBy中</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Tumbling Event-time Window（事件时间字段rowtime）</span></span><br><span class="line">.window(<span class="type">Tumble</span> over <span class="number">10.</span>minutes on <span class="symbol">'rowtime</span> as <span class="symbol">'w</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Tumbling Processing-time Window（处理时间字段proctime）</span></span><br><span class="line">.window(<span class="type">Tumble</span> over <span class="number">10.</span>minutes on <span class="symbol">'proctime</span> as <span class="symbol">'w</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Tumbling Row-count Window (类似于计数窗口，按处理时间排序，10行一组)</span></span><br><span class="line">.window(<span class="type">Tumble</span> over <span class="number">10.</span>rows on <span class="symbol">'proctime</span> as <span class="symbol">'w</span>)</span><br></pre></td></tr></table></figure><h4 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h4><p>滑动窗口（Sliding windows）要用Slide类来定义，另外还有四个方法：</p><p>over：定义窗口长度</p><p>every：定义滑动步长</p><p>on：用来分组（按时间间隔）或者排序（按行数）的时间字段</p><p>as：别名，必须出现在后面的groupBy中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Sliding Event-time Window</span></span><br><span class="line">.window(Slide over <span class="number">10</span>.minutes every <span class="number">5</span>.minutes on <span class="string">'rowtime as '</span>w)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Sliding Processing-time window </span></span><br><span class="line">.window(Slide over <span class="number">10</span>.minutes every <span class="number">5</span>.minutes on <span class="string">'proctime as '</span>w)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Sliding Row-count window</span></span><br><span class="line">.window(Slide over <span class="number">10</span>.rows every <span class="number">5</span>.rows on <span class="string">'proctime as '</span>w)</span><br></pre></td></tr></table></figure><h4 id="会话窗口"><a href="#会话窗口" class="headerlink" title="会话窗口"></a>会话窗口</h4><p>会话窗口（Session windows）要用Session类来定义，另外还有三个方法：</p><ul><li><p>withGap：会话时间间隔</p></li><li><p>on：用来分组（按时间间隔）或者排序（按行数）的时间字段</p></li><li><p>as：别名，必须出现在后面的groupBy中</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Session Event-time Window</span></span><br><span class="line">.window(Session withGap <span class="number">10</span>.minutes on <span class="string">'rowtime as '</span>w)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Session Processing-time Window </span></span><br><span class="line">.window(Session withGap <span class="number">10</span>.minutes on <span class="string">'proctime as '</span>w)</span><br></pre></td></tr></table></figure><h4 id="Over-Windows"><a href="#Over-Windows" class="headerlink" title="Over Windows"></a>Over Windows</h4><p>Over window聚合是标准SQL中已有的（Over子句），可以在查询的SELECT子句中定义。Over window 聚合，会针对每个输入行，计算相邻行范围内的聚合。Over windows<br>使用.window（w:overwindows*）子句定义，并在select（）方法中通过别名来引用。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val table = input</span><br><span class="line">  .window([w: OverWindow] as <span class="string">'w)</span></span><br><span class="line"><span class="string">  .select('</span>a, <span class="string">'b.sum over '</span>w, <span class="string">'c.min over '</span>w)</span><br></pre></td></tr></table></figure><p>Table API提供了Over类，来配置Over窗口的属性。可以在事件时间或处理时间，以及指定为时间间隔、或行计数的范围内，定义Over windows。</p><p>无界的over window是使用常量指定的。也就是说，时间间隔要指定UNBOUNDED_RANGE，或者行计数间隔要指定UNBOUNDED_ROW。而有界的over window是用间隔的大小指定的。</p><p>实际代码应用如下：</p><p>1） 无界的 over window</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 无界的事件时间over window (时间字段 "rowtime")</span></span><br><span class="line">.window(Over partitionBy <span class="string">'a orderBy '</span>rowtime preceding UNBOUNDED_RANGE as <span class="string">'w)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">//无界的处理时间over window (时间字段"proctime")</span></span><br><span class="line"><span class="string">.window(Over partitionBy '</span>a orderBy <span class="string">'proctime preceding UNBOUNDED_RANGE as '</span>w)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 无界的事件时间Row-count over window (时间字段 "rowtime")</span></span><br><span class="line">.window(Over partitionBy <span class="string">'a orderBy '</span>rowtime preceding UNBOUNDED_ROW as <span class="string">'w)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">//无界的处理时间Row-count over window (时间字段 "rowtime")</span></span><br><span class="line"><span class="string">.window(Over partitionBy '</span>a orderBy <span class="string">'proctime preceding UNBOUNDED_ROW as '</span>w)</span><br></pre></td></tr></table></figure><p>2） 有界的over window</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 有界的事件时间over window (时间字段 "rowtime"，之前1分钟)</span></span><br><span class="line">.window(Over partitionBy <span class="string">'a orderBy '</span>rowtime preceding <span class="number">1</span>.minutes as <span class="string">'w)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">// 有界的处理时间over window (时间字段 "rowtime"，之前1分钟)</span></span><br><span class="line"><span class="string">.window(Over partitionBy '</span>a orderBy <span class="string">'proctime preceding 1.minutes as '</span>w)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 有界的事件时间Row-count over window (时间字段 "rowtime"，之前10行)</span></span><br><span class="line">.window(Over partitionBy <span class="string">'a orderBy '</span>rowtime preceding <span class="number">10</span>.rows as <span class="string">'w)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">// 有界的处理时间Row-count over window (时间字段 "rowtime"，之前10行)</span></span><br><span class="line"><span class="string">.window(Over partitionBy '</span>a orderBy <span class="string">'proctime preceding 10.rows as '</span>w)</span><br></pre></td></tr></table></figure><h3 id="SQL中窗口的定义"><a href="#SQL中窗口的定义" class="headerlink" title="SQL中窗口的定义"></a>SQL中窗口的定义</h3><p>我们已经了解了在Table API里window的调用方式，同样，我们也可以在SQL中直接加入窗口的定义和使用。</p><h4 id="Group-Windows"><a href="#Group-Windows" class="headerlink" title="Group Windows"></a>Group Windows</h4><p>Group Windows在SQL查询的Group BY子句中定义。与使用常规GROUP BY子句的查询一样，使用GROUP BY子句的查询会计算每个组的单个结果行。</p><p>SQL支持以下Group窗口函数:</p><ul><li>TUMBLE(time_attr, interval)</li></ul><p>定义一个滚动窗口，第一个参数是时间字段，第二个参数是窗口长度。</p><ul><li>HOP(time_attr, interval, interval)</li></ul><p>定义一个滑动窗口，第一个参数是时间字段，第二个参数是窗口滑动步长，第三个是窗口长度。</p><ul><li>SESSION(time_attr, interval)</li></ul><p>定义一个会话窗口，第一个参数是时间字段，第二个参数是窗口间隔（Gap）。</p><p>另外还有一些辅助函数，可以用来选择Group Window的开始和结束时间戳，以及时间属性。</p><p>这里只写TUMBLE_<em>，滑动和会话窗口是类似的（HOP_</em>，SESSION_*）。</p><ul><li>TUMBLE_START(time_attr, interval)</li><li>TUMBLE_END(time_attr, interval)</li><li>TUMBLE_ROWTIME(time_attr, interval)</li><li>TUMBLE_PROCTIME(time_attr, interval)</li></ul><h4 id="Over-Windows-1"><a href="#Over-Windows-1" class="headerlink" title="Over Windows"></a>Over Windows</h4><p>由于Over本来就是SQL内置支持的语法，所以这在SQL中属于基本的聚合操作。所有聚合必须在同一窗口上定义，也就是说，必须是相同的分区、排序和范围。目前仅支持在当前行范围之前的窗口（无边界和有边界）。</p><p>注意，ORDER BY必须在单一的时间属性上指定。</p><p>代码如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(amount) <span class="keyword">OVER</span> (</span><br><span class="line">  <span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">user</span></span><br><span class="line">  <span class="keyword">ORDER</span> <span class="keyword">BY</span> proctime</span><br><span class="line">  <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">2</span> <span class="keyword">PRECEDING</span> <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="keyword">ROW</span>)</span><br><span class="line"><span class="keyword">FROM</span> Orders</span><br><span class="line"></span><br><span class="line">// 也可以做多个聚合</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(amount) <span class="keyword">OVER</span> w, <span class="keyword">SUM</span>(amount) <span class="keyword">OVER</span> w</span><br><span class="line"><span class="keyword">FROM</span> Orders</span><br><span class="line"><span class="keyword">WINDOW</span> w <span class="keyword">AS</span> (</span><br><span class="line">  <span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">user</span></span><br><span class="line">  <span class="keyword">ORDER</span> <span class="keyword">BY</span> proctime</span><br><span class="line">  <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">2</span> <span class="keyword">PRECEDING</span> <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="keyword">ROW</span>)</span><br></pre></td></tr></table></figure><h3 id="CASE"><a href="#CASE" class="headerlink" title="CASE"></a>CASE</h3><p>开一个滚动窗口，统计10秒内出现的每个sensor的个数。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">env.setParallelism(<span class="number">1</span>)</span><br><span class="line">env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> streamFromFile: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">"sensor.txt"</span>)</span><br><span class="line"><span class="keyword">val</span> dataStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = streamFromFile</span><br><span class="line">.map( data =&gt; </span><br><span class="line">     &#123;</span><br><span class="line"><span class="keyword">val</span> dataArray = data.split(<span class="string">","</span>)</span><br><span class="line"><span class="type">SensorReading</span>(dataArray(<span class="number">0</span>).trim, dataArray(<span class="number">1</span>).trim.toLong, dataArray(<span class="number">2</span>).trim.toDouble)</span><br><span class="line">&#125; )</span><br><span class="line">.assignTimestampsAndWatermarks( <span class="keyword">new</span> <span class="type">BoundedOutOfOrdernessTimestampExtractor</span>[<span class="type">SensorReading</span>](<span class="type">Time</span>.seconds(<span class="number">1</span>)) &#123;</span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">extractTimestamp</span></span>(element: <span class="type">SensorReading</span>): <span class="type">Long</span> = element.timestamp * <span class="number">1000</span>L</span><br><span class="line">&#125; )</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> settings: <span class="type">EnvironmentSettings</span> = <span class="type">EnvironmentSettings</span></span><br><span class="line">.newInstance()</span><br><span class="line">                                        .useOldPlanner()</span><br><span class="line">                                        .inStreamingMode()</span><br><span class="line">                                        .build()</span><br><span class="line"><span class="keyword">val</span> tableEnv: <span class="type">StreamTableEnvironment</span> = </span><br><span class="line"><span class="type">StreamTableEnvironment</span>.create(env, settings)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> dataTable: <span class="type">Table</span> = tableEnv</span><br><span class="line">.fromDataStream(dataStream, <span class="symbol">'id</span>, <span class="symbol">'temperature</span>, <span class="symbol">'timestamp</span>.rowtime)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultTable: <span class="type">Table</span> = dataTable</span><br><span class="line">                                .window(<span class="type">Tumble</span> over <span class="number">10.</span>seconds on <span class="symbol">'timestamp</span> as <span class="symbol">'tw</span>)</span><br><span class="line">                                .groupBy(<span class="symbol">'id</span>, <span class="symbol">'tw</span>)</span><br><span class="line">                                .select(<span class="symbol">'id</span>, <span class="symbol">'id</span>.count)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> sqlDataTable: <span class="type">Table</span> = dataTable</span><br><span class="line">.select(<span class="symbol">'id</span>, <span class="symbol">'temperature</span>, <span class="symbol">'timestamp</span> as <span class="symbol">'ts</span>)</span><br><span class="line"><span class="keyword">val</span> resultSqlTable: <span class="type">Table</span> = tableEnv</span><br><span class="line">.sqlQuery(<span class="string">"select id, count(id) from "</span> </span><br><span class="line">+ sqlDataTable </span><br><span class="line">+ <span class="string">" group by id,tumble(ts,interval '10' second)"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 把 Table转化成数据流</span></span><br><span class="line"><span class="keyword">val</span> resultDstream: <span class="type">DataStream</span>[(<span class="type">Boolean</span>, (<span class="type">String</span>, <span class="type">Long</span>))] = resultSqlTable.toRetractStream[(<span class="type">String</span>, <span class="type">Long</span>)]</span><br><span class="line"></span><br><span class="line">resultDstream.filter(_._1).print()</span><br><span class="line">env.execute()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><p>Flink Table 和 SQL内置了很多SQL中支持的函数；如果有无法满足的需要，则可以实现用户自定义的函数（UDF）来解决。</p><h3 id="系统内置函数"><a href="#系统内置函数" class="headerlink" title="系统内置函数"></a>系统内置函数</h3><p>Flink Table API 和 SQL为用户提供了一组用于数据转换的内置函数。SQL中支持的很多函数，Table API和SQL都已经做了实现，其它还在快速开发扩展中。</p><p>以下是一些典型函数的举例，全部的内置函数，可以参考官网介绍。</p><table><thead><tr><th>内置函数</th><th>SQL</th><th>Table API</th></tr></thead><tbody><tr><td>判断比较</td><td>value1 = value2</td><td>ANY1 === ANY2</td></tr><tr><td></td><td>value1 &gt; value2</td><td>ANY1 &gt; ANY2</td></tr><tr><td>逻辑函数</td><td>boolean1 OR boolean2</td><td>BOOLEAN1</td></tr><tr><td></td><td>boolean IS FALSE</td><td>BOOLEAN.isFalse</td></tr><tr><td></td><td>NOT boolean</td><td>!BOOLEAN</td></tr><tr><td>算数函数</td><td>numeric1 + numeric2</td><td>NUMERIC1 + NUMERIC2</td></tr><tr><td></td><td>POWER(numeric1, numeric2)</td><td>NUMERIC1.power(NUMERIC2)</td></tr><tr><td>字符串函数</td><td>string1 丨丨 string2</td><td>string1 + string2</td></tr><tr><td></td><td>UPPER(string)</td><td>String.upperCase()</td></tr><tr><td></td><td>CHAR_LENGTH(string)</td><td>STRING.charLength()</td></tr><tr><td>时间函数</td><td>DATE string</td><td>STRING.toDate</td></tr><tr><td></td><td>TIMESTAMP string</td><td>STRING.toTimestamp</td></tr><tr><td></td><td>CURRENT_TIME</td><td>currentTime()</td></tr><tr><td></td><td>INTERVAL string range</td><td>NUMERIC.days</td></tr><tr><td></td><td></td><td>NUMERIC.minutes</td></tr><tr><td>聚合函数</td><td>COUNT(*)</td><td>FIELD.count</td></tr><tr><td></td><td>SUM([ALL丨DISTINCT] expression)</td><td>FIELD.sum0</td></tr><tr><td></td><td>RANK()</td><td></td></tr><tr><td></td><td>ROW_NUMBER()</td></tr></tbody></table><h3 id="UDF"><a href="#UDF" class="headerlink" title="UDF"></a>UDF</h3><p>在大多数情况下，用户定义的函数必须先注册，然后才能在查询中使用。不需要专门为Scala 的Table API注册函数。</p><p>函数通过调用registerFunction（）方法在TableEnvironment中注册。当用户定义的函数被注册时，它被插入到TableEnvironment的函数目录中，这样Table API或SQL解析器就可以识别并正确地解释它。</p><h4 id="标量函数"><a href="#标量函数" class="headerlink" title="标量函数"></a>标量函数</h4><p>用户定义的标量函数，可以将0、1或多个标量值，映射到新的标量值。</p><p>为了定义标量函数，必须在org.apache.flink.table.functions中扩展基类Scalar Function，并实现（一个或多个）求值（evaluation，eval）方法。标量函数的行为由求值方法决定，求值方法必须公开声明并命名为eval（直接def声明，没有override）。求值方法的参数类型和返回类型，确定了标量函数的参数和返回类型。</p><p>在下面的代码中，我们定义自己的HashCode函数，在TableEnvironment中注册它，并在查询中调用它。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 自定义一个标量函数</span></span><br><span class="line">class HashCode( factor: Int ) extends ScalarFunction &#123;</span><br><span class="line">  <span class="function">def <span class="title">eval</span><span class="params">( s: String )</span>: Int </span>= &#123;</span><br><span class="line">    s.hashCode * factor</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>主函数中调用，计算sensor id的哈希值（前面部分照抄，流环境、表环境、读取source、建表）：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">  env.setParallelism(<span class="number">1</span>)</span><br><span class="line">  env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> settings = <span class="type">EnvironmentSettings</span></span><br><span class="line">    .newInstance()</span><br><span class="line">    .useOldPlanner()</span><br><span class="line">    .inStreamingMode()</span><br><span class="line">    .build()</span><br><span class="line">  <span class="keyword">val</span> tableEnv = <span class="type">StreamTableEnvironment</span>.create( env, settings )</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 定义好 DataStream</span></span><br><span class="line">  <span class="keyword">val</span> inputStream: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">"..\\sensor.txt"</span>)</span><br><span class="line">  <span class="keyword">val</span> dataStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = inputStream</span><br><span class="line">    .map(data =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> dataArray = data.split(<span class="string">","</span>)</span><br><span class="line">      <span class="type">SensorReading</span>(dataArray(<span class="number">0</span>), dataArray(<span class="number">1</span>).toLong, dataArray(<span class="number">2</span>).toDouble)</span><br><span class="line">    &#125;)</span><br><span class="line">    .assignAscendingTimestamps(_.timestamp * <span class="number">1000</span>L)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将 DataStream转换为 Table，并指定时间字段</span></span><br><span class="line">  <span class="keyword">val</span> sensorTable = tableEnv.fromDataStream(dataStream, <span class="symbol">'id</span>, <span class="symbol">'timestamp</span>.rowtime, <span class="symbol">'temperature</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Table API中使用</span></span><br><span class="line">  <span class="keyword">val</span> hashCode = <span class="keyword">new</span> <span class="type">HashCode</span>(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> resultTable = sensorTable</span><br><span class="line">    .select( <span class="symbol">'id</span>, hashCode(<span class="symbol">'id</span>) )</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// SQL 中使用</span></span><br><span class="line">  tableEnv.createTemporaryView(<span class="string">"sensor"</span>, sensorTable)</span><br><span class="line">  tableEnv.registerFunction(<span class="string">"hashCode"</span>, hashCode)</span><br><span class="line">  <span class="keyword">val</span> resultSqlTable = tableEnv.sqlQuery(<span class="string">"select id, hashCode(id) from sensor"</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 转换成流，打印输出</span></span><br><span class="line">  resultTable.toAppendStream[<span class="type">Row</span>].print(<span class="string">"table"</span>)</span><br><span class="line">  resultSqlTable.toAppendStream[<span class="type">Row</span>].print(<span class="string">"sql"</span>)</span><br><span class="line"> </span><br><span class="line">  env.execute()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="表函数（Table-Functions）"><a href="#表函数（Table-Functions）" class="headerlink" title="表函数（Table Functions）"></a>表函数（Table Functions）</h4><p>与用户定义的标量函数类似，用户定义的表函数，可以将0、1或多个标量值作为输入参数；与标量函数不同的是，它可以返回任意数量的行作为输出，而不是单个值。</p><p>为了定义一个表函数，必须扩展org.apache.flink.table.functions中的基类TableFunction并实现（一个或多个）求值方法。表函数的行为由其求值方法决定，求值方法必须是public的，并命名为eval。求值方法的参数类型，决定表函数的所有有效参数。</p><p>返回表的类型由TableFunction的泛型类型确定。求值方法使用protected collect（T）方法发出输出行。</p><p>在Table API中，Table函数需要与.joinLateral或.leftOuterJoinLateral一起使用。</p><p>joinLateral算子，会将外部表中的每一行，与表函数（TableFunction，算子的参数是它的表达式）计算得到的所有行连接起来。</p><p>而leftOuterJoinLateral算子，则是左外连接，它同样会将外部表中的每一行与表函数计算生成的所有行连接起来；并且，对于表函数返回的是空表的外部行，也要保留下来。</p><p>在SQL中，则需要使用Lateral Table（<tablefunction>），或者带有ON TRUE条件的左连接。</tablefunction></p><p>下面的代码中，我们将定义一个表函数，在表环境中注册它，并在查询中调用它。</p><p>自定义TableFunction：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 自定义TableFunction</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Split</span>(<span class="params">separator: <span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">TableFunction</span>[(<span class="type">String</span>, <span class="type">Int</span>)]</span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">eval</span></span>(str: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    str.split(separator).foreach(</span><br><span class="line">      word =&gt; collect((word, word.length))</span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来，就是在代码中调用。首先是Table API的方式：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Table API中调用，需要用joinLateral</span></span><br><span class="line">    <span class="keyword">val</span> resultTable = sensorTable</span><br><span class="line">      .joinLateral(split(<span class="symbol">'id</span>) as (<span class="symbol">'word</span>, <span class="symbol">'length</span>))   <span class="comment">// as对输出行的字段重命名</span></span><br><span class="line">      .select(<span class="symbol">'id</span>, <span class="symbol">'word</span>, <span class="symbol">'length</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment">// 或者用leftOuterJoinLateral</span></span><br><span class="line">    <span class="keyword">val</span> resultTable2 = sensorTable</span><br><span class="line">      .leftOuterJoinLateral(split(<span class="symbol">'id</span>) as (<span class="symbol">'word</span>, <span class="symbol">'length</span>))</span><br><span class="line">      .select(<span class="symbol">'id</span>, <span class="symbol">'word</span>, <span class="symbol">'length</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 转换成流打印输出</span></span><br><span class="line">    resultTable.toAppendStream[<span class="type">Row</span>].print(<span class="string">"1"</span>)</span><br><span class="line">    resultTable2.toAppendStream[<span class="type">Row</span>].print(<span class="string">"2"</span>)</span><br></pre></td></tr></table></figure><p>然后是SQL的方式</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.createTemporaryView(<span class="string">"sensor"</span>, sensorTable)</span><br><span class="line">tableEnv.registerFunction(<span class="string">"split"</span>, split)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultSqlTable = tableEnv.sqlQuery(</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |select id, word, length</span></span><br><span class="line"><span class="string">    |from</span></span><br><span class="line"><span class="string">    |sensor, LATERAL TABLE(split(id)) AS newsensor(word, length)</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 或者用左连接的方式</span></span><br><span class="line"><span class="keyword">val</span> resultSqlTable2 = tableEnv.sqlQuery(</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |SELECT id, word, length</span></span><br><span class="line"><span class="string">    |FROM</span></span><br><span class="line"><span class="string">    |sensor</span></span><br><span class="line"><span class="string">    |LEFT JOIN </span></span><br><span class="line"><span class="string">    |LATERAL TABLE(split(id)) AS newsensor(word, length) </span></span><br><span class="line"><span class="string">    |ON TRUE</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 转换成流打印输出</span></span><br><span class="line">resultSqlTable.toAppendStream[<span class="type">Row</span>].print(<span class="string">"1"</span>)</span><br><span class="line">resultSqlTable2.toAppendStream[<span class="type">Row</span>].print(<span class="string">"2"</span>)</span><br></pre></td></tr></table></figure><h4 id="聚合函数-aggregate-Function"><a href="#聚合函数-aggregate-Function" class="headerlink" title="聚合函数(aggregate Function)"></a>聚合函数(aggregate Function)</h4><p>用户自定义聚合函数（User-Defined Aggregate Functions，UDAGGs）可以把一个表中的数据，聚合成一个标量值。用户定义的聚合函数，是通过继承AggregateFunction抽象类实现的。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gejnzvbpitj20jf0b6jsm.jpg" alt="1.png"></p><p>上图中显示了一个聚合的例子。</p><p>假设现在有一张表，包含了各种饮料的数据。该表由三列（id、name和price）、五行组成数据。现在我们需要找到表中所有饮料的最高价格，即执行max（）聚合，结果将是一个数值。</p><p>AggregateFunction的工作原理如下。</p><ul><li><p>首先，它需要一个累加器，用来保存聚合中间结果的数据结构（状态）。可以通过调用AggregateFunction的createAccumulator（）方法创建空累加器。</p></li><li><p>随后，对每个输入行调用函数的accumulate（）方法来更新累加器。</p></li><li><p>处理完所有行后，将调用函数的getValue（）方法来计算并返回最终结果。</p></li></ul><p>AggregationFunction要求必须实现的方法：</p><ul><li><p>createAccumulator()</p></li><li><p>accumulate()</p></li><li><p>getValue()</p></li></ul><p>除了上述方法之外，还有一些可选择实现的方法。其中一些方法，可以让系统执行查询更有效率，而另一些方法，对于某些场景是必需的。例如，如果聚合函数应用在会话窗口（session group window）的上下文中，则merge（）方法是必需的。</p><ul><li><p>retract() </p></li><li><p>merge() </p></li><li><p>resetAccumulator()</p></li></ul><p>除了上述方法之外，还有一些可选择实现的方法。其中一些方法，可以让系统执行查询更有效率，而另一些方法，对于某些场景是必需的。例如，如果聚合函数应用在会话窗口（session group window）的上下文中，则merge（）方法是必需的。</p><ul><li>retract()</li><li>merge()</li><li>resetAccumulator()</li></ul><p>接下来自定义AggregateFunction,计算一下每个sensor的平均温度值。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义AggregateFunction的Accumulator</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AvgTempAcc</span> </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> sum: <span class="type">Double</span> = <span class="number">0.0</span></span><br><span class="line">  <span class="keyword">var</span> count: <span class="type">Int</span> = <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AvgTemp</span> <span class="keyword">extends</span> <span class="title">AggregateFunction</span>[<span class="type">Double</span>, <span class="type">AvgTempAcc</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValue</span></span>(accumulator: <span class="type">AvgTempAcc</span>): <span class="type">Double</span> =</span><br><span class="line">    accumulator.sum / accumulator.count</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createAccumulator</span></span>(): <span class="type">AvgTempAcc</span> = <span class="keyword">new</span> <span class="type">AvgTempAcc</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">accumulate</span></span>(accumulator: <span class="type">AvgTempAcc</span>, temp: <span class="type">Double</span>): <span class="type">Unit</span> =&#123;</span><br><span class="line">    accumulator.sum += temp</span><br><span class="line">    accumulator.count += <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来就可以在代码中调用了</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建一个聚合函数实例</span></span><br><span class="line"><span class="keyword">val</span> avgTemp = <span class="keyword">new</span> <span class="type">AvgTemp</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">// Table API的调用 </span></span><br><span class="line"><span class="keyword">val</span> resultTable = sensorTable.groupBy(<span class="symbol">'id</span>)</span><br><span class="line">  .aggregate(avgTemp(<span class="symbol">'temperature</span>) as <span class="symbol">'avgTemp</span>)</span><br><span class="line">  .select(<span class="symbol">'id</span>, <span class="symbol">'avgTemp</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// SQL的实现</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">"sensor"</span>, sensorTable)</span><br><span class="line">tableEnv.registerFunction(<span class="string">"avgTemp"</span>, avgTemp)</span><br><span class="line"><span class="keyword">val</span> resultSqlTable = tableEnv.sqlQuery(</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |SELECT</span></span><br><span class="line"><span class="string">    |id, avgTemp(temperature)</span></span><br><span class="line"><span class="string">    |FROM</span></span><br><span class="line"><span class="string">    |sensor</span></span><br><span class="line"><span class="string">    |GROUP BY id</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 转换成流打印输出</span></span><br><span class="line">resultTable.toRetractStream[(<span class="type">String</span>, <span class="type">Double</span>)].print(<span class="string">"agg temp"</span>)</span><br><span class="line">resultSqlTable.toRetractStream[<span class="type">Row</span>].print(<span class="string">"agg temp sql"</span>)</span><br></pre></td></tr></table></figure><h3 id="表聚合函数（Table-Aggregate-Functions）"><a href="#表聚合函数（Table-Aggregate-Functions）" class="headerlink" title="表聚合函数（Table Aggregate Functions）"></a>表聚合函数（Table Aggregate Functions）</h3><p>用户定义的表聚合函数（User-Defined Table Aggregate Functions，UDTAGGs），可以把一个表中数据，聚合为具有多行和多列的结果表。这跟AggregateFunction非常类似，只是之前聚合结果是一个标量值，现在变成了一张表。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gejo6fdbb4j20je09cta0.jpg" alt="2.png"></p><p>比如现在我们需要找到表中所有饮料的前2个最高价格，即执行top2（）表聚合。我们需要检查5行中的每一行，得到的结果将是一个具有排序后前2个值的表。</p><p>用户定义的表聚合函数，是通过继承TableAggregateFunction抽象类来实现的。</p><p>TableAggregateFunction的工作原理如下。</p><ul><li><p>首先，它同样需要一个累加器（Accumulator），它是保存聚合中间结果的数据结构。通过调用TableAggregateFunction的createAccumulator（）方法可以创建空累加器。</p></li><li><p>随后，对每个输入行调用函数的accumulate（）方法来更新累加器。</p></li><li><p>处理完所有行后，将调用函数的emitValue（）方法来计算并返回最终结果。</p></li></ul><p>AggregationFunction要求必须实现的方法：</p><ul><li><p>createAccumulator()</p></li><li><p>accumulate()</p></li></ul><p>除了上述方法之外，还有一些可选择实现的方法。</p><ul><li>retract() </li><li>merge()  </li><li>resetAccumulator() </li><li>emitValue() </li><li>emitUpdateWithRetract()</li></ul><p>接下来我们写一个自定义TableAggregateFunction，用来提取每个sensor最高的两个温度值。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 先定义一个 Accumulator </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Top2TempAcc</span></span>&#123;</span><br><span class="line">  <span class="keyword">var</span> highestTemp: <span class="type">Double</span> = <span class="type">Int</span>.<span class="type">MinValue</span></span><br><span class="line">  <span class="keyword">var</span> secondHighestTemp: <span class="type">Double</span> = <span class="type">Int</span>.<span class="type">MinValue</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 自定义 TableAggregateFunction</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Top2Temp</span> <span class="keyword">extends</span> <span class="title">TableAggregateFunction</span>[(<span class="type">Double</span>, <span class="type">Int</span>), <span class="type">Top2TempAcc</span>]</span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createAccumulator</span></span>(): <span class="type">Top2TempAcc</span> = <span class="keyword">new</span> <span class="type">Top2TempAcc</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">accumulate</span></span>(acc: <span class="type">Top2TempAcc</span>, temp: <span class="type">Double</span>): <span class="type">Unit</span> =&#123;</span><br><span class="line">    <span class="keyword">if</span>( temp &gt; acc.highestTemp )&#123;</span><br><span class="line">      acc.secondHighestTemp = acc.highestTemp</span><br><span class="line">      acc.highestTemp = temp</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span>( temp &gt; acc.secondHighestTemp )&#123;</span><br><span class="line">      acc.secondHighestTemp = temp</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">emitValue</span></span>(acc: <span class="type">Top2TempAcc</span>, out: <span class="type">Collector</span>[(<span class="type">Double</span>, <span class="type">Int</span>)]): <span class="type">Unit</span> =&#123;</span><br><span class="line">    out.collect(acc.highestTemp, <span class="number">1</span>)</span><br><span class="line">    out.collect(acc.secondHighestTemp, <span class="number">2</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来就可以在代码中调用了。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建一个表聚合函数实例</span></span><br><span class="line"><span class="keyword">val</span> top2Temp = <span class="keyword">new</span> <span class="type">Top2Temp</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">// Table API的调用</span></span><br><span class="line"><span class="keyword">val</span> resultTable = sensorTable.groupBy(<span class="symbol">'id</span>)</span><br><span class="line">  .flatAggregate( top2Temp(<span class="symbol">'temperature</span>) as (<span class="symbol">'temp</span>, <span class="symbol">'rank</span>) )</span><br><span class="line">  .select(<span class="symbol">'id</span>, <span class="symbol">'temp</span>, <span class="symbol">'rank</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 转换成流打印输出</span></span><br><span class="line">resultTable.toRetractStream[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Int</span>)].print(<span class="string">"agg temp"</span>)</span><br><span class="line">resultSqlTable.toRetractStream[<span class="type">Row</span>].print(<span class="string">"agg temp sql"</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Flink Table 和 SQL 整体的脉络&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/bec9bff2gy1gejppurwd5j20ib046t9h.jpg&quot; alt=&quot;3.png&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Apache" scheme="http://yoursite.com/categories/Apache/"/>
    
      <category term="Flink" scheme="http://yoursite.com/categories/Apache/Flink/"/>
    
    
  </entry>
  
  <entry>
    <title>Flink State</title>
    <link href="http://yoursite.com/2020/04/26/Flink%20State/"/>
    <id>http://yoursite.com/2020/04/26/Flink State/</id>
    <published>2020-04-26T03:38:39.811Z</published>
    <updated>2020-04-26T03:42:22.120Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Flink State的使用经验和平时一些注意不到的属性</p></blockquote><a id="more"></a> <h1 id="Flink-State"><a href="#Flink-State" class="headerlink" title="Flink State"></a>Flink State</h1><h2 id="Flink-State-的种类"><a href="#Flink-State-的种类" class="headerlink" title="Flink State 的种类"></a>Flink State 的种类</h2><p>定义：流式计算中持久化来的状态</p><p>两种不同的 state：operator state 以及 keyed state。</p><p>区别：</p><p><strong>是否存在当前处理的 key</strong>（current key）：operator state 是没有当前 key 的概念，而 keyed state 的数值总是与一个 current key 对应。</p><p><strong>是否存在当前处理的 key</strong>（current key）：operator state 是没有当前 key 的概念，而 keyed state 的数值总是与一个 current key 对应。</p><p><strong>是否需要手动声明快照</strong>（snapshot）<strong>和恢复</strong> (restore) <strong>方法</strong>：operator state 需要手动实现 snapshot 和 restore 方法；而 keyed state 则由 backend 自行实现，对用户透明。</p><p><strong>数据大小</strong>：一般而言，我们认为 operator state 的数据规模是比较小的；认为 keyed state 规模是相对比较大的。需要注意的是，这是一个经验判断，不是一个绝对的判断区分标准。</p><p>生产中，我们会在 FsStateBackend 和 RocksDBStateBackend 间选择：</p><ul><li><strong>FsStateBackend</strong>：性能更好；日常存储是在堆内存中，面临着 OOM 的风险，不支持增量 checkpoint。</li><li><strong>RocksDBStateBackend</strong>：无需担心 OOM 风险，是大部分时候的选择。</li></ul><p><strong>RocksDB StateBackend 概览和相关配置讨论</strong></p><p>RocksDB 是 Facebook 开源的 LSM 的键值存储数据库，被广泛应用于大数据系统的单机组件中。Flink 的 keyed state 本质上来说就是一个键值对，所以与 RocksDB 的数据模型是吻合的。下图分别是 “window state” 和 “value state” 在 RocksDB 中的存储格式，所有存储的 key，value 均被序列化成 bytes 进行存储。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1ge6ze2rcs8j20oz09sglx.jpg" alt="undefined"></p><p>在 RocksDB 中，每个 state 独享一个 Column Family，而每个 Column family 使用各自独享的 write buffer 和 block cache，上图中的 window state 和 value state实际上分属不同的 column family。</p><p>下面介绍一些对 RocksDB 性能比较有影响的参数，并整理了一些相关的推荐配置，至于其他配置项，可以参阅社区相关文档。</p><table><thead><tr><th>state.backend.rocksdb.thread.num</th><th>后台 flush 和 compaction 的线程数. 默认值 ‘1‘. 建议调大</th></tr></thead><tbody><tr><td>state.backend.rocksdb.writebuffer.count</td><td>每个 column family 的 write buffer 数目，默认值 ‘2‘. 如果有需要可以适当调大</td></tr><tr><td>state.backend.rocksdb.writebuffer.size</td><td>每个 write buffer 的 size，默认值‘64MB‘. 对于写频繁的场景，建议调大</td></tr><tr><td>state.backend.rocksdb.block.cache-size</td><td>每个 column family 的 block cache大小，默认值‘8MB’，如果存在重复读的场景，建议调大</td></tr></tbody></table><h2 id="State-best-practice"><a href="#State-best-practice" class="headerlink" title="State best practice"></a>State best practice</h2><p>■ <strong>慎重使用长 list</strong></p><p>下图展示的是目前 task 端 operator state 在执行完 checkpoint 返回给 job master 端的 StateMetaInfo 的代码片段。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1ge6zual0gdj20oz0a0jrv.jpg" alt="undefined"></p><p>由于 operator state 没有 key group 的概念，所以为了实现改并发恢复的功能，需要对 operator state 中的每一个序列化后的元素存储一个位置偏移 offset，也就是构成了上图红框中的 offset 数组。</p><p>那么如果你的 operator state 中的 list 长度达到一定规模时，这个 offset 数组就可能会有几十 MB 的规模，关键这个数组是会返回给 job master，当 operator 的并发数目很大时，很容易触发 job master 的内存超用问题。我们遇到过用户把 operator state 当做黑名单存储，结果这个黑名单规模很大，导致一旦开始执行 checkpoint，job master 就会因为收到 task 发来的“巨大”的 offset 数组，而内存不断增长直到超用无法正常响应。</p><p>■ <strong>正确使用 UnionListState</strong></p><p>union list state 目前被广泛使用在 kafka connector 中，不过可能用户日常开发中较少遇到，他的语义是从检查点恢复之后每个并发 task 内拿到的是原先所有operator 上的 state，如下图所示：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1ge6zuxdx96j20nl0930sn.jpg" alt="undefined"></p><p>kafka connector 使用该功能，为的是从检查点恢复时，可以拿到之前的全局信息，如果用户需要使用该功能，需要切记恢复的 task 只取其中的一部分进行处理和用于下一次 snapshot，否则有可能随着作业不断的重启而导致 state 规模不断增长。</p><h2 id="Keyed-state-使用建议"><a href="#Keyed-state-使用建议" class="headerlink" title="Keyed state 使用建议"></a>Keyed state 使用建议</h2><p>■ <strong>如何正确清空当前的 state</strong></p><p>state.clear() 实际上只能清理当前 key 对应的 value 值，如果想要清空整个 state，需要借助于 applyToAllKeys 方法，具体代码片段如下：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1ge6zvn0chzj20oz04odfx.jpg" alt="undefined"></p><p>如果你的需求中只是对 state 有过期需求，借助于 state TTL 功能来清理会是一个性能更好的方案。</p><p><strong>■ RocksDB 中考虑 value 值很大的极限场景</strong></p><p>受限于 JNI bridge API 的限制，单个 value 只支持 2^31 bytes 大小，如果存在很极限的情况，可以考虑使用 MapState 来替代 ListState 或者 ValueState，因为RocksDB 的 map state 并不是将整个 map 作为 value 进行存储，而是将 map 中的一个条目作为键值对进行存储。</p><p><strong>■ 如何知道当前 RocksDB 的运行情况</strong></p><p>比较直观的方式是打开 RocksDB 的 native metrics ，在默认使用 Flink managed memory 方式的情况下，state.backend.rocksdb.metrics.block-cache-usage ，state.backend.rocksdb.metrics.mem-table-flush-pending，state.backend.rocksdb.metrics.num-running-compactions 以及 state.backend.rocksdb.metrics.num-running-flushes 是比较重要的相关 metrics。</p><p>下面这张图是 Flink-1.10 之后，打开相关 metrics 的示例图：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1ge6zw28irmj20oz0e2aaq.jpg" alt="undefined"></p><p>而下面这张是 Flink-1.10 之前或者关闭 state.backend.rocksdb.memory.managed  的效果：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1ge6zwe0hczj20oz0e0aas.jpg" alt="undefined"></p><p>■ <strong>容器内运行的 RocksDB 的内存超用问题</strong></p><p>在 Flink-1.10 之前，由于一个 state 独占若干 write buffer 和一块 block cache，所以我们会建议用户不要在一个 operator 内创建过多的 state，否则需要考虑到相应的额外内存使用量，否则容易造成在容器内运行时，相关进程被容器环境所杀。对于用户来说，需要考虑一个 slot 内有多少 RocksDB 实例在运行，一个 RocksDB 中有多少 state，整体的计算规则就很复杂，很难真得落地实施。</p><p>Flink-1.10 之后，由于引入了 RocksDB 的内存托管机制，在绝大部分情况下， RocksDB 的这一部分 native 内存是可控的，不过受限于 RocksDB 的相关 cache 实现限制（这里暂不展开，后续会有文章讨论），在某些场景下，无法做到完美控制，这时候建议打开上文提到的 native metrics，观察相关 block cache 内存使用是否存在超用情况，可以将相关内存添加到 taskmanager.memory.task.off-heap.size 中，使得 Flink 有更多的空间给 native 内存使用。</p><p>■ <strong>Checkpoint 间隔不要太短</strong></p><p>虽然理论上 Flink 支持很短的 checkpoint 间隔，但是在实际生产中，过短的间隔对于底层分布式文件系统而言，会带来很大的压力。另一方面，由于检查点的语义，所以实际上 Flink 作业处理 record 与执行 checkpoint 存在互斥锁，过于频繁的 checkpoint，可能会影响整体的性能。当然，这个建议的出发点是底层分布式文件系统的压力考虑。</p><p>■ <strong>合理设置超时时间</strong></p><p>默认的超时时间是 10min，如果 state 规模大，则需要合理配置。最坏情况是分布式地创建速度大于单点（job master 端）的删除速度，导致整体存储集群可用空间压力较大。建议当检查点频繁因为超时而失败时，增大超时时间。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Flink State的使用经验和平时一些注意不到的属性&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Apache" scheme="http://yoursite.com/categories/Apache/"/>
    
      <category term="Flink" scheme="http://yoursite.com/categories/Apache/Flink/"/>
    
    
      <category term="Flink" scheme="http://yoursite.com/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Git详解</title>
    <link href="http://yoursite.com/2020/04/13/Git%E8%AF%A6%E8%A7%A3/"/>
    <id>http://yoursite.com/2020/04/13/Git详解/</id>
    <published>2020-04-13T06:48:17.587Z</published>
    <updated>2020-05-07T06:16:46.328Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>讨论了许多种git的情况，非常详细的git报告</p></blockquote><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gds54g3odrj206402kmwz.jpg" alt="undefined"><br><a id="more"></a> </p><h1 id="Git超详细"><a href="#Git超详细" class="headerlink" title="Git超详细"></a>Git超详细</h1><h4 id="Git是什么"><a href="#Git是什么" class="headerlink" title="Git是什么"></a>Git是什么</h4><p>Git是目前世界上最先进的分布式版本控制系统。</p><h4 id="SVN与Git的最主要的区别"><a href="#SVN与Git的最主要的区别" class="headerlink" title="SVN与Git的最主要的区别"></a><strong>SVN与Git的最主要的区别</strong></h4><p>SVN是集中式版本控制系统，版本库是集中放在中央服务器的，而干活的时候，用的都是自己的电脑，所以首先要从中央服务器哪里得到最新的版本，然后干活，干完后，需要把自己做完的活推送到中央服务器。集中式版本控制系统是必须联网才能工作，如果在局域网还可以，带宽够大，速度够快，如果在互联网下，如果网速慢的话，就纳闷了。</p><p>   Git是分布式版本控制系统，那么它就没有中央服务器的，每个人的电脑就是一个完整的版本库，这样，工作的时候就不需要联网了，因为版本都是在自己的电脑上。既然每个人的电脑都有一个完整的版本库，那多个人如何协作呢？比如说自己在电脑上改了文件A，其他人也在电脑上改了文件A，这时，你们两之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。</p><h4 id="创建版本库"><a href="#创建版本库" class="headerlink" title="创建版本库"></a>创建版本库</h4><p>   什么是版本库？版本库又名仓库，英文名repository,你可以简单的理解一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改，删除，Git都能跟踪，以便任何时刻都可以追踪历史，或者在将来某个时刻还可以将文件”还原”。</p><p>  所以创建一个版本库也非常简单，如下我是D盘 –&gt; www下 目录下新建一个testgit版本库。</p><p>pwd 命令是用于显示当前的目录。</p><p>   \1. 通过命令 git init 把这个目录变成git可以管理的仓库，如下：</p><p><a href="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyr2rpcnj20en025mx9.jpg" target="_blank" rel="noopener"><img src="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyr2rpcnj20en025mx9.jpg" alt="img"></a></p><p>   这时候你当前testgit目录下会多了一个.git的目录，这个目录是Git来跟踪管理版本的，没事千万不要手动乱改这个目录里面的文件，否则，会把git仓库给破坏了。如下：</p><p>  <a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyr1x3lzj20h004tgm1.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyr1x3lzj20h004tgm1.jpg" alt="img"></a></p><h4 id="把文件添加到版本库中"><a href="#把文件添加到版本库中" class="headerlink" title="把文件添加到版本库中"></a>把文件添加到版本库中</h4><p>​     首先要明确下，所有的版本控制系统，只能跟踪文本文件的改动，比如txt文件，网页，所有程序的代码等，Git也不列外，版本控制系统可以告诉你每次的改动，但是图片，视频这些二进制文件，虽能也能由版本控制系统管理，但没法跟踪文件的变化，只能把二进制文件每次改动串起来，也就是知道图片从1kb变成2kb，但是到底改了啥，版本控制也不知道。</p><p>  <strong>下面先看下**</strong>demo<strong>**如下演示：</strong></p><p>   我在版本库testgit目录下新建一个记事本文件 readme.txt 内容如下：11111111</p><p>   第一步：使用命令 git add readme.txt添加到暂存区里面去。如下：</p><p>  <a href="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyr0wkxbj20ch028dfu.jpg" target="_blank" rel="noopener"><img src="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyr0wkxbj20ch028dfu.jpg" alt="img"></a></p><p>  如果和上面一样，没有任何提示，说明已经添加成功了。</p><p>  第二步：用命令 git commit告诉Git，把文件提交到仓库。</p><p>  <a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyqz56axj20dp03djrr.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyqz56axj20dp03djrr.jpg" alt="img"></a></p><p> 现在我们已经提交了一个readme.txt文件了，我们下面可以通过命令git status来查看是否还有文件未提交，如下：</p><p><a href="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyqrg067j20d102zwen.jpg" target="_blank" rel="noopener"><img src="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyqrg067j20d102zwen.jpg" alt="img"></a></p><p> 说明没有任何文件未提交，但是我现在继续来改下readme.txt内容，比如我在下面添加一行2222222222内容，继续使用git status来查看下结果，如下：</p><p> <a href="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyqq7ts6j20h504r74x.jpg" target="_blank" rel="noopener"><img src="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyqq7ts6j20h504r74x.jpg" alt="img"></a></p><p>上面的命令告诉我们 readme.txt文件已被修改，但是未被提交的修改。</p><p>接下来我想看下readme.txt文件到底改了什么内容，如何查看呢？可以使用如下命令：</p><p>git diff readme.txt 如下：</p><p> <a href="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyqnrvxgj20ds05maal.jpg" target="_blank" rel="noopener"><img src="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyqnrvxgj20ds05maal.jpg" alt="img"></a></p><p>如上可以看到，readme.txt文件内容从一行11111111改成 二行 添加了一行22222222内容。</p><p>知道了对readme.txt文件做了什么修改后，我们可以放心的提交到仓库了，提交修改和提交文件是一样的2步(第一步是git add 第二步是：git commit)。</p><p>如下：</p><p> <a href="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyqmcupsj20h609i402.jpg" target="_blank" rel="noopener"><img src="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyqmcupsj20h609i402.jpg" alt="img"></a></p><h4 id="版本回退"><a href="#版本回退" class="headerlink" title="版本回退"></a>版本回退</h4><p>   如上，我们已经学会了修改文件，现在我继续对readme.txt文件进行修改，再增加一行</p><p>内容为33333333333333.继续执行命令如下：</p><p>  <a href="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyql1473j20cp03vdga.jpg" target="_blank" rel="noopener"><img src="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyql1473j20cp03vdga.jpg" alt="img"></a></p><p>现在我已经对readme.txt文件做了三次修改了，那么我现在想查看下历史记录，如何查呢？我们现在可以使用命令 git log 演示如下所示：</p><p> <a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyqd9m1dj20gt08ggn8.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyqd9m1dj20gt08ggn8.jpg" alt="img"></a></p><p>  git log命令显示从最近到最远的显示日志，我们可以看到最近三次提交，最近的一次是,增加内容为333333.上一次是添加内容222222，第一次默认是 111111.如果嫌上面显示的信息太多的话，我们可以使用命令 git log –pretty=oneline 演示如下：</p><p> <a href="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyqc3ziwj20gs02paai.jpg" target="_blank" rel="noopener"><img src="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyqc3ziwj20gs02paai.jpg" alt="img"></a></p><p>  现在我想使用版本回退操作，我想把当前的版本回退到上一个版本，要使用什么命令呢？可以使用如下2种命令，第一种是：git reset –hard HEAD^ 那么如果要回退到上上个版本只需把HEAD^ 改成 HEAD^^ 以此类推。那如果要回退到前100个版本的话，使用上面的方法肯定不方便，我们可以使用下面的简便命令操作：git reset –hard HEAD~100 即可。未回退之前的readme.txt内容如下：</p><p><a href="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyqavyf7j20ch04laap.jpg" target="_blank" rel="noopener"><img src="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyqavyf7j20ch04laap.jpg" alt="img"></a></p><p>如果想回退到上一个版本的命令如下操作：</p><p><a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyqa5xjfj20ct02xaad.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyqa5xjfj20ct02xaad.jpg" alt="img"></a></p><p>再来查看下 readme.txt内容如下：通过命令cat readme.txt查看</p><p><a href="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyq9fck2j20c402d74c.jpg" target="_blank" rel="noopener"><img src="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyq9fck2j20c402d74c.jpg" alt="img"></a></p><p>可以看到，内容已经回退到上一个版本了。我们可以继续使用git log 来查看下历史记录信息，如下：</p><p><a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyq6bhrlj20dc063dgk.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyq6bhrlj20dc063dgk.jpg" alt="img"></a></p><p>我们看到 增加333333 内容我们没有看到了，但是现在我想回退到最新的版本，如：有333333的内容要如何恢复呢？我们可以通过版本号回退，使用命令方法如下：</p><p>git reset –hard 版本号 ，但是现在的问题假如我已经关掉过一次命令行或者333内容的版本号我并不知道呢？要如何知道增加3333内容的版本号呢？可以通过如下命令即可获取到版本号：git reflog 演示如下：</p><p><a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyq5dtfrj20e603e0t5.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyq5dtfrj20e603e0t5.jpg" alt="img"></a></p><p>通过上面的显示我们可以知道，增加内容3333的版本号是 6fcfc89.我们现在可以命令</p><p>git reset –hard 6fcfc89来恢复了。演示如下：</p><p><a href="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyq4m3oqj20e104974t.jpg" target="_blank" rel="noopener"><img src="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyq4m3oqj20e104974t.jpg" alt="img"></a></p><p>可以看到 目前已经是最新的版本了。</p><h4 id="理解工作区与暂存区的区别"><a href="#理解工作区与暂存区的区别" class="headerlink" title="理解工作区与暂存区的区别"></a>理解工作区与暂存区的区别</h4><p><strong>工作区：</strong>就是你在电脑上看到的目录，比如目录下testgit里的文件(.git隐藏目录版本库除外)。或者以后需要再新建的目录文件等等都属于工作区范畴。</p><p>   <strong>版本库**</strong>(Repository)<strong>**：</strong>工作区有一个隐藏目录.git,这个不属于工作区，这是版本库。其中版本库里面存了很多东西，其中最重要的就是stage(暂存区)，还有Git为我们自动创建了第一个分支master,以及指向master的一个指针HEAD。</p><p>我们前面说过使用Git提交文件到版本库有两步：</p><p> 第一步：是使用 git add 把文件添加进去，实际上就是把文件添加到暂存区。</p><p> 第二步：使用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支上。</p><p>我们继续使用demo来演示下：</p><p>我们在readme.txt再添加一行内容为4444444，接着在目录下新建一个文件为test.txt 内容为test，我们先用命令 git status来查看下状态，如下：</p><p><a href="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyq3ykzsj20hv06pwfi.jpg" target="_blank" rel="noopener"><img src="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyq3ykzsj20hv06pwfi.jpg" alt="img"></a></p><p>现在我们先使用git add 命令把2个文件都添加到暂存区中，再使用git status来查看下状态，如下：</p><p><a href="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyq2gn7sj20d206p0t8.jpg" target="_blank" rel="noopener"><img src="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyq2gn7sj20d206p0t8.jpg" alt="img"></a></p><p>接着我们可以使用git commit一次性提交到分支上，如下：</p><p><a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyq1gpk0j20h704mdgm.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyq1gpk0j20h704mdgm.jpg" alt="img"></a></p><h4 id="Git撤销修改和删除文件操作"><a href="#Git撤销修改和删除文件操作" class="headerlink" title="Git撤销修改和删除文件操作"></a>Git撤销修改和删除文件操作</h4><h4 id="撤销修改"><a href="#撤销修改" class="headerlink" title="撤销修改"></a><strong>撤销修改</strong></h4><p>  比如我现在在readme.txt文件里面增加一行 内容为555555555555，我们先通过命令查看如下：</p><p><a href="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyq0rzrcj20ax03vaaa.jpg" target="_blank" rel="noopener"><img src="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyq0rzrcj20ax03vaaa.jpg" alt="img"></a></p><p>在我未提交之前，我发现添加5555555555555内容有误，所以我得马上恢复以前的版本，现在我可以有如下几种方法可以做修改：</p><p>第一：如果我知道要删掉那些内容的话，直接手动更改去掉那些需要的文件，然后add添加到暂存区，最后commit掉。</p><p>第二：我可以按以前的方法直接恢复到上一个版本。使用 git reset –hard HEAD^</p><p>但是现在我不想使用上面的2种方法，我想直接想使用撤销命令该如何操作呢？首先在做撤销之前，我们可以先用 git status 查看下当前的状态。如下所示：</p><p><a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyq034qhj20hs04oaam.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyq034qhj20hs04oaam.jpg" alt="img"></a></p><p>可以发现，Git会告诉你，git checkout — file 可以丢弃工作区的修改，如下命令：</p><p>git checkout — readme.txt,如下所示：</p><p><a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloypz44y5j20eh03w0t4.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloypz44y5j20eh03w0t4.jpg" alt="img"></a></p><p>命令 git checkout –readme.txt 意思就是，把readme.txt文件在工作区做的修改全部撤销，这里有2种情况，如下：</p><ol><li>readme.txt自动修改后，还没有放到暂存区，使用 撤销修改就回到和版本库一模一样的状态。</li><li>另外一种是readme.txt已经放入暂存区了，接着又作了修改，撤销修改就回到添加暂存区后的状态。</li></ol><p>对于第二种情况，我想我们继续做demo来看下，假如现在我对readme.txt添加一行 内容为6666666666666，我git add 增加到暂存区后，接着添加内容7777777，我想通过撤销命令让其回到暂存区后的状态。如下所示：</p><p> <a href="http://ww1.sinaimg.cn/mw690/6941baebgw1eloypybh8pj20h40deq52.jpg" target="_blank" rel="noopener"><img src="http://ww1.sinaimg.cn/mw690/6941baebgw1eloypybh8pj20h40deq52.jpg" alt="img"></a></p><p><strong>注意：</strong>命令git checkout — readme.txt 中的 — 很重要，如果没有 — 的话，那么命令变成创建分支了。</p><h4 id="删除文件"><a href="#删除文件" class="headerlink" title="删除文件"></a><strong>删除文件</strong></h4><p> 假如我现在版本库testgit目录添加一个文件b.txt,然后提交。如下：</p><p> <a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloypxcttej20hr0awmzc.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloypxcttej20hr0awmzc.jpg" alt="img"></a></p><p>如上：一般情况下，可以直接在文件目录中把文件删了，或者使用如上rm命令：rm b.txt ，如果我想彻底从版本库中删掉了此文件的话，可以再执行commit命令 提交掉，现在目录是这样的，</p><p> <a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloypvtweyj20jj05cwf4.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloypvtweyj20jj05cwf4.jpg" alt="img"></a></p><p>只要没有commit之前，如果我想在版本库中恢复此文件如何操作呢？</p><p>可以使用如下命令 git checkout — b.txt，如下所示：</p><p><a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyput1l8j20fh06s0tr.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyput1l8j20fh06s0tr.jpg" alt="img"></a></p><p>再来看看我们testgit目录，添加了3个文件了。如下所示：</p><h4 id="远程仓库"><a href="#远程仓库" class="headerlink" title="远程仓库"></a>远程仓库</h4><p> 在了解之前，先注册github账号，由于你的本地Git仓库和github仓库之间的传输是通过SSH加密的，所以需要一点设置：</p><p>   第一步：创建SSH Key。在用户主目录下，看看有没有.ssh目录，如果有，再看看这个目录下有没有id_rsa和id_rsa.pub这两个文件，如果有的话，直接跳过此如下命令，如果没有的话，打开命令行，输入如下命令：</p><p>ssh-keygen -t rsa –C “<a href="mailto:youremail@example.com" target="_blank" rel="noopener">youremail@example.com</a>”, 由于我本地此前运行过一次，所以本地有，如下所示：</p><p> <a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloypq7esij20kx04pt9c.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloypq7esij20kx04pt9c.jpg" alt="img"></a></p><p>id_rsa是私钥，不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。</p><p>第二步：登录github,打开” settings”中的SSH Keys页面，然后点击“Add SSH Key”,填上任意title，在Key文本框里黏贴id_rsa.pub文件的内容。</p><p><a href="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyppfdu3j20vh0nwdl0.jpg" target="_blank" rel="noopener"><img src="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyppfdu3j20vh0nwdl0.jpg" alt="img"></a></p><p>点击 Add Key，你就应该可以看到已经添加的key。</p><p><a href="http://ww1.sinaimg.cn/mw690/6941baebgw1eloypnrj0cj20l60ad75p.jpg" target="_blank" rel="noopener"><img src="http://ww1.sinaimg.cn/mw690/6941baebgw1eloypnrj0cj20l60ad75p.jpg" alt="img"></a></p><ol><li>如何添加远程库？</li></ol><p>​     现在的情景是：我们已经在本地创建了一个Git仓库后，又想在github创建一个Git仓库，并且希望这两个仓库进行远程同步，这样github的仓库可以作为备份，又可以其他人通过该仓库来协作。</p><p>  首先，登录github上，然后在右上角找到“create a new repo”创建一个新的仓库。如下：</p><p><a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloypmocbsj20u40gttbc.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloypmocbsj20u40gttbc.jpg" alt="img"></a></p><p>在Repository name填入<code>testgit</code>，其他保持默认设置，点击“Create repository”按钮，就成功地创建了一个新的Git仓库：</p><p><a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloypm6o2gj20si0idwh4.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloypm6o2gj20si0idwh4.jpg" alt="img"></a></p><p>  目前，在GitHub上的这个<code>testgit</code>仓库还是空的，GitHub告诉我们，可以从这个仓库克隆出新的仓库，也可以把一个已有的本地仓库与之关联，然后，把本地仓库的内容推送到GitHub仓库。</p><p>现在，我们根据GitHub的提示，在本地的<code>testgit</code>仓库下运行命令：</p><p>git remote add origin <a href="https://github.com/tugenhua0707/testgit.git" target="_blank" rel="noopener">https://github.com/tugenhua0707/testgit.git</a></p><p>所有的如下：</p><p> <a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloypk8b34j20hk070764.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloypk8b34j20hk070764.jpg" alt="img"></a></p><p>把本地库的内容推送到远程，使用 git push命令，实际上是把当前分支master推送到远程。</p><p>由于远程库是空的，我们第一次推送master分支时，加上了 –u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。推送成功后，可以立刻在github页面中看到远程库的内容已经和本地一模一样了，上面的要输入github的用户名和密码如下所示：</p><p><a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloypjhn5ij20t40i7mzp.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloypjhn5ij20t40i7mzp.jpg" alt="img"></a></p><p>从现在起，只要本地作了提交，就可以通过如下命令：</p><p>git push origin master</p><p>把本地master分支的最新修改推送到github上了，现在你就拥有了真正的分布式版本库了。</p><p>\2. 如何从远程库克隆？</p><p>上面我们了解了先有本地库，后有远程库时候，如何关联远程库。</p><p>现在我们想，假如远程库有新的内容了，我想克隆到本地来 如何克隆呢？</p><p>首先，登录github，创建一个新的仓库，名字叫testgit2.如下：</p><p><a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyphv15sj20t10gs775.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyphv15sj20t10gs775.jpg" alt="img"></a></p><p>如下，我们看到：</p><p><a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloypexzvuj20ss0dgabs.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloypexzvuj20ss0dgabs.jpg" alt="img"></a></p><p>现在，远程库已经准备好了，下一步是使用命令git clone克隆一个本地库了。如下所示：</p><p><a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloypec5t0j20hp03jwf6.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloypec5t0j20hp03jwf6.jpg" alt="img"></a></p><p>接着在我本地目录下 生成testgit2目录了，如下所示：</p><p><a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloypdbpwnj20jt05hmxr.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloypdbpwnj20jt05hmxr.jpg" alt="img"></a></p><p>六：创建与合并分支。</p><p>在  版本回填退里，你已经知道，每次提交，Git都把它们串成一条时间线，这条时间线就是一个分支。截止到目前，只有一条时间线，在Git里，这个分支叫主分支，即master分支。HEAD严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。</p><p>首先，我们来创建dev分支，然后切换到dev分支上。如下操作：</p><p><a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloypab36sj20bc04nweu.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloypab36sj20bc04nweu.jpg" alt="img"></a></p><p>git checkout 命令加上 –b参数表示创建并切换，相当于如下2条命令</p><p>git branch dev</p><p>git checkout dev</p><p>git branch查看分支，会列出所有的分支，当前分支前面会添加一个星号。然后我们在dev分支上继续做demo，比如我们现在在readme.txt再增加一行 7777777777777</p><p>首先我们先来查看下readme.txt内容，接着添加内容77777777，如下：</p><p><a href="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyp9es90j20at0awjsq.jpg" target="_blank" rel="noopener"><img src="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyp9es90j20at0awjsq.jpg" alt="img"></a></p><p>现在dev分支工作已完成，现在我们切换到主分支master上，继续查看readme.txt内容如下：</p><p><a href="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyp8mng3j20hm05qaav.jpg" target="_blank" rel="noopener"><img src="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyp8mng3j20hm05qaav.jpg" alt="img"></a></p><p>现在我们可以把dev分支上的内容合并到分支master上了，可以在master分支上，使用如下命令 git merge dev 如下所示：</p><p><a href="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyp83uksj20es073gmi.jpg" target="_blank" rel="noopener"><img src="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyp83uksj20es073gmi.jpg" alt="img"></a></p><p>git merge命令用于合并指定分支到当前分支上，合并后，再查看readme.txt内容，可以看到，和dev分支最新提交的是完全一样的。</p><p>注意到上面的<em>Fast-forward</em>信息，Git告诉我们，这次合并是“快进模式”，也就是直接把master指向dev的当前提交，所以合并速度非常快。</p><p>合并完成后，我们可以接着删除dev分支了，操作如下：</p><p>总结创建与合并分支命令如下：</p><p>  查看分支：git branch</p><p>  创建分支：git branch name</p><p>  切换分支：git checkout name</p><p>创建+切换分支：git checkout –b name</p><p>合并某分支到当前分支：git merge name</p><p>删除分支：git branch –d name</p><h4 id="如何解决冲突"><a href="#如何解决冲突" class="headerlink" title="如何解决冲突"></a>如何解决冲突</h4><p>下面我们还是一步一步来，先新建一个新分支，比如名字叫fenzhi1，在readme.txt添加一行内容8888888，然后提交，如下所示：</p><p><a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyp4jq8yj20ft0cu40a.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyp4jq8yj20ft0cu40a.jpg" alt="img"></a></p><p>同样，我们现在切换到master分支上来，也在最后一行添加内容，内容为99999999，如下所示：</p><p><a href="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyp3w0l1j20g80dwmz7.jpg" target="_blank" rel="noopener"><img src="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyp3w0l1j20g80dwmz7.jpg" alt="img"></a></p><p>现在我们需要在master分支上来合并fenzhi1，如下操作：</p><p><a href="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyp1wo2ij20hm0gddi9.jpg" target="_blank" rel="noopener"><img src="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyp1wo2ij20hm0gddi9.jpg" alt="img"></a></p><p>Git用&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同分支的内容，其中&lt;&lt;&lt;HEAD是指主分支修改的内容，&gt;&gt;&gt;&gt;&gt;fenzhi1 是指fenzhi1上修改的内容，我们可以修改下如下后保存：</p><p><a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyp11x4zj20g107e3zd.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyp11x4zj20g107e3zd.jpg" alt="img"></a></p><p>如果我想查看分支合并的情况的话，需要使用命令 git log.命令行演示如下：</p><p><a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyp0aj6uj20dt0o5gph.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyp0aj6uj20dt0o5gph.jpg" alt="img"></a></p><h4 id="分支管理策略"><a href="#分支管理策略" class="headerlink" title="分支管理策略"></a>分支管理策略</h4><p>通常合并分支时，git一般使用”Fast forward”模式，在这种模式下，删除分支后，会丢掉分支信息，现在我们来使用带参数 –no-ff来禁用”Fast forward”模式。首先我们来做demo演示下：</p><ol><li>创建一个dev分支。</li><li>修改readme.txt内容。</li><li>添加到暂存区。</li><li>切换回主分支(master)。</li><li>合并dev分支，使用命令 git merge –no-ff -m “注释” dev</li><li>查看历史记录</li></ol><p>截图如下：</p><p> <a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyoz5m31j20gr0lon0y.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyoz5m31j20gr0lon0y.jpg" alt="img"></a></p><p><strong>分支策略：</strong>首先master主分支应该是非常稳定的，也就是用来发布新版本，一般情况下不允许在上面干活，干活一般情况下在新建的dev分支上干活，干完后，比如上要发布，或者说dev分支代码稳定后可以合并到主分支master上来。</p><p>七：bug分支：</p><p>   在开发中，会经常碰到bug问题，那么有了bug就需要修复，在Git中，分支是很强大的，每个bug都可以通过一个临时分支来修复，修复完成后，合并分支，然后将临时的分支删除掉。</p><p>比如我在开发中接到一个404 bug时候，我们可以创建一个404分支来修复它，但是，当前的dev分支上的工作还没有提交。比如如下：</p><p> <a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyoy0x5yj20he04m74v.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyoy0x5yj20he04m74v.jpg" alt="img"></a></p><p>  并不是我不想提交，而是工作进行到一半时候，我们还无法提交，比如我这个分支bug要2天完成，但是我issue-404 bug需要5个小时内完成。怎么办呢？还好，Git还提供了一个stash功能，可以把当前工作现场 ”隐藏起来”，等以后恢复现场后继续工作。如下：</p><p> <a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyoxn4t8j20i3058dgo.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyoxn4t8j20i3058dgo.jpg" alt="img"></a></p><p>  所以现在我可以通过创建issue-404分支来修复bug了。</p><p>首先我们要确定在那个分支上修复bug，比如我现在是在主分支master上来修复的，现在我要在master分支上创建一个临时分支，演示如下：</p><p> <a href="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyowmdooj20gp0etq55.jpg" target="_blank" rel="noopener"><img src="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyowmdooj20gp0etq55.jpg" alt="img"></a></p><p>修复完成后，切换到master分支上，并完成合并，最后删除issue-404分支。演示如下：</p><p>现在，我们回到dev分支上干活了。</p><p><a href="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyou5898j20bq03s0t6.jpg" target="_blank" rel="noopener"><img src="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyou5898j20bq03s0t6.jpg" alt="img"></a></p><p>工作区是干净的，那么我们工作现场去哪里呢？我们可以使用命令 git stash list来查看下。如下：</p><p><a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyot6ny2j20c202lmxg.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyot6ny2j20c202lmxg.jpg" alt="img"></a></p><p>工作现场还在，Git把stash内容存在某个地方了，但是需要恢复一下，可以使用如下2个方法：</p><ol><li>git stash apply恢复，恢复后，stash内容并不删除，你需要使用命令git stash drop来删除。</li><li>另一种方式是使用git stash pop,恢复的同时把stash内容也删除了。</li></ol><p>​     演示如下</p><p> <a href="https://images2015.cnblogs.com/blog/762349/201610/762349-20161026134059296-2019917854.png" target="_blank" rel="noopener"><img src="https://images2015.cnblogs.com/blog/762349/201610/762349-20161026134059296-2019917854.png" alt="img"></a></p><h4 id="多人协作"><a href="#多人协作" class="headerlink" title="多人协作"></a>多人协作</h4><p>当你从远程库克隆时候，实际上Git自动把本地的master分支和远程的master分支对应起来了，并且远程库的默认名称是origin。</p><ol><li>要查看远程库的信息 使用 git remote</li><li>要查看远程库的详细信息 使用 git remote –v</li></ol><p>如下演示：</p><p> <a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyor8ayjj20h704pt9e.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyor8ayjj20h704pt9e.jpg" alt="img"></a></p><p><strong>一：推送分支：</strong></p><p>   推送分支就是把该分支上所有本地提交到远程库中，推送时，要指定本地分支，这样，Git就会把该分支推送到远程库对应的远程分支上：</p><p>   使用命令 git push origin master</p><p>比如我现在的github上的readme.txt代码如下：</p><p><a href="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyoolky9j20n00crt9x.jpg" target="_blank" rel="noopener"><img src="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyoolky9j20n00crt9x.jpg" alt="img"></a></p><p>本地的readme.txt代码如下：</p><p> <a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyoljbdoj20bp05p74u.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyoljbdoj20bp05p74u.jpg" alt="img"></a></p><p>现在我想把本地更新的readme.txt代码推送到远程库中，使用命令如下：</p><p><a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyoklccxj20f105nmy8.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyoklccxj20f105nmy8.jpg" alt="img"></a></p><p>我们可以看到如上，推送成功，我们可以继续来截图github上的readme.txt内容 如下：</p><p><a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyojp2l7j20mi0dgdh4.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyojp2l7j20mi0dgdh4.jpg" alt="img"></a></p><p>可以看到 推送成功了，如果我们现在要推送到其他分支，比如dev分支上，我们还是那个命令 git push origin dev</p><p>那么一般情况下，那些分支要推送呢？</p><ol><li><p>master分支是主分支，因此要时刻与远程同步。</p></li><li><p>一些修复bug分支不需要推送到远程去，可以先合并到主分支上，然后把主分支master推送到远程去。</p></li><li><h4 id="抓取分支"><a href="#抓取分支" class="headerlink" title="抓取分支"></a>抓取分支</h4></li><li><p>多人协作时，大家都会往master分支上推送各自的修改。现在我们可以模拟另外一个同事，可以在另一台电脑上（注意要把SSH key添加到github上）或者同一台电脑上另外一个目录克隆，新建一个目录名字叫testgit2</p><p>但是我首先要把dev分支也要推送到远程去，如下</p><p><a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyoilae8j20dz047jrw.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyoilae8j20dz047jrw.jpg" alt="img"></a></p><p>接着进入testgit2目录，进行克隆远程的库到本地来，如下：</p><p> <a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyofwtkzj20e404qdgn.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyofwtkzj20e404qdgn.jpg" alt="img"></a></p><p>现在目录下生成有如下所示：</p><p><a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyoerppxj20jy07475a.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyoerppxj20jy07475a.jpg" alt="img"></a></p><p>现在我们的小伙伴要在dev分支上做开发，就必须把远程的origin的dev分支到本地来，于是可以使用命令创建本地dev分支：git checkout –b dev origin/dev</p><p>现在小伙伴们就可以在dev分支上做开发了，开发完成后把dev分支推送到远程库时。</p><p>如下：</p><p><a href="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyodj3j4j20gq0katc9.jpg" target="_blank" rel="noopener"><img src="http://ww1.sinaimg.cn/mw690/6941baebgw1eloyodj3j4j20gq0katc9.jpg" alt="img"></a></p><p>小伙伴们已经向origin/dev分支上推送了提交，而我在我的目录文件下也对同样的文件同个地方作了修改，也试图推送到远程库时，如下：</p><p><a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyocm8nlj20hz0l3jvp.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyocm8nlj20hz0l3jvp.jpg" alt="img"></a></p><p>由上面可知：推送失败，因为我的小伙伴最新提交的和我试图推送的有冲突，解决的办法也很简单，上面已经提示我们，先用git pull把最新的提交从origin/dev抓下来，然后在本地合并，解决冲突，再推送。</p><p><a href="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyoblpvij20gi07ugmx.jpg" target="_blank" rel="noopener"><img src="http://ww2.sinaimg.cn/mw690/6941baebgw1eloyoblpvij20gi07ugmx.jpg" alt="img"></a></p><p><em>git pull</em>也失败了，原因是没有指定本地dev分支与远程origin/dev分支的链接，根据提示，设置dev和origin/dev的链接：如下：</p><p><a href="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyoab9gfj20hy05j0tu.jpg" target="_blank" rel="noopener"><img src="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyoab9gfj20hy05j0tu.jpg" alt="img"></a></p><p>这回<em>git pull</em>成功，但是合并有冲突，需要手动解决，解决的方法和分支管理中的 解决冲突完全一样。解决后，提交，再push：</p><p>我们可以先来看看readme.txt内容了。</p><p><a href="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyo7l3o6j20ef07p74y.jpg" target="_blank" rel="noopener"><img src="http://ww4.sinaimg.cn/mw690/6941baebgw1eloyo7l3o6j20ef07p74y.jpg" alt="img"></a></p><p>现在手动已经解决完了，我接在需要再提交，再push到远程库里面去。如下所示：<br><a href="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyo5em1aj20gt0dcwgv.jpg" target="_blank" rel="noopener"><img src="http://ww3.sinaimg.cn/mw690/6941baebgw1eloyo5em1aj20gt0dcwgv.jpg" alt="img"></a></p><p>因此：多人协作工作模式一般是这样的：</p><ol><li><p>首先，可以试图用git push origin branch-name推送自己的修改.</p></li><li><p>如果推送失败，则因为远程分支比你的本地更新早，需要先用git pull试图合并。</p></li><li><p>如果合并有冲突，则需要解决冲突，并在本地提交。再用git push origin branch-name推送。</p></li><li><p>Git基本常用命令如下</p></li><li><p>mkdir：     XX (创建一个空目录 XX指目录名)</p><p>pwd：     显示当前目录的路径。</p><p>git init     把当前的目录变成可以管理的git仓库，生成隐藏.git文件。</p><p>git add XX    把xx文件添加到暂存区去。</p><p>git commit –m “XX” 提交文件 –m 后面的是注释。</p><p>git status    查看仓库状态</p><p>git diff XX   查看XX文件修改了那些内容</p><p>git log     查看历史记录</p><p>git reset –hard HEAD^ 或者 git reset –hard HEAD~ 回退到上一个版本</p><p>​            (如果想回退到100个版本，使用git reset –hard HEAD~100 )</p><p>cat XX     查看XX文件内容</p><p>git reflog    查看历史记录的版本号id</p><p>git checkout — XX 把XX文件在工作区的修改全部撤销。</p><p>git rm XX     删除XX文件</p><p>git remote add origin <a href="https://github.com/ev-power/XiaoYong" target="_blank" rel="noopener">https://github.com/ev-power/XiaoYong</a> 关联一个远程库</p><p>git push –u(第一次要用-u 以后不需要) origin master 把当前master分支推送到远程库</p><p>git clone <a href="https://github.com/ev-power/XiaoYong" target="_blank" rel="noopener">https://github.com/ev-power/XiaoYong</a> 从远程库中克隆</p><p>git checkout –b dev 创建dev分支 并切换到dev分支上</p><p>git branch 查看当前所有的分支</p><p>git checkout master 切换回master分支</p><p>git merge dev  在当前的分支上合并dev分支</p><p>git branch –d dev 删除dev分支</p><p>git branch name 创建分支</p><p>git stash 把当前的工作隐藏起来 等以后恢复现场后继续工作</p><p>git stash list 查看所有被隐藏的文件列表</p><p>git stash apply 恢复被隐藏的文件，但是内容不删除</p><p>git stash drop 删除文件</p><p>git stash pop 恢复文件的同时 也删除文件</p><p>git remote 查看远程库的信息</p><p>git remote –v 查看远程库的详细信息</p><p>git push origin master Git会把master分支推送到远程库对应的远程分支上   </p></li><li><p>本文非原创博客，部分内容有所更改，原文出自：<a href="http://www.cnblogs.com/tugenhua0707/p/4050072.html" target="_blank" rel="noopener">http://www.cnblogs.com/tugenhua0707/p/4050072.html</a></p></li></ol></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;讨论了许多种git的情况，非常详细的git报告&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/bec9bff2gy1gds54g3odrj206402kmwz.jpg&quot; alt=&quot;undefined&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Git" scheme="http://yoursite.com/categories/Git/"/>
    
    
      <category term="Git" scheme="http://yoursite.com/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>朝花夕拾</title>
    <link href="http://yoursite.com/2020/04/09/%E6%9C%9D%E8%8A%B1%E5%A4%95%E6%8B%BE/"/>
    <id>http://yoursite.com/2020/04/09/朝花夕拾/</id>
    <published>2020-04-09T07:29:23.635Z</published>
    <updated>2020-05-30T01:41:01.589Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>资质低下 三心二意 昨日知识 朝花夕拾</p></blockquote><a id="more"></a> <h3 id="更友好的创建对象方式"><a href="#更友好的创建对象方式" class="headerlink" title="更友好的创建对象方式"></a>更友好的创建对象方式</h3><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gdnjra9kkrj20sk0c6myf.jpg" alt="3d5024b55687373af54fcb9ef4e0eb4.png"></p><p>上面的方式，对JVM来说是更友好的，因为堆内存的调用无法避免，所以从栈内存这边入手解决内存问题是一个不错的解决的方式</p><hr><h3 id="下面代码是否线程安全"><a href="#下面代码是否线程安全" class="headerlink" title="下面代码是否线程安全"></a>下面代码是否线程安全</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> Singleton instance; </span><br><span class="line">    <span class="function"><span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span></span>&#123; </span><br><span class="line">    <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">synchronized</span>(Singleton.class) &#123;</span><br><span class="line">                <span class="keyword">if</span> (instance == <span class="keyword">null</span>) instance = <span class="keyword">new</span> Singleton();</span><br><span class="line">            &#125; </span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">return</span> instance; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>乍一看类似饿汉式的单例，线程安全，其实是有问题的</p><p>虽然只有一个线程能够获得锁，并且这个锁还是类锁，所有对象共享的</p><p>关键在于 jvm 对 new 的优化，这个变量没有声明 volatile，new 不是一个线程安全的操作，</p><p>对于 new 这个指令，一般的顺序是申请内存空间，初始化内存空间，然后把内存地址赋给 instance 对象，但是 jvm 会对这段指令进行优化，优化之后变成 申请内存空间，内存地址赋给 instance 对象，初始化内存空间，这就导致 第二层检查可能会出错，标准写法只需要在变量前声明 volatile 即可。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gdnkbsp9sij20pp0gy75i.jpg" alt="677701574e4f69f35e226ed6bc9a380.png"></p><hr><h3 id="volatile利用了什么协议来实现可见性"><a href="#volatile利用了什么协议来实现可见性" class="headerlink" title="volatile利用了什么协议来实现可见性"></a>volatile利用了什么协议来实现可见性</h3><p>volatile 是通过内存屏障实现的，MESI协议，缓存一致性协议</p><p>JVM推荐书《The Java Language Specification》<br>volatile 修饰的变量如果值发生变化 发现线程的高速缓存与主存数据不一致时候 由于缓存一致性协议 则总线将高速缓存中的值清空 其他线程只能通过访问主存来获取最新的值 并缓存到告诉缓存上。</p><hr><h3 id="Java-Trainsient-关键字"><a href="#Java-Trainsient-关键字" class="headerlink" title="Java Trainsient 关键字"></a>Java Trainsient 关键字</h3><p>1.一旦变量被transient修饰，变量将不再是对象持久化的一部分，该变量内容在序列化后无法获得访问。 </p><p>2.transient关键字只能修饰变量，而不能修饰方法和类。注意，本地变量是不能被transient关键字修饰的。变量如果是用户自定义类变量，则该类需要实现Serializable接口。 </p><p>3.一个静态变量不管是否被transient修饰，均不能被序列化。 </p><p>使用总结和场景：某个类的有些属性需要序列化，其他属性不需要被序列化，比如：敏感信息（如密码，银行卡号等），java 的transient关键字为我们提供了便利，你只需要实现Serilizable接口，将不需要序列化的属性前添加关键字transient，序列化对象的时候，这个属性就不会序列化到指定的目的地中。</p><h3 id="多线程中Random的使用"><a href="#多线程中Random的使用" class="headerlink" title="多线程中Random的使用"></a>多线程中Random的使用</h3><p>1.不要在多个线程间共享一个java.util.Random实例，而该把它放入ThreadLocal之中。</p><p>2.Java7以上我们更推荐使用java.util.concurrent.ThreadLocalRandom。</p><p>下面两条建议是 IDEA给的:</p><p>1.不要将将随机数放大10的若干倍然后取整，直接使用Random对象的nextInt或者nextLong方法</p><p>2.Math.random()应避免在多线程环境下使用</p><h3 id="为什么阿里禁止使用Executor创建线程池"><a href="#为什么阿里禁止使用Executor创建线程池" class="headerlink" title="为什么阿里禁止使用Executor创建线程池"></a>为什么阿里禁止使用Executor创建线程池</h3><p>阿里规约之所以强制要求手动创建线程池，也是和这些参数有关。具体为什么不允许，规约是这么说的：</p><p>线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。</p><p>Executor提供的四个静态方法创建线程池，但是阿里规约却并不建议使用它。</p><p>Executors各个方法的弊端：<br>1）newFixedThreadPool和newSingleThreadExecutor:<br>  主要问题是堆积的请求处理队列可能会耗费非常大的内存，甚至OOM。<br>2）newCachedThreadPool和newScheduledThreadPool:<br>  主要问题是线程数最大数是Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至OOM。</p><p>看一下这两种弊端怎么导致的。</p><p>第一种，newFixedThreadPool和newSingleThreadExecutor分别获得 FixedThreadPool 类型的线程池 和  SingleThreadExecutor 类型的线程池。　</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newFixedThreadPool</span><span class="params">(<span class="keyword">int</span> nThreads)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">new</span> ThreadPoolExecutor(nThreads, nThreads,</span><br><span class="line">                                     <span class="number">0L</span>, TimeUnit.MILLISECONDS,</span><br><span class="line">                                     <span class="keyword">new</span> LinkedBlockingQueue&lt;Runnable&gt;());</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public static ExecutorService newSingleThreadExecutor() &#123;</span><br><span class="line">       return new FinalizableDelegatedExecutorService</span><br><span class="line">           (new ThreadPoolExecutor(1, 1,</span><br><span class="line">                                   0L, TimeUnit.MILLISECONDS,</span><br><span class="line">                                   new LinkedBlockingQueue&lt;Runnable&gt;()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为，创建了一个无界队列LinkedBlockingQueuesize，是一个最大值为Integer.MAX_VALUE的线程阻塞队列，当添加任务的速度大于线程池处理任务的速度，可能会在队列堆积大量的请求，消耗很大的内存，甚至导致OOM。</p><h3 id="阿里开发手册上不推荐（禁止）使用Double的根本原因"><a href="#阿里开发手册上不推荐（禁止）使用Double的根本原因" class="headerlink" title="阿里开发手册上不推荐（禁止）使用Double的根本原因"></a>阿里开发手册上不推荐（禁止）使用Double的根本原因</h3><p>精度丢失就不谈了，稍微深入一下为什么精度会丢失，分为一些不同情况</p><p><strong>典型现象（一）：条件判断超预期</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">System.out.println( <span class="number">1f</span> == <span class="number">0.9999999f</span> );   <span class="comment">// 打印：false</span></span><br><span class="line">System.out.println( <span class="number">1f</span> == <span class="number">0.99999999f</span> );  <span class="comment">// 打印：true    纳尼？</span></span><br><span class="line"></span><br><span class="line"><span class="number">1.0</span>（十进制）</span><br><span class="line">    ↓</span><br><span class="line"><span class="number">00111111</span> <span class="number">10000000</span> <span class="number">00000000</span> <span class="number">00000000</span>（二进制）</span><br><span class="line">    ↓</span><br><span class="line"><span class="number">0x3F800000</span>（十六进制）</span><br><span class="line">    </span><br><span class="line"><span class="number">0.99999999</span>（十进制）</span><br><span class="line">    ↓</span><br><span class="line"><span class="number">00111111</span> <span class="number">10000000</span> <span class="number">00000000</span> <span class="number">00000000</span>（二进制）</span><br><span class="line">    ↓</span><br><span class="line"><span class="number">0x3F800000</span>（十六进制）</span><br><span class="line">    </span><br><span class="line">果不其然，这两个十进制浮点数的底层二进制表示是一毛一样的，怪不得==的判断结果返回<span class="keyword">true</span>！</span><br><span class="line"></span><br><span class="line">浮点数的精度问题。</span><br><span class="line">    </span><br><span class="line">浮点数在计算机中的存储方式遵循IEEE <span class="number">754</span> 浮点数计数标准，可以用科学计数法表示为：</span><br><span class="line">    <span class="number">1</span> + <span class="number">2</span> + <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span>、符号部分（S）</span><br><span class="line"></span><br><span class="line"><span class="number">0</span>-正  <span class="number">1</span>-负</span><br><span class="line"></span><br><span class="line"><span class="number">2</span>、阶码部分（E）（指数部分）：</span><br><span class="line"></span><br><span class="line">对于<span class="keyword">float</span>型浮点数，指数部分<span class="number">8</span>位，考虑可正可负，因此可以表示的指数范围为-<span class="number">127</span> ~ <span class="number">128</span></span><br><span class="line">对于<span class="keyword">double</span>型浮点数，指数部分<span class="number">11</span>位，考虑可正可负，因此可以表示的指数范围为-<span class="number">1023</span> ~ <span class="number">1024</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">3</span>、尾数部分（M）：</span><br><span class="line"></span><br><span class="line">浮点数的精度是由尾数的位数来决定的：</span><br><span class="line"></span><br><span class="line">对于<span class="keyword">float</span>型浮点数，尾数部分<span class="number">23</span>位，换算成十进制就是 <span class="number">2</span>^<span class="number">23</span>=<span class="number">8388608</span>，所以十进制精度只有<span class="number">6</span> ~ <span class="number">7</span>位；</span><br><span class="line">对于<span class="keyword">double</span>型浮点数，尾数部分<span class="number">52</span>位，换算成十进制就是 <span class="number">2</span>^<span class="number">52</span> = <span class="number">4503599627370496</span>，所以十进制精度只有<span class="number">15</span> ~ <span class="number">16</span>位</span><br><span class="line"></span><br><span class="line">所以对于上面的数值<span class="number">0.99999999f</span>，很明显已经超过了<span class="keyword">float</span>型浮点数据的精度范围，出问题也是在所难免的。</span><br></pre></td></tr></table></figure><p><strong>典型现象（二）：数据转换超预期</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> f = <span class="number">1.1f</span>;</span><br><span class="line"><span class="keyword">double</span> d = (<span class="keyword">double</span>) f;</span><br><span class="line">System.out.println(f);  <span class="comment">// 打印：1.1</span></span><br><span class="line">System.out.println(d);  <span class="comment">// 打印：1.100000023841858  纳尼？</span></span><br></pre></td></tr></table></figure><p><strong>典型现象（三）：基本运算超预期</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">System.out.println( <span class="number">0.2</span> + <span class="number">0.7</span> );  </span><br><span class="line"></span><br><span class="line"><span class="comment">// 打印：0.8999999999999999   纳尼？</span></span><br></pre></td></tr></table></figure><p><strong>典型现象（四）：数据自增超预期</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> f1 = <span class="number">8455263f</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">    System.out.println(f1);</span><br><span class="line">    f1++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 打印：8455263.0</span></span><br><span class="line"><span class="comment">// 打印：8455264.0</span></span><br><span class="line"><span class="comment">// 打印：8455265.0</span></span><br><span class="line"><span class="comment">// 打印：8455266.0</span></span><br><span class="line"><span class="comment">// 打印：8455267.0</span></span><br><span class="line"><span class="comment">// 打印：8455268.0</span></span><br><span class="line"><span class="comment">// 打印：8455269.0</span></span><br><span class="line"><span class="comment">// 打印：8455270.0</span></span><br><span class="line"><span class="comment">// 打印：8455271.0</span></span><br><span class="line"><span class="comment">// 打印：8455272.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">float</span> f2 = <span class="number">84552631f</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">    System.out.println(f2);</span><br><span class="line">    f2++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//    打印：8.4552632E7   纳尼？不是 +1了吗？</span></span><br><span class="line"><span class="comment">//    打印：8.4552632E7   纳尼？不是 +1了吗？</span></span><br><span class="line"><span class="comment">//    打印：8.4552632E7   纳尼？不是 +1了吗？</span></span><br><span class="line"><span class="comment">//    打印：8.4552632E7   纳尼？不是 +1了吗？</span></span><br><span class="line"><span class="comment">//    打印：8.4552632E7   纳尼？不是 +1了吗？</span></span><br><span class="line"><span class="comment">//    打印：8.4552632E7   纳尼？不是 +1了吗？</span></span><br><span class="line"><span class="comment">//    打印：8.4552632E7   纳尼？不是 +1了吗？</span></span><br><span class="line"><span class="comment">//    打印：8.4552632E7   纳尼？不是 +1了吗？</span></span><br><span class="line"><span class="comment">//    打印：8.4552632E7   纳尼？不是 +1了吗？</span></span><br><span class="line"><span class="comment">//    打印：8.4552632E7   纳尼？不是 +1了吗？</span></span><br></pre></td></tr></table></figure><p>解决办法：</p><p>1.我们我们可以用字符串或者数组来表示这种大数，然后按照四则运算的规则来手动模拟出具体计算过程，中间还需要考虑各种诸如：<strong>进位、借位、符号</strong>等等问题的处理，有点复杂。</p><ol start="2"><li>JDK早已为我们考虑到了浮点数的计算精度问题，因此提供了专用于高精度数值计算的<strong>大数类</strong>来方便我们使用。</li></ol><h3 id="mac-清理maven仓库的脚本"><a href="#mac-清理maven仓库的脚本" class="headerlink" title="mac 清理maven仓库的脚本"></a>mac 清理maven仓库的脚本</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 这里写你的仓库路径</span><br><span class="line">REPOSITORY_PATH=~/Documents/tools/apache-maven-3.0.3/repository</span><br><span class="line">echo 正在搜索...</span><br><span class="line">find $REPOSITORY_PATH -name &quot;*lastUpdated*&quot; | xargs rm -fr</span><br><span class="line">echo 删除完毕</span><br><span class="line"></span><br><span class="line">mac（linux）系统-创建.sh文件脚本执行（mac用.command终端也可以）</span><br></pre></td></tr></table></figure><h3 id="idea目录较多，文件名较长产生的错误"><a href="#idea目录较多，文件名较长产生的错误" class="headerlink" title="idea目录较多，文件名较长产生的错误"></a>idea目录较多，文件名较长产生的错误</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Error running &apos;ServiceStarter&apos;: Command line is too long. Shorten command line for ServiceStarter or also for Application default configuration.</span><br><span class="line"></span><br><span class="line">修改项目下 .idea\workspace.xml，找到标签 &lt;component name=&quot;PropertiesComponent&quot;&gt; ， 在标签里加一行 &lt;property name=&quot;dynamic.classpath&quot; value=&quot;true&quot; /&gt;</span><br></pre></td></tr></table></figure><h3 id="Log4J-指定屏蔽某些特定报警信息"><a href="#Log4J-指定屏蔽某些特定报警信息" class="headerlink" title="Log4J 指定屏蔽某些特定报警信息"></a>Log4J 指定屏蔽某些特定报警信息</h3><p>Logger.getLogger(“org.apache.library”).setLevel(Level.OFF)</p><h3 id="Flink-Source并行度为1的意义"><a href="#Flink-Source并行度为1的意义" class="headerlink" title="Flink Source并行度为1的意义"></a>Flink Source并行度为1的意义</h3><p>对于需要设置EventTime的流来说，我们的TimestampAssigner应该在Source之后立即调用，原因是时间戳分配器看到的元素的顺序应该和source操作符产生数据的顺序是一样的，否则就乱了，也就是说，任何分区操作都会将元素的顺序打乱，例如：改变并行度 keyBy操作等等。，所以最佳实践是：</p><p>在尽量接近数据源source操作符的地方分配时间戳和产生水位线，甚至最好在SourceFunction中分配时间戳和产生水位线。当然在分配时间戳和产生水位线之前可以对流进行map和filter操作是没问题的，也就是说必须是窄依赖。</p><h3 id="JB套件的一个实用功能"><a href="#JB套件的一个实用功能" class="headerlink" title="JB套件的一个实用功能"></a>JB套件的一个实用功能</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">之前没注意，更改变量名字的时候直接使用refactor就可以了，真的实用</span><br></pre></td></tr></table></figure><h3 id="zk使用的分布式协议并不是paxos"><a href="#zk使用的分布式协议并不是paxos" class="headerlink" title="zk使用的分布式协议并不是paxos"></a>zk使用的分布式协议并不是paxos</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">而是zab协议</span><br></pre></td></tr></table></figure><h3 id="为什么说NULL是计算机科学中最大的错误，至少值十亿美金"><a href="#为什么说NULL是计算机科学中最大的错误，至少值十亿美金" class="headerlink" title="为什么说NULL是计算机科学中最大的错误，至少值十亿美金"></a>为什么说NULL是计算机科学中最大的错误，至少值十亿美金</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.覆类型</span><br><span class="line">2.是凌乱的</span><br><span class="line">3.是一个特例</span><br><span class="line">4.使 API 变得糟糕</span><br><span class="line">5.使错误的语言决策更加恶化</span><br><span class="line">6.难以调试</span><br><span class="line">7.是不可组合的</span><br></pre></td></tr></table></figure><h4 id="1-NULL-颠覆类型"><a href="#1-NULL-颠覆类型" class="headerlink" title="1. NULL 颠覆类型"></a>1. NULL 颠覆类型</h4><p>静态类型语言不需要实际去执行程序，就可以检查程序中类型的使用，并且提供一定的程序行为保证。</p><p>例如，在 Java 中，如果我编写 <code>x.toUppercase()</code>，编译器会检查 <code>x</code> 的类型。如果 <code>x</code> 是一个 <code>String</code>，那么类型检查成功；如果 <code>x</code> 是一个 <code>Socket</code>，那么类型检查失败。</p><p>在编写庞大的、复杂的软件时，静态类型检查是一个强大的工具。但是对于 Java，这些很棒的编译时检查存在一个致命缺陷：任何引用都可以是 null，而调用一个 null 对象的方法会产生一个 <code>NullPointerException</code>。所以，</p><ul><li><code>toUppercase()</code> 可以被任意 <code>String</code> 对象调用。除非 <code>String</code> 是 null。</li><li><code>read()</code> 可以被任意 <code>InputStream</code> 对象调用。除非 <code>InputStream</code> 是 null。</li><li><code>toString()</code> 可以被任意 <code>Object</code> 对象调用。除非 <code>Object</code> 是 null。</li></ul><p>Java 不是唯一引起这个问题的语言；很多其它的类型系统也有同样的缺点，当然包括 AGOL W 语言。</p><p>在这些语言中，NULL 超出了类型检查的范围。它悄悄地越过类型检查，等待运行时，最后一下子释放出一大批错误。NULL 什么也不是，同时又什么都是。</p><h4 id="2-NULL-是凌乱的"><a href="#2-NULL-是凌乱的" class="headerlink" title="2. NULL 是凌乱的"></a>2. NULL 是凌乱的</h4><p>在很多情况下 null 是没有意义的。不幸的是，如果一种语言允许任何东西为 null，好吧，那么任何东西都可以是 null。</p><p>Java 程序员冒着患腕管综合症的风险写下</p><p>Java</p><p> <code>if (str == null 丨丨 str.equals(&quot;&quot;)) {}</code> </p><p>而在 C# 中添加 <code>String.IsNullOrEmpty</code> 是一个常见的语法</p><p>C#</p><p> <code>if (string.IsNullOrEmpty(str)) {}</code> </p><p>真可恶！</p><p>每次你写代码，将 null 字符串和空字符串混为一谈时，Guava 团队都要哭了。– <a href="https://code.google.com/p/guava-libraries/wiki/UsingAndAvoidingNullExplained" target="_blank" rel="noopener">Google Guava</a></p><p>说得好。但是当你的类型系统（例如，Java 或者 C#）到处都允许 NULL 时，你就不能可靠地排除 NULL 的可能性，并且不可避免的会在某个地方混淆。</p><p>null 无处不在的可能性造成了这样一个问题，Java 8 添加了 <code>@NonNull</code> 标注，尝试着在它的类型系统中以追溯方式解决这个缺陷。</p><h4 id="3-NULL-是一个特例"><a href="#3-NULL-是一个特例" class="headerlink" title="3. NULL 是一个特例"></a>3. NULL 是一个特例</h4><p>考虑到 NULL 不是一个值却又起到一个值的作用，NULL 自然地成为各种特别处理方法的课题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">char c = &apos;A&apos;;</span><br><span class="line">char *myChar = &amp;c;</span><br><span class="line">std::cout &lt;&lt; *myChar &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><p>单个 NUL 字符的例外已经导致无数的错误：API 的怪异行为、安全漏洞和缓冲区溢出。</p><p>NULL 是 C 字符串中最糟糕的错误；更确切地说，以 NUL 结尾的字符串是<a href="http://queue.acm.org/detail.cfm?id=2010365" target="_blank" rel="noopener">最昂贵的<strong>一字节</strong>错误</a>。</p><h4 id="4-NULL-使-API-变得糟糕"><a href="#4-NULL-使-API-变得糟糕" class="headerlink" title="4.NULL 使 API 变得糟糕"></a>4.NULL 使 API 变得糟糕</h4><p>我们可以想象在很多语言中类似的类（Python、JavaScript、Java、C# 等）。</p><p>现在假设我们的程序有一个慢的或者占用大量资源的方法，来找到某个人的电话号码——可能通过连通一个网络服务。</p><p>为了提高性能，我们将会使用本地存储作为缓存，将一个人名映射到他的电话号码上。</p><p>然而，一些人没有电话号码（即他们的电话号码是 nil）。我们仍然会缓存那些信息，所以我们不需要在后面重新填充那些信息。</p><p>但是现在意味着我们的结果模棱两可！它可能表示：</p><ol><li>这个人不存在于缓存中（Alice）</li><li>这个人存在于缓存中，但是没有电话号码（Tom）</li></ol><p>一种情形要求昂贵的重新计算，另一种需要即时的答复。但是我们的代码不够精密来区分这两种情况。</p><p>在实际的代码中，像这样的情况经常会以复杂且不易察觉的方式出现。因此，简单通用的 API 可以马上变成特例，迷惑了 null 凌乱行为的来源。</p><p>用一个 <code>contains()</code> 方法来修补 <code>Store</code> 类可能会有帮助。但是这引入重复的查找，导致降低性能和竞争条件。</p><h4 id="5-NULL-使错误的语言决策更加恶化"><a href="#5-NULL-使错误的语言决策更加恶化" class="headerlink" title="5.NULL 使错误的语言决策更加恶化"></a>5.NULL 使错误的语言决策更加恶化</h4><h4 id="6-NULL-难以调试"><a href="#6-NULL-难以调试" class="headerlink" title="6.NULL 难以调试"></a>6.NULL 难以调试</h4><p>来解释 NULL 是多么的麻烦，C++ 是一个很好的例子。调用成员函数指向一个 NULL 指针不一定会导致程序崩溃。更糟糕的是：它可能会导致程序崩溃。</p><h4 id="7-NULL不可组合"><a href="#7-NULL不可组合" class="headerlink" title="7.NULL不可组合"></a>7.NULL不可组合</h4><h3 id="IDEA-maven修改pom文件，导致jdk版本重置问题"><a href="#IDEA-maven修改pom文件，导致jdk版本重置问题" class="headerlink" title="IDEA maven修改pom文件，导致jdk版本重置问题"></a>IDEA maven修改pom文件，导致jdk版本重置问题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;properties&gt;</span><br><span class="line">    &lt;maven.compiler.source&gt;8&lt;/maven.compiler.source&gt;</span><br><span class="line">    &lt;maven.compiler.target&gt;8&lt;/maven.compiler.target&gt;</span><br><span class="line">&lt;/properties&gt;</span><br></pre></td></tr></table></figure><h3 id="EXCEL一点小技巧"><a href="#EXCEL一点小技巧" class="headerlink" title="EXCEL一点小技巧"></a>EXCEL一点小技巧</h3><p>正好最近用来有点小用处</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.从固定的单元格里随机取一个值</span><br><span class="line">=INDEX($G$2:$M$2, RANDBETWEEN(1,7))</span><br><span class="line">$G$2：下拉的时候不会自动延伸</span><br><span class="line"></span><br><span class="line">2.从固定列取值用在本单元格里</span><br><span class="line">=&quot;INSERT INTO `event_mapping` VALUES (&apos;&quot;&amp;B2&amp;&quot;&apos;,&quot;&amp;C2&amp;&quot;,&quot;&amp;D2&amp;&quot;);&quot;</span><br><span class="line"></span><br><span class="line">3.下拉到某行</span><br><span class="line">在有第一行的情况下，直接双击右下角小箭头即可</span><br></pre></td></tr></table></figure><h3 id="Flink-On-Zeppelin上传Jar包的位置"><a href="#Flink-On-Zeppelin上传Jar包的位置" class="headerlink" title="Flink On Zeppelin上传Jar包的位置"></a>Flink On Zeppelin上传Jar包的位置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/opt/flink-1.10/flink-1.10.0/lib</span><br><span class="line"></span><br><span class="line">目前看来应该是放在flink包里面的，会稳定上传，已经确定</span><br><span class="line"></span><br><span class="line">在interpreter 依赖里面设置了路劲</span><br><span class="line">/opt/flink-1.10/flink-1.10.0/lib/jimipojo-1.0.jar</span><br></pre></td></tr></table></figure><h3 id="Flink系列深度好文，等待细读"><a href="#Flink系列深度好文，等待细读" class="headerlink" title="Flink系列深度好文，等待细读"></a>Flink系列深度好文，等待细读</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">https://www.jianshu.com/c/b6089c70072f</span><br><span class="line">flink的apply和process方法有什么区别呢</span><br></pre></td></tr></table></figure><h3 id="FastJson直接解析"><a href="#FastJson直接解析" class="headerlink" title="FastJson直接解析"></a>FastJson直接解析</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">.map(</span><br><span class="line">a -&gt; JSON</span><br><span class="line">.parseObject(</span><br><span class="line">a,</span><br><span class="line">Pojo.class)</span><br><span class="line">).returns(</span><br><span class="line">Pojo.class</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>具体的还要试一下，我故意写的很难看来督促自己。。。</p><h3 id="FastJson很多坑-准备放弃"><a href="#FastJson很多坑-准备放弃" class="headerlink" title="FastJson很多坑 准备放弃"></a>FastJson很多坑 准备放弃</h3><h3 id="配置框架无法访问的问题"><a href="#配置框架无法访问的问题" class="headerlink" title="配置框架无法访问的问题"></a>配置框架无法访问的问题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">有点脑残了，今天在mac上配置了zeppelin win无法访问，其原因是配置文件中的网络地址写死了 172.0.0.1, 如果想要别尔德位置能够访问的话，必须改变配置为其局域网id</span><br><span class="line"></span><br><span class="line">更好的选择是更改为0.0.0.0</span><br></pre></td></tr></table></figure><h3 id="解决GitHub提交历史头像不显示问题-以及首页没有绿色方块的问题"><a href="#解决GitHub提交历史头像不显示问题-以及首页没有绿色方块的问题" class="headerlink" title="解决GitHub提交历史头像不显示问题,以及首页没有绿色方块的问题"></a>解决GitHub提交历史头像不显示问题,以及首页没有绿色方块的问题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">最近把本地的一个项目提交推送到GitHub的时候发现有两个问题, </span><br><span class="line">1.在commit提交历史里面</span><br><span class="line"></span><br><span class="line">提交内容的旁边,显示的不是原本github主页的头像,而是默认的灰色章鱼头像</span><br><span class="line"></span><br><span class="line">2.我的contributions里面提交的历史(绿色方块)也没有了</span><br><span class="line"></span><br><span class="line">怎么解决呢？</span><br><span class="line"></span><br><span class="line">1.首先在终端里切到项目所在目录</span><br><span class="line"></span><br><span class="line">2.输入git show命令,你会发现 有一行写着Author: Apple &lt;邮箱&gt;,这个邮箱肯定不是你绑定到github的邮箱</span><br><span class="line"></span><br><span class="line">3.输入git config user.email &quot;你的邮箱地址&quot;,修改邮箱</span><br><span class="line"></span><br><span class="line">4.修改完以后输入git config user.email 检查是否修改成了你的邮箱</span><br><span class="line"></span><br><span class="line">5.到目前为止现在只是修改这个项目的邮箱,重新推送一个新的改动,在查看该项目的提交历史和contributions里面提交的历史(绿色方块),问题已经解决了(之前的依旧不显示)</span><br><span class="line"></span><br><span class="line">6.如果你想其他项目提交时,也避免此类情况,把上面的两条命令改成 （1） git config --global user.email &quot;your_email@example.com&quot;</span><br><span class="line"></span><br><span class="line">（2）git config --global user.email 就可以了</span><br></pre></td></tr></table></figure><h3 id="解决anaconda无法连接的问题"><a href="#解决anaconda无法连接的问题" class="headerlink" title="解决anaconda无法连接的问题"></a>解决anaconda无法连接的问题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">win10下更换清华镜像后无法连接 是因为win10里面无法解析https协议，修改‪~\.condarc文件，把https换成http</span><br></pre></td></tr></table></figure><h3 id="排查挖矿程序中会用到的一些追踪某个进程的命令"><a href="#排查挖矿程序中会用到的一些追踪某个进程的命令" class="headerlink" title="排查挖矿程序中会用到的一些追踪某个进程的命令"></a>排查挖矿程序中会用到的一些追踪某个进程的命令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>查看PID启动文件的路径</span><br><span class="line">ls -l /proc/$PID/exe</span><br><span class="line"><span class="meta">#</span>查看PID执行目录的路径</span><br><span class="line">ls -l /proc/$PID/cwd</span><br><span class="line"><span class="meta">#</span>在定时器配置目录查看是否存在异常定时器配置</span><br><span class="line">/var/spool/cron/root 和/etc/crontab 和/etc/rc.lcoal</span><br><span class="line"><span class="meta">#</span>查看定时器启动日志,跟踪自启动程序</span><br><span class="line">tail -f /var/log/cron</span><br><span class="line"><span class="meta">#</span>查看各个进程的cpu使用情况，默认按cpu使用率排序</span><br><span class="line">top</span><br><span class="line"><span class="meta">#</span>显示所有运行中的进程，q退出</span><br><span class="line">ps aux | less</span><br><span class="line"><span class="meta">#</span>查看test.jar进程号</span><br><span class="line">ps -aux|grep test.jar | grep -v grep</span><br><span class="line"><span class="meta">#</span>查看test.jar进程号</span><br><span class="line">ps -ef|grep test.jar | grep -v grep</span><br><span class="line"><span class="meta">#</span>查看该进程下各个线程的cpu使用情况</span><br><span class="line">top -Hp pid</span><br><span class="line"><span class="meta">#</span>将线程pid转换为十六进制 8f7</span><br><span class="line">printf "%x\n" pid</span><br><span class="line"><span class="meta">#</span>查看pid进程里面的线程信息,线程Id为十六进制</span><br><span class="line">jstack pid | grep 8f7</span><br><span class="line"><span class="meta">#</span>查看该进程打开的文件</span><br><span class="line">lsof -p pid</span><br><span class="line"><span class="meta">#</span>查看pid线程内存分配</span><br><span class="line">cat /proc/pid/maps </span><br><span class="line"><span class="meta">#</span>查看PID启动文件的路径</span><br><span class="line">ls -l /proc/$PID/exe </span><br><span class="line"><span class="meta">#</span>查看PID执行目录的路径</span><br><span class="line">ls -l /proc/$PID/cwd </span><br><span class="line"><span class="meta">#</span>查看PID详细的内存占比</span><br><span class="line">cat /proc/$PID/status</span><br></pre></td></tr></table></figure><h3 id="Kerberos缺点"><a href="#Kerberos缺点" class="headerlink" title="Kerberos缺点"></a>Kerberos缺点</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">1、KDC 有单点风险，除非设置HA系统(Aictive Directory 可以做到这一点，目前apache directoryserver 也可以做到这一点)；</span><br><span class="line"></span><br><span class="line">2、访问压力可能使KDC过载；分布式服务使用Kerberos 必须做到这一点，KDC无法承受高负载请求；为什么Hadoop 要使用代理tokens的原因也是如此；</span><br><span class="line"></span><br><span class="line">3、服务之间的通信通道也需要安全认证，kerberos不保证数据加密；如果通信通道不安全，tickets 可能会被拦截或者通信伪造；</span><br><span class="line"></span><br><span class="line">4、机器之前需要保证时间的精确一致性，不然具备时限的tockens不会正常工作；这个在分布式领域是一个典型的问题，Paxos &amp;Raft协议也必须保证时间的一致性；</span><br><span class="line"></span><br><span class="line">5、如果机器间的时间没有被安全管理，理论上可能延长被盗token的使用时间；</span><br><span class="line"></span><br><span class="line">6、被盗用的token可以拿来直接访问服务，在KDC是没有访问日志的。每一个application需要拥有自己的以用户为单位的审计日志，这样才能保证被盗的ticket可被追踪，比如在Hadoop里面HDFS审计日志；</span><br><span class="line"></span><br><span class="line">7、这是一个仅仅认证服务：验证caller的合法性并准许给caller传递认证信息，他不处理任何授权信息；</span><br></pre></td></tr></table></figure><h3 id="mac无法运行-sh文件的解决办法"><a href="#mac无法运行-sh文件的解决办法" class="headerlink" title="mac无法运行.sh文件的解决办法"></a>mac无法运行.sh文件的解决办法</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">今天解决了一下内网穿透的问题，</span><br><span class="line">轻量级的选择有frp，</span><br><span class="line">重量级的有goproxy</span><br><span class="line"></span><br><span class="line">几个问题记录一下，第一点：</span><br><span class="line">zsh无法运行.sh文件，要进行切换</span><br><span class="line">chsh -s /bin/bash</span><br><span class="line">chsh -s /bin/zsh</span><br></pre></td></tr></table></figure><h3 id="解决git下载速度慢的终极方法"><a href="#解决git下载速度慢的终极方法" class="headerlink" title="解决git下载速度慢的终极方法"></a>解决git下载速度慢的终极方法</h3><p>因为本地的网络始终有一些问题，再忍受了很久很久的龟速下载之后，终于找了个一个非常顶的方法</p><p>前提是现有一个vpn，但是vpn不会自动代理git的流量，不管是在windows下面还是在mac下面都不会自动代理git，这点一直让我十分苦恼，现在终于找到了一劳永逸的办法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global http.proxy &apos;socks5://127.0.0.1:1080&apos; </span><br><span class="line">git config --global https.proxy &apos;socks5://127.0.0.1:1080&apos;</span><br></pre></td></tr></table></figure><p>简单说明：vpn一般都是走的1080端口，通过这个端口转发git的流量，跳过本地运营商。</p><h3 id="给win10商店设置代理"><a href="#给win10商店设置代理" class="headerlink" title="给win10商店设置代理"></a>给win10商店设置代理</h3><p>最近发现。。。只要有一个好的代理服务器，win10的商店原来也是能随便打开的，这里介绍一下win10的商店的流量怎么走代理</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">首先通过 Win + R 快捷键打开「运行」窗口，输入「Regedit」打开注册表编辑器，然后定位到 HKEY_CURRENT_USER\Software\Classes\Local Settings\Software\Microsoft\Windows\CurrentVersion\AppContainer\Mappings，接着在左边的注册表项中找到你想解除网络隔离的应用，右边的 DisplayName 就是应用名称，而左边那一大串字符就是应用的 SID 值了。</span><br></pre></td></tr></table></figure><p>找到这个值之后，然后在cmd命令行中输入：</p><p><code>CheckNetIsolation.exe loopbackexempt -a -p=SID</code></p><p>这ID就是上面搜索到的，这样就行</p><h3 id="Maven代理配置"><a href="#Maven代理配置" class="headerlink" title="Maven代理配置"></a>Maven代理配置</h3><p>不需要配置什么https或者http模式，在有代理的前提下，只要配置一个代理即可</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">proxy</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">id</span>&gt;</span>ss<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">active</span>&gt;</span>true<span class="tag">&lt;/<span class="name">active</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">protocol</span>&gt;</span>socks5<span class="tag">&lt;/<span class="name">protocol</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">username</span>&gt;</span><span class="tag">&lt;/<span class="name">username</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">password</span>&gt;</span><span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">host</span>&gt;</span>127.0.0.1<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">port</span>&gt;</span>1080<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">nonProxyHosts</span>&gt;</span>127.0.0.1<span class="tag">&lt;/<span class="name">nonProxyHosts</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">proxy</span>&gt;</span></span><br></pre></td></tr></table></figure><p>要注意的是监控一下端口，如果代理没开的话那肯定是无法连接上的，mirror就不用设置了，直接从中央仓库拉去数据。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;资质低下 三心二意 昨日知识 朝花夕拾&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Interview" scheme="http://yoursite.com/categories/Interview/"/>
    
    
      <category term="PICKS" scheme="http://yoursite.com/tags/PICKS/"/>
    
  </entry>
  
  <entry>
    <title>clearLastUpdated</title>
    <link href="http://yoursite.com/2020/03/17/clearLastUpdated/"/>
    <id>http://yoursite.com/2020/03/17/clearLastUpdated/</id>
    <published>2020-03-17T02:46:49.404Z</published>
    <updated>2020-05-23T12:15:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>mvn库 windows清理脚本<br>需要把mvn的位置改成自己的<br><a id="more"></a> </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">@echo off</span><br><span class="line">  </span><br><span class="line">rem 这里写你的仓库路径</span><br><span class="line">set REPOSITORY_PATH=C:\Users\flyho\.m2\repository</span><br><span class="line">rem 正在搜索...</span><br><span class="line">for /f &quot;delims=&quot; %%i in (&apos;dir /b /s &quot;%REPOSITORY_PATH%\*lastUpdated*&quot;&apos;) do (</span><br><span class="line">    echo %%i</span><br><span class="line">    del /s /q &quot;%%i&quot;</span><br><span class="line">)</span><br><span class="line">rem 搜索完毕</span><br><span class="line">pause</span><br></pre></td></tr></table></figure><p>另一个版本：因为有中文显示，所以编码格式不能用UTF-8</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">cls </span><br><span class="line">@ECHO OFF </span><br><span class="line">SET CLEAR_PATH=C: </span><br><span class="line">SET CLEAR_DIR=C:\Users\flyho\.m2\repository</span><br><span class="line">color 0a </span><br><span class="line">TITLE ClearLastUpdated For Windows </span><br><span class="line">GOTO MENU </span><br><span class="line">:MENU </span><br><span class="line">CLS</span><br><span class="line">ECHO. </span><br><span class="line">ECHO. * * * *  ClearLastUpdated For Windows  * * * * </span><br><span class="line">ECHO. * * </span><br><span class="line">ECHO. * 1 清理*.lastUpdated * </span><br><span class="line">ECHO. * * </span><br><span class="line">ECHO. * 2 查看*.lastUpdated * </span><br><span class="line">ECHO. * * </span><br><span class="line">ECHO. * 3 退 出 * </span><br><span class="line">ECHO. * * </span><br><span class="line">ECHO. * * * * * * * * * * * * * * * * * * * * * * * * </span><br><span class="line">ECHO. </span><br><span class="line">ECHO.请输入选择项目的序号： </span><br><span class="line">set /p ID= </span><br><span class="line">IF &quot;%id%&quot;==&quot;1&quot; GOTO cmd1 </span><br><span class="line">IF &quot;%id%&quot;==&quot;2&quot; GOTO cmd2 </span><br><span class="line">IF &quot;%id%&quot;==&quot;3&quot; EXIT </span><br><span class="line">PAUSE </span><br><span class="line">:cmd1 </span><br><span class="line">ECHO. 开始清理</span><br><span class="line">%CLEAR_PATH%</span><br><span class="line">cd %CLEAR_DIR%</span><br><span class="line">for /r %%i in (*.lastUpdated) do del %%i</span><br><span class="line">ECHO.OK </span><br><span class="line">PAUSE </span><br><span class="line">GOTO MENU </span><br><span class="line">:cmd2 </span><br><span class="line">ECHO. 查看*.lastUpdated文件</span><br><span class="line">%CLEAR_PATH%</span><br><span class="line">cd %CLEAR_DIR%</span><br><span class="line">for /r %%i in (*.lastUpdated) do echo %%i</span><br><span class="line">ECHO.OK </span><br><span class="line">PAUSE </span><br><span class="line">GOTO MENU</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;mvn库 windows清理脚本&lt;br&gt;需要把mvn的位置改成自己的&lt;br&gt;
    
    </summary>
    
      <category term="Script" scheme="http://yoursite.com/categories/Script/"/>
    
    
      <category term="Script" scheme="http://yoursite.com/tags/Script/"/>
    
  </entry>
  
  <entry>
    <title>Scala Note</title>
    <link href="http://yoursite.com/2020/03/09/Scala%20Note/"/>
    <id>http://yoursite.com/2020/03/09/Scala Note/</id>
    <published>2020-03-09T10:03:41.710Z</published>
    <updated>2019-08-16T08:06:13.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>开一个新坑，Scala这门语言在优化上有很大的操作余地，需要相当的熟练度。本文仅做基础笔记的整理。</p></blockquote><a id="more"></a> <h1 id="Scala"><a href="#Scala" class="headerlink" title="Scala"></a>Scala</h1><h2 id="Scala-介绍"><a href="#Scala-介绍" class="headerlink" title="Scala 介绍"></a>Scala 介绍</h2><p>Scala 是 Scalable Language 的简写，是一门多范式的编程语言</p><p>联邦理工学院洛桑（EPFL）的Martin Odersky于2001年基于Funnel的工作开始设计Scala。</p><p>Funnel是把函数式编程思想和Petri网相结合的一种编程语言。</p><p>Odersky先前的工作是Generic Java和javac（Sun Java编译器）。Java平台的Scala于2003年底/2004年初发布。.NET平台的Scala发布于2004年6月。该语言第二个版本，v2.0，发布于2006年3月。</p><p>截至2009年9月，最新版本是版本2.7.6 。Scala 2.8预计的特性包括重写的Scala类库（Scala collections library）、方法的命名参数和默认参数、包对象（package object），以及Continuation。</p><p>2009年4月，Twitter宣布他们已经把大部分后端程序从Ruby迁移到Scala，其余部分也打算要迁移。此外， Wattzon已经公开宣称，其整个平台都已经是基于Scala基础设施编写的。</p><hr><h2 id="环境部分："><a href="#环境部分：" class="headerlink" title="环境部分："></a>环境部分：</h2><p>安装：和Java一样也要配置环境变量</p><p>配置IDEA：</p><p>先安装插件Scala</p><p>然后创建Maven项目</p><p>因为Maven默认不支持Scala</p><p>创建完毕之后</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3izm7uublj20f30ch0t5.jpg" alt></p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3izmsgpxxj20pw0lnab5.jpg" alt></p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3iznzcv6ej20sw0o13zt.jpg" alt></p><p>Scala文件夹标记为Source</p><h2 id="语法部分"><a href="#语法部分" class="headerlink" title="语法部分"></a>语法部分</h2><h3 id="Hello-Scala"><a href="#Hello-Scala" class="headerlink" title="Hello Scala"></a>Hello Scala</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HelloScala</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    println(<span class="string">"hello Scala"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>命令台执行命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala -cp C:\Users\61661\Desktop\scala-1.0-SNAPSHOT.jar HelloScala</span><br></pre></td></tr></table></figure><h3 id="声明值和变量"><a href="#声明值和变量" class="headerlink" title="声明值和变量"></a>声明值和变量</h3><p>Scala声明变量有两种方式：<code>val</code> 和 <code>var</code></p><p><code>val</code>定义的值是不可变的，它不是一个常量，是不可变量，或者称之为只读变量。</p><p>Tips：</p><ol><li>Scala的匿名变量（为了运行程序，系统自动添加的变量）分配<code>val</code>。</li><li><code>val</code>定义的变量虽然不能改变其引用的内存地址，但是可以改变其引用的对象的内部的其他属性值。</li><li>为了减少可变性引起的bug，应该尽可能地使用不可变变量。变量类型可以省略，解析器会根据值进行推断。<code>val</code>和<code>var</code>声明变量时都必须初始化。</li></ol><h3 id="常用类型"><a href="#常用类型" class="headerlink" title="常用类型"></a>常用类型</h3><p>8种常用类型</p><table><thead><tr><th>类型</th><th>属性</th></tr></thead><tbody><tr><td>Boolean</td><td><code>true</code> 或者 <code>false</code></td></tr><tr><td>Byte</td><td>8位， 有符号</td></tr><tr><td>Short</td><td>16位， 有符号</td></tr><tr><td>Int</td><td>32位， 有符号</td></tr><tr><td>Long</td><td>64位， 有符号</td></tr><tr><td>Char</td><td>16位， 无符号</td></tr><tr><td>Float</td><td>32位， 单精度浮点数</td></tr><tr><td>Double</td><td>64位， 双精度浮点数</td></tr><tr><td>String</td><td>由Char数组组成</td></tr></tbody></table><p>与Java中的数据类型不同，Scala并不区分基本类型和引用类型，所以这些类型<strong>都是对象</strong></p><p>可以调用相对应的方法，String直接使用的是<code>java.lang.String</code></p><p>由于String实际是一系列Char的不可变的集合，Scala中大部分针对集合的操作，都可以用于String，具体来说，String的这些方法存在于类<code>scala.collection.immutable.StringOps</code>中。</p><p>由于String在需要时能隐式转换为<code>StringOps</code>，因此不需要任何额外的转换，String就可以使用这些方法。</p><p>每一种数据类型都有对应的<code>Rich*</code>类型，如<code>RichInt</code>、<code>RichChar</code>等，为基本类型提供了更多的有用操作。</p><h3 id="常用类型结构图"><a href="#常用类型结构图" class="headerlink" title="常用类型结构图"></a>常用类型结构图</h3><p>Scala中，所有的值都是类对象，而所有的类，包括值类型，都最终继承自一个统一的根类型<code>Any</code>。统一类型，是Scala的又一大特点。更特别的是，Scala中还定义了几个底层类<code>Bottom Class</code>，比如<code>Null</code>和<code>Nothing</code>。</p><ol><li><code>Null</code>是所有引用类型的子类型，而<code>Nothing</code>是所有类型的子类型。<code>Null</code>类只有一个实例对象，<code>null</code>，类似于Java中的<code>null</code>引用。<code>null</code>可以赋值给任意引用类型，但是不能赋值给值类型。</li><li><code>Nothing</code>，可以作为没有正常返回值的方法的返回类型，非常直观的告诉你这个方法不会正常返回，而且由于<code>Nothing</code>是其他任意类型的子类，他还能跟要求返回值的方法兼容。</li><li><code>Unit</code>类型用来标识过程，也就是没有明确返回值的函数。 由此可见，<code>Unit</code>类似于<code>Java</code>里的<code>void</code>。<code>Unit</code>只有一个实例，()，这个实例也没有实质的意义。</li></ol><p>关系图：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3jcuo85e8j20of0gtta1.jpg" alt></p><h3 id="算数操作符重载"><a href="#算数操作符重载" class="headerlink" title="算数操作符重载"></a>算数操作符重载</h3><p><code>+</code> <code>-</code> <code>*</code> <code>/</code> <code>%</code>可以完成和Java中相同的工作，但是有一点区别，他们都是方法。你几乎可以用任何符号来为方法命名。</p><p><code>1 + 2</code> 等同于 <code>1.+(2)</code></p><p>Tips: Scala中没有++、–操作符，需要通过+=、-=来实现同样的效果。</p><h3 id="调用函数与方法"><a href="#调用函数与方法" class="headerlink" title="调用函数与方法"></a>调用函数与方法</h3><p>在Scala中，一般情况下我们不会刻意的去区分<code>函数</code>与<code>方法</code>的区别，但是他们确实是不同的东西。</p><p>后面我们再详细探讨。首先我们要学会使用Scala来调用函数与方法。</p><h4 id="1-调用函数，求方根"><a href="#1-调用函数，求方根" class="headerlink" title="1.调用函数，求方根"></a>1.调用函数，求方根</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.math</span><br><span class="line">sqrt(<span class="number">100</span>)</span><br></pre></td></tr></table></figure><h4 id="2-调用方法，静态方法（Scala中没有静态方法这个概念，需要通过伴生类对象来实现）"><a href="#2-调用方法，静态方法（Scala中没有静态方法这个概念，需要通过伴生类对象来实现）" class="headerlink" title="2.调用方法，静态方法（Scala中没有静态方法这个概念，需要通过伴生类对象来实现）"></a>2.调用方法，静态方法（Scala中没有静态方法这个概念，需要通过伴生类对象来实现）</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">BigInt</span>.probablePrime(<span class="number">16</span>, scala.util.<span class="type">Random</span>)</span><br></pre></td></tr></table></figure><h4 id="3-调用方法，非静态方法，使用对象调用"><a href="#3-调用方法，非静态方法，使用对象调用" class="headerlink" title="3.调用方法，非静态方法，使用对象调用"></a>3.调用方法，非静态方法，使用对象调用</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"HelloWorld"</span>.distinct</span><br></pre></td></tr></table></figure><h4 id="4-apply与update方法"><a href="#4-apply与update方法" class="headerlink" title="4.apply与update方法"></a>4.apply与update方法</h4><p>apply方法是调用时可以省略方法名的方法。用于构造和获取元素：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"Hello"</span>(<span class="number">4</span>)  等同于  <span class="string">"Hello"</span>.apply(<span class="number">4</span>)</span><br><span class="line"><span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>) 等同于 <span class="type">Array</span>.apply(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">如：</span><br><span class="line">println(<span class="string">"Hello"</span>(<span class="number">4</span>))</span><br><span class="line">println(<span class="string">"Hello"</span>.apply(<span class="number">4</span>))</span><br></pre></td></tr></table></figure><p>在<code>StringOps</code>中你会发现一个 <code>def apply(n: Int): Char</code>方法定义。<code>update</code>方法也是调用时可以省略方法名的方法，用于元素的更新：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">arr(<span class="number">4</span>) = <span class="number">5</span>  等同于  arr.update(<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">如：</span><br><span class="line"><span class="keyword">val</span> arr1 = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Int</span>](<span class="number">5</span>)</span><br><span class="line">arr1(<span class="number">1</span>) = <span class="number">2</span></span><br><span class="line">arr1.update(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">println(arr1.mkString(<span class="string">","</span>))</span><br></pre></td></tr></table></figure><h4 id="Option类型"><a href="#Option类型" class="headerlink" title="Option类型"></a>Option类型</h4><p>Scala为单个值提供了对象的包装器，表示为那种可能存在也可能不存在的值。他只有两个有效的子类对象，一个是Some，表示某个值，另外一个是None，表示为空，通过Option的使用，避免了使用null、空字符串等方式来表示缺少某个值的做法。</p><p>如：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> map1 = <span class="type">Map</span>(<span class="string">"Alice"</span> -&gt; <span class="number">20</span>, <span class="string">"Bob"</span> -&gt; <span class="number">30</span>)</span><br><span class="line">println(map1.get(<span class="string">"Alice"</span>))</span><br><span class="line">println(map1.get(<span class="string">"Jone"</span>))</span><br></pre></td></tr></table></figure><h3 id="控制结构和函数"><a href="#控制结构和函数" class="headerlink" title="控制结构和函数"></a>控制结构和函数</h3><h4 id="if-else"><a href="#if-else" class="headerlink" title="if else"></a>if else</h4><p>Scala中没有三目运算符，因为根本不需要。Scala中if else表达式是有返回值的，如果if或者else返回的类型不一样，就返回Any类型（所有类型的公共超类型）。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> a3 = <span class="number">10</span></span><br><span class="line">    <span class="keyword">val</span> a4 =</span><br><span class="line">      <span class="comment">//返回类型一样</span></span><br><span class="line">      <span class="keyword">if</span>(a3 &gt; <span class="number">20</span>)&#123;</span><br><span class="line">        <span class="string">"a3大于20"</span></span><br><span class="line">      &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="string">"a3小于20"</span></span><br><span class="line">      &#125;</span><br><span class="line">    <span class="keyword">val</span> a5 = </span><br><span class="line">      <span class="keyword">if</span>(a3 &gt; <span class="number">20</span>)&#123;</span><br><span class="line">          <span class="string">"a3大于20"</span></span><br><span class="line">      &#125;</span><br><span class="line">    println(a4)</span><br><span class="line">    <span class="comment">//a3小于20</span></span><br><span class="line">    println(a5)</span><br><span class="line">    <span class="comment">//()</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果缺少一个判断，什么都没有返回，但是Scala认为任何表达式都会有值，对于空值，使用Unit类，写做()，叫做无用占位符，相当于Java中的void。</p><p>Tips: 行尾的位置不需要分号，只要能够从上下文判断出语句的终止即可。但是如果在单行中写多个语句，则需要分号分割。在Scala中，{}块包含一系列表达式，其结果也是一个表达式。块中最后一个表达式的值就是块的值。</p><h4 id="while-表达式"><a href="#while-表达式" class="headerlink" title="while 表达式"></a>while 表达式</h4><p>Scala提供和Java一样的while和do循环，与If语句不同，While语句本身没有值，即整个While语句的结果是Unit类型的()。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">var</span> n = <span class="number">1</span></span><br><span class="line">    <span class="keyword">val</span> while1 = <span class="keyword">while</span>(n &lt;= <span class="number">10</span>)&#123;</span><br><span class="line">      n += <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    println(while1) <span class="comment">//()</span></span><br><span class="line">    println(n) <span class="comment">//11</span></span><br><span class="line">    <span class="comment">//Scala提供和Java一样的while和do循环，与If语句不同，While语句本身没有值，即整个While语句的结果是Unit类型的()。</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>while循环的中断</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.util.control.<span class="type">Breaks</span></span><br><span class="line"><span class="keyword">val</span> loop = <span class="keyword">new</span> <span class="type">Breaks</span></span><br><span class="line">loop.breakable&#123;</span><br><span class="line">  <span class="keyword">while</span>(n &lt;= <span class="number">20</span>)&#123;</span><br><span class="line">    n += <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span>(n == <span class="number">18</span>)&#123;</span><br><span class="line">      loop.<span class="keyword">break</span>()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">println(n)</span><br></pre></td></tr></table></figure><p>Tips: Scala并没有提供break和continue语句来退出循环，如果需要break，可以通过几种方法来做1、使用Boolean型的控制变量 2、使用嵌套函数，从函数中return 3、使用Breaks对象的break方法。</p><h4 id="for表达式"><a href="#for表达式" class="headerlink" title="for表达式"></a>for表达式</h4><p>Scala也为for循环这一常见的控制结构提供了非常多的特性，这些for循环特性被称为for推导式(for comprehension)或for表达式(for expression).</p><h5 id="for示例1-to左右两边为前闭后闭的访问"><a href="#for示例1-to左右两边为前闭后闭的访问" class="headerlink" title="for示例1: to左右两边为前闭后闭的访问"></a>for示例1: to左右两边为前闭后闭的访问</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(i &lt;- <span class="number">1</span> to <span class="number">3</span>; j &lt;- <span class="number">1</span> to <span class="number">3</span>)&#123;</span><br><span class="line">  print(i * j + <span class="string">" "</span>)</span><br><span class="line">&#125;</span><br><span class="line">println()</span><br></pre></td></tr></table></figure><h5 id="for示例2：until左右两边为前闭后开的访问"><a href="#for示例2：until左右两边为前闭后开的访问" class="headerlink" title="for示例2：until左右两边为前闭后开的访问"></a>for示例2：until左右两边为前闭后开的访问</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(i &lt;- <span class="number">1</span> until <span class="number">3</span>; j &lt;- <span class="number">1</span> until <span class="number">3</span>) &#123;</span><br><span class="line">  print(i * j + <span class="string">" "</span>)</span><br><span class="line">&#125;</span><br><span class="line">println()</span><br></pre></td></tr></table></figure><h5 id="for示例3：引入保护式（也称条件判断式）该语句只打印1-3。保护式满足为true则进入循环内部，满足为false则跳过，类似于continue"><a href="#for示例3：引入保护式（也称条件判断式）该语句只打印1-3。保护式满足为true则进入循环内部，满足为false则跳过，类似于continue" class="headerlink" title="for示例3：引入保护式（也称条件判断式）该语句只打印1 3。保护式满足为true则进入循环内部，满足为false则跳过，类似于continue"></a>for示例3：引入保护式（也称条件判断式）该语句只打印1 3。保护式满足为true则进入循环内部，满足为false则跳过，类似于continue</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(i &lt;- <span class="number">1</span> to <span class="number">3</span> <span class="keyword">if</span> i != <span class="number">2</span>) &#123;</span><br><span class="line">  print(i + <span class="string">" "</span>)</span><br><span class="line">&#125;</span><br><span class="line">println()</span><br></pre></td></tr></table></figure><h5 id="for示例4：引入变量"><a href="#for示例4：引入变量" class="headerlink" title="for示例4：引入变量"></a>for示例4：引入变量</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(i &lt;- <span class="number">1</span> to <span class="number">3</span>; j = <span class="number">4</span> - i) &#123;</span><br><span class="line">  print(j + <span class="string">" "</span>)</span><br><span class="line">&#125;</span><br><span class="line">println()</span><br></pre></td></tr></table></figure><h5 id="for示例5：将遍历过程中处理的结果返回到一个，使用yield关键字"><a href="#for示例5：将遍历过程中处理的结果返回到一个，使用yield关键字" class="headerlink" title="for示例5：将遍历过程中处理的结果返回到一个，使用yield关键字"></a>for示例5：将遍历过程中处理的结果返回到一个，使用yield关键字</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> for5 = <span class="keyword">for</span>(i &lt;- <span class="number">1</span> to <span class="number">10</span>) <span class="keyword">yield</span> i</span><br><span class="line">println(for5)</span><br></pre></td></tr></table></figure><h5 id="for示例6：使用花括号-代替小括号"><a href="#for示例6：使用花括号-代替小括号" class="headerlink" title="for示例6：使用花括号{}代替小括号()"></a>for示例6：使用花括号{}代替小括号()</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>&#123;</span><br><span class="line">  i &lt;- <span class="number">1</span> to <span class="number">3</span></span><br><span class="line">  j = <span class="number">4</span> - i&#125;</span><br><span class="line">  print(i * j + <span class="string">" "</span>)</span><br><span class="line">println()</span><br></pre></td></tr></table></figure><p><strong>Tips</strong>: {}和()对于for表达式来说都可以。for 推导式有一个不成文的约定：当for<br>推导式仅包含单一表达式时使用原括号，当其包含多个表达式时使用大括号。值得注意的是，使用原括号时，早前版本的Scala 要求表达式之间必须使用分号。</p><h4 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h4><p>scala定义函数的标准格式为：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">函数名</span></span>(参数名<span class="number">1</span>: 参数类型<span class="number">1</span>, 参数名<span class="number">2</span>: 参数类型<span class="number">2</span>) : 返回类型 = &#123;函数体&#125;</span><br></pre></td></tr></table></figure><p>函数示例1：返回Unit类型的函数：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">shout1</span><span class="params">(content: String)</span> : Unit </span>= &#123;</span><br><span class="line">  println(content)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>函数示例2：返回Unit类型的函数，但是没有显式指定返回类型。（当然也可以返回非Unit类型的值）</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shout2</span></span>(content: <span class="type">String</span>) = &#123;</span><br><span class="line">  println(content)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>函数示例3:返回值类型有多种可能，此时也可以省略Unit</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shout3</span></span>(content: <span class="type">String</span>) = &#123;</span><br><span class="line">  <span class="keyword">if</span>(content.length &gt;= <span class="number">3</span>)</span><br><span class="line">    content + <span class="string">"喵喵喵~"</span></span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="number">3</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>函数示例4：带有默认值参数的函数，调用该函数时，可以只给无默认值的参数传递值，也可以都传递，新值会覆盖默认值；传递参数时如果不按照定义顺序，则可以通过参数名来指定。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shout4</span></span>(content: <span class="type">String</span>, leg: <span class="type">Int</span> = <span class="number">4</span>) = &#123;</span><br><span class="line">  println(content + <span class="string">","</span> + leg)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>函数示例5：变长参数（不确定个数参数，类似Java的…）</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>(args: <span class="type">Int</span>*) = &#123;</span><br><span class="line">  <span class="keyword">var</span> result = <span class="number">0</span></span><br><span class="line">  <span class="keyword">for</span>(arg &lt;- args)</span><br><span class="line">    result += arg</span><br><span class="line">  result</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>递归函数：递归函数在使用时必须有明确的返回值类型</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">factorial</span></span>(n: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span>(n &lt;= <span class="number">0</span>)</span><br><span class="line">    <span class="number">1</span></span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    n * factorial(n - <span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Tips:</strong></p><p>1、Scala可以通过=右边的表达式  推断出函数的返回类型。如果函数体需要多个表达式，可以用代码块{}。</p><p>2、可以把return 当做  函数版本的break语句。</p><p>3、递归函数一定要指定返回类型。</p><p>4、变长参数通过* 来指定，所有参数会转化为一个seq序列。</p><h4 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h4><p>我们将函数的返回类型为Unit的函数称之为过程。</p><h5 id="定义过程示例1："><a href="#定义过程示例1：" class="headerlink" title="定义过程示例1："></a>定义过程示例1：</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shout1</span></span>(content: <span class="type">String</span>) : <span class="type">Unit</span> = &#123;</span><br><span class="line">  println(content)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义过程示例2：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shout1</span></span>(content: <span class="type">String</span>) = &#123;</span><br><span class="line">  println(content)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义过程示例3：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shout1</span></span>(content: <span class="type">String</span>) &#123;</span><br><span class="line">  println(content)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>尖叫提示：这只是一个逻辑上的细分，如果因为该概念导致了理解上的混淆，可以暂时直接跳过过程这样的描述。毕竟过程，在某种意义上也是函数。</p><h4 id="懒值"><a href="#懒值" class="headerlink" title="懒值"></a>懒值</h4><p>当val被声明为lazy时，他的初始化将被推迟，直到我们首次对此取值，适用于初始化开销较大的场景。</p><p>lazy示例：通过lazy关键字的使用与否，来观察执行过程</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Lazy</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">init</span></span>(): <span class="type">String</span> = &#123;</span><br><span class="line">    println(<span class="string">"init方法执行"</span>)</span><br><span class="line">    <span class="string">"嘿嘿嘿，我来了~"</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">lazy</span> <span class="keyword">val</span> msg = init()</span><br><span class="line">    println(<span class="string">"lazy方法没有执行"</span>)</span><br><span class="line">    println(msg)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h4><p>当碰到异常情况时，方法抛出一个异常，终止方法本身的执行，异常传递到其调用者，调用者可以处理该异常，也可以升级到它的调用者。运行系统会一直这样升级异常，直到有调用者能处理它。 如果一直没有处理，则终止整个程序。</p><p>Scala的异常的工作机制和Java一样，但是Scala没有“checked”异常，你不需要声明说函数或者方法可能会抛出某种异常。受检异常在编译器被检查，java必须声明方法所会抛出的异常类型。</p><p><strong>抛出异常</strong>：用throw关键字，抛出一个异常对象。所有异常都是Throwable的子类型。throw表达式是有类型的，就是Nothing，因为Nothing是所有类型的子类型，所以throw表达式可以用在需要类型的地方。</p><p><strong>捕捉异常：</strong>在Scala里，借用了模式匹配的思想来做异常的匹配，因此，在catch的代码里，是一系列case字句。</p><p>异常捕捉的机制与其他语言中一样，如果有异常发生，catch字句是按次序捕捉的。因此，在catch字句中，越具体的异常越要靠前，越普遍的异常越靠后。 如果抛出的异常不在catch字句中，该异常则无法处理，会被升级到调用者处。</p><p>finally字句用于执行不管是正常处理还是有异常发生时都需要执行的步骤，一般用于对象的清理工作。</p><h5 id="异常示例："><a href="#异常示例：" class="headerlink" title="异常示例："></a>异常示例：</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ExceptionSyllabus</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">divider</span></span>(x: <span class="type">Int</span>, y: <span class="type">Int</span>): <span class="type">Float</span>= &#123;</span><br><span class="line">    <span class="keyword">if</span>(y == <span class="number">0</span>) <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">Exception</span>(<span class="string">"0作为了除数"</span>)</span><br><span class="line">    <span class="keyword">else</span> x / y</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          println(divider(<span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">          <span class="keyword">case</span> ex: <span class="type">Exception</span> =&gt; println(<span class="string">"捕获了异常："</span> + ex)</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><h4 id="数据结构特点"><a href="#数据结构特点" class="headerlink" title="数据结构特点"></a>数据结构特点</h4><p>Scala同时支持可变集合和不可变集合，不可变集合从不可变，可以安全的并发访问。</p><p>两个主要的包：</p><p>不可变集合：scala.collection.immutable</p><p>可变集合：  scala.collection.mutable</p><p>Scala优先采用不可变集合，对于几乎所有的集合类，Scala都同时提供了可变和不可变的版本。</p><p>不可变集合继承层次：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g61hebn4l8j20qa0j63zo.jpg" alt></p><p>可变集合继承层次：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g61hf54tkwj20xc0l0q50.jpg" alt></p><h4 id="数组Array"><a href="#数组Array" class="headerlink" title="数组Array"></a>数组Array</h4><h5 id="1-定长数组"><a href="#1-定长数组" class="headerlink" title="1.定长数组"></a>1.定长数组</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//定义</span></span><br><span class="line"><span class="keyword">val</span> arr1 = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Int</span>](<span class="number">10</span>)</span><br><span class="line"><span class="comment">//赋值</span></span><br><span class="line">arr1(<span class="number">1</span>) = <span class="number">7</span></span><br><span class="line">或：</span><br><span class="line"><span class="comment">//定义</span></span><br><span class="line"><span class="keyword">val</span> arr1 = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure><h5 id="2-变长数组"><a href="#2-变长数组" class="headerlink" title="2.变长数组"></a>2.变长数组</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//定义</span></span><br><span class="line"><span class="keyword">val</span> arr2 = <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]()</span><br><span class="line"><span class="comment">//追加值</span></span><br><span class="line">arr2.append(<span class="number">7</span>)</span><br><span class="line"><span class="comment">//重新赋值</span></span><br><span class="line">arr2(<span class="number">0</span>) = <span class="number">7</span></span><br></pre></td></tr></table></figure><h5 id="3-定长数据与变长数据的装换"><a href="#3-定长数据与变长数据的装换" class="headerlink" title="3.定长数据与变长数据的装换"></a>3.定长数据与变长数据的装换</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arr1.toBuffer</span><br><span class="line">arr2.toArray</span><br></pre></td></tr></table></figure><h5 id="4-多维数据"><a href="#4-多维数据" class="headerlink" title="4.多维数据"></a>4.多维数据</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//定义</span></span><br><span class="line"><span class="keyword">val</span> arr3 = <span class="type">Array</span>.ofDim[<span class="type">Double</span>](<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="comment">//赋值</span></span><br><span class="line">arr3(<span class="number">1</span>)(<span class="number">1</span>) = <span class="number">11.11</span></span><br></pre></td></tr></table></figure><h5 id="5-与Java数组的互转"><a href="#5-与Java数组的互转" class="headerlink" title="5.与Java数组的互转"></a>5.与Java数组的互转</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//scala =&gt; Java</span></span><br><span class="line"><span class="keyword">val</span> arr4 = <span class="type">ArrayBuffer</span>(<span class="string">"1"</span>, <span class="string">"2"</span>, <span class="string">"3"</span>)</span><br><span class="line"><span class="comment">//Scala to Java</span></span><br><span class="line"><span class="keyword">import</span> scala.collection.<span class="type">JavaConversions</span>.bufferAsJavaList</span><br><span class="line"><span class="keyword">val</span> javaArr = <span class="keyword">new</span> <span class="type">ProcessBuilder</span>(arr4)</span><br><span class="line">println(javaArr.command())</span><br><span class="line"></span><br><span class="line"><span class="comment">//Java =&gt; scala</span></span><br><span class="line"><span class="keyword">import</span> scala.collection.<span class="type">JavaConversions</span>.asScalaBuffer</span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">Buffer</span></span><br><span class="line"><span class="keyword">val</span> scalaArr: <span class="type">Buffer</span>[<span class="type">String</span>] = javaArr.command()</span><br><span class="line">println(scalaArr)</span><br></pre></td></tr></table></figure><p>6.数据的遍历</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(x &lt;- arr1) &#123;</span><br><span class="line">  println(x)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="5-3-元组-Tuple"><a href="#5-3-元组-Tuple" class="headerlink" title="5.3 元组 Tuple"></a>5.3 元组 Tuple</h4><p>元组可以理解为一个容器，可以存放各种相同或者不同类型的数据。</p><h5 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tuple1 = (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="string">"heiheihei"</span>)</span><br><span class="line">println(tuple1)</span><br></pre></td></tr></table></figure><h5 id="访问-注意元素元素访问邮箱划线，并且访问下标从1开始，而不是0"><a href="#访问-注意元素元素访问邮箱划线，并且访问下标从1开始，而不是0" class="headerlink" title="访问(注意元素元素访问邮箱划线，并且访问下标从1开始，而不是0)"></a>访问(注意元素元素访问邮箱划线，并且访问下标从1开始，而不是0)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val value1 = tuple1._4</span><br><span class="line">println(value1)</span><br></pre></td></tr></table></figure><h5 id="元组的遍历"><a href="#元组的遍历" class="headerlink" title="元组的遍历"></a>元组的遍历</h5><p><strong>方式1</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (elem &lt;- tuple1.productIterator) &#123;</span><br><span class="line">  print(elem)</span><br><span class="line">&#125;</span><br><span class="line">println()</span><br></pre></td></tr></table></figure><p><strong>方式2</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tuple1.productIterator.foreach(i =&gt; println(i))</span><br><span class="line">tuple1.productIterator.foreach(print(_))</span><br></pre></td></tr></table></figure><h4 id="列表List"><a href="#列表List" class="headerlink" title="列表List"></a>列表List</h4><p>如果List列表为空，则使用Nil来表示</p><h5 id="创建List"><a href="#创建List" class="headerlink" title="创建List"></a>创建List</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> list1 = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">println(list1)</span><br></pre></td></tr></table></figure><h5 id="访问List元素"><a href="#访问List元素" class="headerlink" title="访问List元素"></a>访问List元素</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> value1 = list1(<span class="number">1</span>)</span><br><span class="line">println(value1)</span><br></pre></td></tr></table></figure><h5 id="List元素的追加"><a href="#List元素的追加" class="headerlink" title="List元素的追加"></a>List元素的追加</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> list2 = list1 :+ <span class="number">99</span></span><br><span class="line">println(list2)</span><br><span class="line"><span class="keyword">val</span> list3 = <span class="number">100</span> +: list1</span><br><span class="line">println(list3)</span><br></pre></td></tr></table></figure><p>List的创建与追加，符号“::”，注意观察去掉Nil和不去掉Nil的区别</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> list4 = <span class="number">1</span> :: <span class="number">2</span> :: <span class="number">3</span> :: list1 :: <span class="type">Nil</span></span><br><span class="line">println(list4)</span><br></pre></td></tr></table></figure><h4 id="队列Queue"><a href="#队列Queue" class="headerlink" title="队列Queue"></a>队列Queue</h4><p>队列数据存取符合先进先出的策略</p><h5 id="队列的创建"><a href="#队列的创建" class="headerlink" title="队列的创建"></a>队列的创建</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"><span class="keyword">val</span> q1 = <span class="keyword">new</span> mutable.<span class="type">Queue</span>[<span class="type">Int</span>]</span><br><span class="line">println(q1)</span><br></pre></td></tr></table></figure><h5 id="队列元素的追加"><a href="#队列元素的追加" class="headerlink" title="队列元素的追加"></a>队列元素的追加</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">q1+=<span class="number">1</span></span><br><span class="line">print;n(q1)</span><br></pre></td></tr></table></figure><h5 id="队列的追加"><a href="#队列的追加" class="headerlink" title="队列的追加"></a>队列的追加</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">q1 ++= <span class="type">List</span>(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">println(q1)</span><br></pre></td></tr></table></figure><h5 id="按照进入队列的顺序删除元素"><a href="#按照进入队列的顺序删除元素" class="headerlink" title="按照进入队列的顺序删除元素"></a>按照进入队列的顺序删除元素</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">q1.dequeue()</span><br><span class="line">println(q1)</span><br></pre></td></tr></table></figure><h5 id="塞入数据"><a href="#塞入数据" class="headerlink" title="塞入数据"></a>塞入数据</h5><h5 id="返回队列的第一个元素"><a href="#返回队列的第一个元素" class="headerlink" title="返回队列的第一个元素"></a>返回队列的第一个元素</h5><h5 id="返回队列的最后一个元素"><a href="#返回队列的最后一个元素" class="headerlink" title="返回队列的最后一个元素"></a>返回队列的最后一个元素</h5><h5 id="返回队列最后一个元素"><a href="#返回队列最后一个元素" class="headerlink" title="返回队列最后一个元素"></a>返回队列最后一个元素</h5><h5 id="返回除了第一个以外的元素"><a href="#返回除了第一个以外的元素" class="headerlink" title="返回除了第一个以外的元素"></a>返回除了第一个以外的元素</h5><h5 id="返回除了第一个以外的元素-1"><a href="#返回除了第一个以外的元素-1" class="headerlink" title="返回除了第一个以外的元素"></a>返回除了第一个以外的元素</h5><h4 id="映射"><a href="#映射" class="headerlink" title="映射"></a>映射</h4><h5 id="构造不可变映射"><a href="#构造不可变映射" class="headerlink" title="构造不可变映射"></a>构造不可变映射</h5><h5 id="构造可变映射"><a href="#构造可变映射" class="headerlink" title="构造可变映射"></a>构造可变映射</h5><h5 id="空的映射"><a href="#空的映射" class="headerlink" title="空的映射"></a>空的映射</h5><h5 id="对偶元组"><a href="#对偶元组" class="headerlink" title="对偶元组"></a>对偶元组</h5><h5 id="取值"><a href="#取值" class="headerlink" title="取值"></a>取值</h5><h5 id="更新值"><a href="#更新值" class="headerlink" title="更新值"></a>更新值</h5><h5 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h5><h4 id="集-Set"><a href="#集-Set" class="headerlink" title="集 Set"></a>集 Set</h4><h5 id="1-Set不可变集合的创建"><a href="#1-Set不可变集合的创建" class="headerlink" title="1.Set不可变集合的创建"></a>1.Set不可变集合的创建</h5><h5 id="2-Set可变集合的创建，如果import了可变集合，那么后续继续使用默认也是可变集合"><a href="#2-Set可变集合的创建，如果import了可变集合，那么后续继续使用默认也是可变集合" class="headerlink" title="2.Set可变集合的创建，如果import了可变集合，那么后续继续使用默认也是可变集合"></a>2.Set可变集合的创建，如果import了可变集合，那么后续继续使用默认也是可变集合</h5><h5 id="3-可变集合的元素添加"><a href="#3-可变集合的元素添加" class="headerlink" title="3.可变集合的元素添加"></a>3.可变集合的元素添加</h5><h5 id="4-可变集合的元素删除"><a href="#4-可变集合的元素删除" class="headerlink" title="4.可变集合的元素删除"></a>4.可变集合的元素删除</h5><h5 id="5-遍历"><a href="#5-遍历" class="headerlink" title="5.遍历"></a>5.遍历</h5><h5 id="6-Set更多常用操作"><a href="#6-Set更多常用操作" class="headerlink" title="6.Set更多常用操作"></a>6.Set更多常用操作</h5><h4 id="集合元素与函数的映射"><a href="#集合元素与函数的映射" class="headerlink" title="集合元素与函数的映射"></a>集合元素与函数的映射</h4><h5 id="map"><a href="#map" class="headerlink" title="map"></a>map</h5><h5 id="flatmap"><a href="#flatmap" class="headerlink" title="flatmap"></a>flatmap</h5><h4 id="化简、折叠、扫描"><a href="#化简、折叠、扫描" class="headerlink" title="化简、折叠、扫描"></a>化简、折叠、扫描</h4><h5 id="折叠，化简：将二次元函数引用于集合中的函数。"><a href="#折叠，化简：将二次元函数引用于集合中的函数。" class="headerlink" title="折叠，化简：将二次元函数引用于集合中的函数。"></a>折叠，化简：将二次元函数引用于集合中的函数。</h5><h5 id="折叠，化简：fold"><a href="#折叠，化简：fold" class="headerlink" title="折叠，化简：fold"></a>折叠，化简：fold</h5>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;开一个新坑，Scala这门语言在优化上有很大的操作余地，需要相当的熟练度。本文仅做基础笔记的整理。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Language" scheme="http://yoursite.com/categories/Language/"/>
    
      <category term="Scala" scheme="http://yoursite.com/categories/Language/Scala/"/>
    
    
      <category term="Scala" scheme="http://yoursite.com/tags/Scala/"/>
    
  </entry>
  
  <entry>
    <title>Analog Data With TPCDS &amp; TPCH</title>
    <link href="http://yoursite.com/2020/03/09/analog_data/"/>
    <id>http://yoursite.com/2020/03/09/analog_data/</id>
    <published>2020-03-09T10:03:41.694Z</published>
    <updated>2020-04-10T17:05:22.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>为了测试Kudu的性能，学习了一下大公司SRE生成模拟数据的手段<br>本文会贴上各种原帖，本文仅记录生成过程中遇到的困难和介绍文章中的不同</p></blockquote><a id="more"></a> <h3 id="大神fayson的日志："><a href="#大神fayson的日志：" class="headerlink" title="大神fayson的日志："></a>大神<code>fayson</code>的日志：</h3><p><a href="https://mp.weixin.qq.com/s?__biz=MzI4OTY3MTUyNg==&amp;mid=2247488108&amp;idx=1&amp;sn=8f34c674bc12990d61a8f4de4ca3c728&amp;chksm=ec2ac265db5d4b731b93c4b7da0b3a24f0bf200274dd763531873bb4dd205e37d704ea2719b6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">如何编译及使用TPC-DS生成测试数据</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzI4OTY3MTUyNg==&amp;mid=2247488190&amp;idx=1&amp;sn=3f34824bdadbfa0823823121f86cafd4&amp;chksm=ec2ac2b7db5d4ba1484d6a6cf3161fdb90798d2605d2e79fa8bf633d32766c42cc8e2b41e206&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">如何编译及使用hive-testbench生成Hive基准测试数据</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzI4OTY3MTUyNg==&amp;mid=2247489095&amp;idx=1&amp;sn=5af481742664f79146c58f425c9429d3&amp;chksm=ec2ac64edb5d4f58860db96ae4b452fda70b108527e4cc78c1978461ed62e67fcf997631d270&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Impala TPC-DS基准测试</a></p><h3 id="一、遇到的问题"><a href="#一、遇到的问题" class="headerlink" title="一、遇到的问题"></a>一、遇到的问题</h3><h4 id="1-源码无法编译"><a href="#1-源码无法编译" class="headerlink" title="1.源码无法编译"></a>1.源码无法编译</h4><p>源码下载下来之后build，需要的组件根本下载不了</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g330ii05j5j20tt0bt75b.jpg" alt></p><p>这里Google到了一个办法</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g330lkku7yj20tn0a7wf6.jpg" alt></p><p>先把包下载下来，放进对应的文件夹里然后编译</p><h4 id="2-安装遇到的问题"><a href="#2-安装遇到的问题" class="headerlink" title="2.安装遇到的问题"></a>2.安装遇到的问题</h4><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g330stw7enj20of0ebdgx.jpg" alt></p><p>类似配置冲突的问题 不知道为什么</p><p>yes和no我都分别选过，但是都不对，配置完成之后执行都有问题</p><p>我初步怀疑可能是版本问题，我下一个旧版本的试一试</p><p><a href="http://www.tpc.org/tpc_documents_current_versions/current_specifications.asp" target="_blank" rel="noopener">TPC下载地址</a></p><p>之前用的是V 2.11的，现在下载一个V 2.10.1的试一下</p><p>执行完毕之后，首先报错</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g335c98sa0j20ns0g2tac.jpg" alt></p><p>权限不够，我重新使用hdfs用户来创建目录</p><p><code>hdfs</code>用户没有办法<code>git clone</code></p><p>我使用了<code>root</code>用户<code>clone</code>之后</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chown -R hdfs:hdfs hive-testbench/</span><br><span class="line">chmod -R 777 hive-testbench/</span><br></pre></td></tr></table></figure><p>将权限开放</p><p>其余操作使用HDFS完成</p><p>。。。</p><p>等了一段时间</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g336c9kby8j20rx05ydfz.jpg" alt></p><p>MR正常运行没有问题，可以MR运行完毕之后还是报错，不知道为什么</p><p>中间又做了很多尝试，失败的尝试在这不做记录</p><p>重点记录一下我在BUG日志中发现HiveServer2有一些问题</p><p>Google之后发现了是因为配置里面出现了问题<br>Java 8里面用原先的配置代码已经被舍弃了，更改完毕之后解决了这个问题，</p><p>但是<code>TPCDS</code>的问题还是没有解决，吐出一口老血</p><p>验证<code>HiveServer2</code>正确开启的代码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> /usr/lib/hive/bin/beeline</span><br><span class="line"><span class="meta">beeline&gt;</span> !connect jdbc:hive2://localhost:10000 username password org.apache.hive.jdbc.HiveDriver</span><br><span class="line">0: jdbc:hive2://localhost:10000&gt; SHOW TABLES;</span><br><span class="line">show tables;</span><br><span class="line">+-----------+</span><br><span class="line">| tab_name  |</span><br><span class="line">+-----------+</span><br><span class="line">+-----------+</span><br><span class="line">No rows selected (0.238 seconds)</span><br><span class="line">0: jdbc:hive2://localhost:10000&gt;</span><br></pre></td></tr></table></figure><p>现在我解决问题的点还在于是不是<code>CDH</code>的配置还有一些问题</p><p>但是<code>TPCH</code>明明又能够生成数据的，难顶了</p><h4 id="3-数据从Hive转入Kudu速度过慢"><a href="#3-数据从Hive转入Kudu速度过慢" class="headerlink" title="3.数据从Hive转入Kudu速度过慢"></a>3.数据从Hive转入Kudu速度过慢</h4><p>从周五下班的点开始到周一上班，1000个Tasks，仅仅完成了210个，速度十分之慢。</p><hr><h3 id="二、解决办法"><a href="#二、解决办法" class="headerlink" title="二、解决办法"></a>二、解决办法</h3><h4 id="1-总结问题"><a href="#1-总结问题" class="headerlink" title="1.总结问题"></a>1.总结问题</h4><p>好好想了下我自己遇到的错误，有几个点，第一个点是<code>TPCH</code>是可以生成数据的，第二个点是我在编译<code>TPCDS</code>源码的过程中，报出了奇怪的提示，我一直怀疑可能是我编译的时候除了问题，但是重新编译了好几遍，一直没有找到解决办法。</p><p>这边在<a href="https://blog.csdn.net/sinat_36300982/article/details/89556220" target="_blank" rel="noopener">另一个技术博客上</a>找到了解决方案，可以在本地编译完成之后再上传到服务器，但是我看了一下这篇博客，他是用的官方原版的<code>hive-testbench</code>，里面会有一些错误，我直接下载了别人使用的版本hive14.zip(可以在TIM上下载)，然后<a href="http://dev.hortonworks.com.s3.amazonaws.com/hive-testbench/tpcds/TPCDS_Tools.zip" target="_blank" rel="noopener">下载TPCDS_Tools.zip</a>改名<code>tpcds_kit.zip</code>放进<code>tpcds</code>对应的文件夹就可以了，最后编译成功。</p><p>编译完成之后，数据在Hive上面，Hive上面生成了两个库，一个是<code>ORC</code>库，还有一个是TEXT库，<code>ORC</code>文件<code>impala</code>用不了就算了，迁移TEXT就行，代码可以在下面的<code>github</code>中找到，然后要注意的事情是最后<code>package</code>的代码，因为是<code>scala</code>，打包的代码和别的并不一样</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">finalName</span>&gt;</span>anlogSparkSQL<span class="tag">&lt;/<span class="name">finalName</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 设置项目编译版本--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.6.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 用于编译scala代码到class --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>net.alchim31.maven<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.2.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>testCompile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">archive</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">manifest</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">mainClass</span>&gt;</span>kuduimport.hiveToKudu<span class="tag">&lt;/<span class="name">mainClass</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">manifest</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">archive</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">id</span>&gt;</span>make-assembly<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>single<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure><p>使用HUE里面的<code>Oozie</code>调用Spark程序的时候，如果想要在spark提交里面出现任务记录，应该添加</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--conf spark.shuffle.memoryFraction=0.3</span><br><span class="line">--conf spark.yarn.historyServer.address=http://datanode127:18089</span><br><span class="line">--conf spark.eventLog.dir=hdfs://master126:8020/user/spark/spark2ApplicationHistory</span><br><span class="line">--conf spark.eventLog.enabled=true</span><br></pre></td></tr></table></figure><p><a href="https://github.com/YunKillerE/kudu-learning" target="_blank" rel="noopener">github/kudu-learning</a></p><hr><h4 id="2-自动生成Kudu表格脚本"><a href="#2-自动生成Kudu表格脚本" class="headerlink" title="2.自动生成Kudu表格脚本"></a>2.自动生成Kudu表格脚本</h4><p>脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br><span class="line">715</span><br><span class="line">716</span><br><span class="line">717</span><br><span class="line">718</span><br><span class="line">719</span><br><span class="line">720</span><br><span class="line">721</span><br><span class="line">722</span><br><span class="line">723</span><br><span class="line">724</span><br><span class="line">725</span><br><span class="line">726</span><br><span class="line">727</span><br><span class="line">728</span><br><span class="line">729</span><br><span class="line">730</span><br><span class="line">731</span><br></pre></td><td class="code"><pre><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists call_center;</span><br><span class="line"></span><br><span class="line">create table call_center(</span><br><span class="line">      cc_call_center_sk         bigint               </span><br><span class="line">,     cc_call_center_id         string              </span><br><span class="line">,     cc_rec_start_date        string                         </span><br><span class="line">,     cc_rec_end_date          string                         </span><br><span class="line">,     cc_closed_date_sk         bigint                       </span><br><span class="line">,     cc_open_date_sk           bigint                       </span><br><span class="line">,     cc_name                   string                   </span><br><span class="line">,     cc_class                  string                   </span><br><span class="line">,     cc_employees              int                       </span><br><span class="line">,     cc_sq_ft                  int                       </span><br><span class="line">,     cc_hours                  string                      </span><br><span class="line">,     cc_manager                string                   </span><br><span class="line">,     cc_mkt_id                 int                       </span><br><span class="line">,     cc_mkt_class              string                      </span><br><span class="line">,     cc_mkt_desc               string                  </span><br><span class="line">,     cc_market_manager         string                   </span><br><span class="line">,     cc_division               int                       </span><br><span class="line">,     cc_division_name          string                   </span><br><span class="line">,     cc_company                int                       </span><br><span class="line">,     cc_company_name           string                      </span><br><span class="line">,     cc_street_number          string                      </span><br><span class="line">,     cc_street_name            string                   </span><br><span class="line">,     cc_street_type            string                      </span><br><span class="line">,     cc_suite_number           string                      </span><br><span class="line">,     cc_city                   string                   </span><br><span class="line">,     cc_county                 string                   </span><br><span class="line">,     cc_state                  string                       </span><br><span class="line">,     cc_zip                    string                      </span><br><span class="line">,     cc_country                string                   </span><br><span class="line">,     cc_gmt_offset             double                  </span><br><span class="line">,     cc_tax_percentage         double</span><br><span class="line">,PRIMARY KEY(cc_call_center_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH PARTITIONS 2</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists catalog_page;</span><br><span class="line"></span><br><span class="line">create table catalog_page(</span><br><span class="line">      cp_catalog_page_sk        bigint               </span><br><span class="line">,     cp_catalog_page_id        string              </span><br><span class="line">,     cp_start_date_sk          bigint                       </span><br><span class="line">,     cp_end_date_sk            bigint                       </span><br><span class="line">,     cp_department             string                   </span><br><span class="line">,     cp_catalog_number         int                       </span><br><span class="line">,     cp_catalog_page_number    int                       </span><br><span class="line">,     cp_description            string                  </span><br><span class="line">,     cp_type                   string</span><br><span class="line">,PRIMARY KEY(cp_catalog_page_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH PARTITIONS 2</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists catalog_returns;</span><br><span class="line"></span><br><span class="line">create table catalog_returns</span><br><span class="line">(</span><br><span class="line">    cr_item_sk                bigint,</span><br><span class="line">cr_order_number           bigint,</span><br><span class="line">    cr_returned_date_sk       bigint,</span><br><span class="line">    cr_returned_time_sk       bigint,</span><br><span class="line">    cr_refunded_customer_sk   bigint,</span><br><span class="line">    cr_refunded_cdemo_sk      bigint,</span><br><span class="line">    cr_refunded_hdemo_sk      bigint,</span><br><span class="line">    cr_refunded_addr_sk       bigint,</span><br><span class="line">    cr_returning_customer_sk  bigint,</span><br><span class="line">    cr_returning_cdemo_sk     bigint,</span><br><span class="line">    cr_returning_hdemo_sk     bigint,</span><br><span class="line">    cr_returning_addr_sk      bigint,</span><br><span class="line">    cr_call_center_sk         bigint,</span><br><span class="line">    cr_catalog_page_sk        bigint,</span><br><span class="line">    cr_ship_mode_sk           bigint,</span><br><span class="line">    cr_warehouse_sk           bigint,</span><br><span class="line">    cr_reason_sk              bigint,</span><br><span class="line">    cr_return_quantity        int,</span><br><span class="line">    cr_return_amount          double,</span><br><span class="line">    cr_return_tax             double,</span><br><span class="line">    cr_return_amt_inc_tax     double,</span><br><span class="line">    cr_fee                    double,</span><br><span class="line">    cr_return_ship_cost       double,</span><br><span class="line">    cr_refunded_cash          double,</span><br><span class="line">    cr_reversed_charge        double,</span><br><span class="line">    cr_store_credit           double,</span><br><span class="line">    cr_net_loss               double</span><br><span class="line">,PRIMARY KEY(cr_item_sk,cr_order_number)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (cr_item_sk) PARTITIONS 16</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists catalog_sales;</span><br><span class="line"></span><br><span class="line">create table catalog_sales</span><br><span class="line">(</span><br><span class="line">    cs_item_sk                bigint,</span><br><span class="line">    cs_order_number           bigint,</span><br><span class="line">    cs_sold_date_sk           bigint,</span><br><span class="line">    cs_sold_time_sk           bigint,</span><br><span class="line">    cs_ship_date_sk           bigint,</span><br><span class="line">    cs_bill_customer_sk       bigint,</span><br><span class="line">    cs_bill_cdemo_sk          bigint,</span><br><span class="line">    cs_bill_hdemo_sk          bigint,</span><br><span class="line">    cs_bill_addr_sk           bigint,</span><br><span class="line">    cs_ship_customer_sk       bigint,</span><br><span class="line">    cs_ship_cdemo_sk          bigint,</span><br><span class="line">    cs_ship_hdemo_sk          bigint,</span><br><span class="line">    cs_ship_addr_sk           bigint,</span><br><span class="line">    cs_call_center_sk         bigint,</span><br><span class="line">    cs_catalog_page_sk        bigint,</span><br><span class="line">    cs_ship_mode_sk           bigint,</span><br><span class="line">    cs_warehouse_sk           bigint,</span><br><span class="line">    cs_promo_sk               bigint,</span><br><span class="line">    cs_quantity               int,</span><br><span class="line">    cs_wholesale_cost         double,</span><br><span class="line">    cs_list_price             double,</span><br><span class="line">    cs_sales_price            double,</span><br><span class="line">    cs_ext_discount_amt       double,</span><br><span class="line">    cs_ext_sales_price        double,</span><br><span class="line">    cs_ext_wholesale_cost     double,</span><br><span class="line">    cs_ext_list_price         double,</span><br><span class="line">    cs_ext_tax                double,</span><br><span class="line">    cs_coupon_amt             double,</span><br><span class="line">    cs_ext_ship_cost          double,</span><br><span class="line">    cs_net_paid               double,</span><br><span class="line">    cs_net_paid_inc_tax       double,</span><br><span class="line">    cs_net_paid_inc_ship      double,</span><br><span class="line">    cs_net_paid_inc_ship_tax  double,</span><br><span class="line">    cs_net_profit             double</span><br><span class="line">,PRIMARY KEY(cs_item_sk,cs_order_number)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (cs_item_sk) PARTITIONS 64</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists customer_address;</span><br><span class="line"></span><br><span class="line">create table customer_address</span><br><span class="line">(</span><br><span class="line">    ca_address_sk             bigint,</span><br><span class="line">    ca_address_id             string,</span><br><span class="line">    ca_street_number          string,</span><br><span class="line">    ca_street_name            string,</span><br><span class="line">    ca_street_type            string,</span><br><span class="line">    ca_suite_number           string,</span><br><span class="line">    ca_city                   string,</span><br><span class="line">    ca_county                 string,</span><br><span class="line">    ca_state                  string,</span><br><span class="line">    ca_zip                    string,</span><br><span class="line">    ca_country                string,</span><br><span class="line">    ca_gmt_offset             double,</span><br><span class="line">    ca_location_type          string</span><br><span class="line">,PRIMARY KEY(ca_address_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (ca_address_sk) PARTITIONS 6</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists customer_demographics;</span><br><span class="line"></span><br><span class="line">create table customer_demographics</span><br><span class="line">(</span><br><span class="line">    cd_demo_sk                bigint,</span><br><span class="line">    cd_gender                 string,</span><br><span class="line">    cd_marital_status         string,</span><br><span class="line">    cd_education_status       string,</span><br><span class="line">    cd_purchase_estimate      int,</span><br><span class="line">    cd_credit_rating          string,</span><br><span class="line">    cd_dep_count              int,</span><br><span class="line">    cd_dep_employed_count     int,</span><br><span class="line">    cd_dep_college_count      int </span><br><span class="line">,PRIMARY KEY(cd_demo_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (cd_demo_sk) PARTITIONS 2</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists customer;</span><br><span class="line"></span><br><span class="line">create table customer</span><br><span class="line">(</span><br><span class="line">    c_customer_sk             bigint,</span><br><span class="line">    c_customer_id             string,</span><br><span class="line">    c_current_cdemo_sk        bigint,</span><br><span class="line">    c_current_hdemo_sk        bigint,</span><br><span class="line">    c_current_addr_sk         bigint,</span><br><span class="line">    c_first_shipto_date_sk    bigint,</span><br><span class="line">    c_first_sales_date_sk     bigint,</span><br><span class="line">    c_salutation              string,</span><br><span class="line">    c_first_name              string,</span><br><span class="line">    c_last_name               string,</span><br><span class="line">    c_preferred_cust_flag     string,</span><br><span class="line">    c_birth_day               int,</span><br><span class="line">    c_birth_month             int,</span><br><span class="line">    c_birth_year              int,</span><br><span class="line">    c_birth_country           string,</span><br><span class="line">    c_login                   string,</span><br><span class="line">    c_email_address           string,</span><br><span class="line">    c_last_review_date        string</span><br><span class="line">,PRIMARY KEY(c_customer_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (c_customer_sk) PARTITIONS 8</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists date_dim;</span><br><span class="line"></span><br><span class="line">create table date_dim</span><br><span class="line">(</span><br><span class="line">    d_date_sk                 bigint,</span><br><span class="line">    d_date_id                 string,</span><br><span class="line">    d_date                    string,</span><br><span class="line">    d_month_seq               int,</span><br><span class="line">    d_week_seq                int,</span><br><span class="line">    d_quarter_seq             int,</span><br><span class="line">    d_year                    int,</span><br><span class="line">    d_dow                     int,</span><br><span class="line">    d_moy                     int,</span><br><span class="line">    d_dom                     int,</span><br><span class="line">    d_qoy                     int,</span><br><span class="line">    d_fy_year                 int,</span><br><span class="line">    d_fy_quarter_seq          int,</span><br><span class="line">    d_fy_week_seq             int,</span><br><span class="line">    d_day_name                string,</span><br><span class="line">    d_quarter_name            string,</span><br><span class="line">    d_holiday                 string,</span><br><span class="line">    d_weekend                 string,</span><br><span class="line">    d_following_holiday       string,</span><br><span class="line">    d_first_dom               int,</span><br><span class="line">    d_last_dom                int,</span><br><span class="line">    d_same_day_ly             int,</span><br><span class="line">    d_same_day_lq             int,</span><br><span class="line">    d_current_day             string,</span><br><span class="line">    d_current_week            string,</span><br><span class="line">    d_current_month           string,</span><br><span class="line">    d_current_quarter         string,</span><br><span class="line">    d_current_year            string </span><br><span class="line">,PRIMARY KEY(d_date_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (d_date_sk) PARTITIONS 2</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists household_demographics;</span><br><span class="line"></span><br><span class="line">create table household_demographics</span><br><span class="line">(</span><br><span class="line">    hd_demo_sk                bigint,</span><br><span class="line">    hd_income_band_sk         bigint,</span><br><span class="line">    hd_buy_potential          string,</span><br><span class="line">    hd_dep_count              int,</span><br><span class="line">    hd_vehicle_count          int</span><br><span class="line">,PRIMARY KEY(hd_demo_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (hd_demo_sk) PARTITIONS 2</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists income_band;</span><br><span class="line"></span><br><span class="line">create table income_band(</span><br><span class="line">      ib_income_band_sk         bigint               </span><br><span class="line">,     ib_lower_bound            int                       </span><br><span class="line">,     ib_upper_bound            int</span><br><span class="line">,PRIMARY KEY(ib_income_band_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (ib_income_band_sk) PARTITIONS 2</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists inventory;</span><br><span class="line"></span><br><span class="line">create table inventory</span><br><span class="line">(</span><br><span class="line">    inv_date_skbigint,</span><br><span class="line">    inv_item_skbigint,</span><br><span class="line">    inv_warehouse_skbigint,</span><br><span class="line">    inv_quantity_on_handint</span><br><span class="line">,PRIMARY KEY(inv_date_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (inv_date_sk) PARTITIONS 12</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists item;</span><br><span class="line"></span><br><span class="line">create table item</span><br><span class="line">(</span><br><span class="line">    i_item_sk                 bigint,</span><br><span class="line">    i_item_id                 string,</span><br><span class="line">    i_rec_start_date          string,</span><br><span class="line">    i_rec_end_date            string,</span><br><span class="line">    i_item_desc               string,</span><br><span class="line">    i_current_price           double,</span><br><span class="line">    i_wholesale_cost          double,</span><br><span class="line">    i_brand_id                int,</span><br><span class="line">    i_brand                   string,</span><br><span class="line">    i_class_id                int,</span><br><span class="line">    i_class                   string,</span><br><span class="line">    i_category_id             int,</span><br><span class="line">    i_category                string,</span><br><span class="line">    i_manufact_id             int,</span><br><span class="line">    i_manufact                string,</span><br><span class="line">    i_size                    string,</span><br><span class="line">    i_formulation             string,</span><br><span class="line">    i_color                   string,</span><br><span class="line">    i_units                   string,</span><br><span class="line">    i_container               string,</span><br><span class="line">    i_manager_id              int,</span><br><span class="line">    i_product_name            string</span><br><span class="line">,PRIMARY KEY(i_item_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (i_item_sk) PARTITIONS 4</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists promotion;</span><br><span class="line"></span><br><span class="line">create table promotion</span><br><span class="line">(</span><br><span class="line">    p_promo_sk                bigint,</span><br><span class="line">    p_promo_id                string,</span><br><span class="line">    p_start_date_sk           bigint,</span><br><span class="line">    p_end_date_sk             bigint,</span><br><span class="line">    p_item_sk                 bigint,</span><br><span class="line">    p_cost                    double,</span><br><span class="line">    p_response_target         int,</span><br><span class="line">    p_promo_name              string,</span><br><span class="line">    p_channel_dmail           string,</span><br><span class="line">    p_channel_email           string,</span><br><span class="line">    p_channel_catalog         string,</span><br><span class="line">    p_channel_tv              string,</span><br><span class="line">    p_channel_radio           string,</span><br><span class="line">    p_channel_press           string,</span><br><span class="line">    p_channel_event           string,</span><br><span class="line">    p_channel_demo            string,</span><br><span class="line">    p_channel_details         string,</span><br><span class="line">    p_purpose                 string,</span><br><span class="line">    p_discount_active         string </span><br><span class="line">,PRIMARY KEY(p_promo_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (p_promo_sk) PARTITIONS 2</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists reason;</span><br><span class="line"></span><br><span class="line">create table reason(</span><br><span class="line">      r_reason_sk               bigint               </span><br><span class="line">,     r_reason_id               string              </span><br><span class="line">,     r_reason_desc             string                </span><br><span class="line">,PRIMARY KEY(r_reason_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (r_reason_sk) PARTITIONS 2</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists ship_mode;</span><br><span class="line"></span><br><span class="line">create table ship_mode(</span><br><span class="line">      sm_ship_mode_sk           bigint               </span><br><span class="line">,     sm_ship_mode_id           string              </span><br><span class="line">,     sm_type                   string                      </span><br><span class="line">,     sm_code                   string                      </span><br><span class="line">,     sm_carrier                string                      </span><br><span class="line">,     sm_contract               string                      </span><br><span class="line">,PRIMARY KEY(sm_ship_mode_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (sm_ship_mode_sk) PARTITIONS 2</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists store_returns;</span><br><span class="line"></span><br><span class="line">create table store_returns</span><br><span class="line">(</span><br><span class="line">    sr_item_sk                bigint,</span><br><span class="line">    sr_returned_date_sk       bigint,</span><br><span class="line">    sr_return_time_sk         bigint,</span><br><span class="line">    sr_customer_sk            bigint,</span><br><span class="line">    sr_cdemo_sk               bigint,</span><br><span class="line">    sr_hdemo_sk               bigint,</span><br><span class="line">    sr_addr_sk                bigint,</span><br><span class="line">    sr_store_sk               bigint,</span><br><span class="line">    sr_reason_sk              bigint,</span><br><span class="line">    sr_ticket_number          bigint,</span><br><span class="line">    sr_return_quantity        int,</span><br><span class="line">    sr_return_amt             double,</span><br><span class="line">    sr_return_tax             double,</span><br><span class="line">    sr_return_amt_inc_tax     double,</span><br><span class="line">    sr_fee                    double,</span><br><span class="line">    sr_return_ship_cost       double,</span><br><span class="line">    sr_refunded_cash          double,</span><br><span class="line">    sr_reversed_charge        double,</span><br><span class="line">    sr_store_credit           double,</span><br><span class="line">    sr_net_loss               double,</span><br><span class="line">PRIMARY KEY(sr_item_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH PARTITIONS 32</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists store_sales;</span><br><span class="line"></span><br><span class="line">create table store_sales</span><br><span class="line">(</span><br><span class="line">    ss_item_sk                bigint,</span><br><span class="line">    ss_sold_date_sk           bigint,</span><br><span class="line">    ss_sold_time_sk           bigint,</span><br><span class="line">    ss_customer_sk            bigint,</span><br><span class="line">    ss_cdemo_sk               bigint,</span><br><span class="line">    ss_hdemo_sk               bigint,</span><br><span class="line">    ss_addr_sk                bigint,</span><br><span class="line">    ss_store_sk               bigint,</span><br><span class="line">    ss_promo_sk               bigint,</span><br><span class="line">    ss_ticket_number          bigint,</span><br><span class="line">    ss_quantity               int,</span><br><span class="line">    ss_wholesale_cost         double,</span><br><span class="line">    ss_list_price             double,</span><br><span class="line">    ss_sales_price            double,</span><br><span class="line">    ss_ext_discount_amt       double,</span><br><span class="line">    ss_ext_sales_price        double,</span><br><span class="line">    ss_ext_wholesale_cost     double,</span><br><span class="line">    ss_ext_list_price         double,</span><br><span class="line">    ss_ext_tax                double,</span><br><span class="line">    ss_coupon_amt             double,</span><br><span class="line">    ss_net_paid               double,</span><br><span class="line">    ss_net_paid_inc_tax       double,</span><br><span class="line">    ss_net_profit             double                  </span><br><span class="line">,PRIMARY KEY(ss_item_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (ss_item_sk) PARTITIONS 96</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists store;</span><br><span class="line"></span><br><span class="line">create table store</span><br><span class="line">(</span><br><span class="line">    s_store_sk                bigint,</span><br><span class="line">    s_store_id                string,</span><br><span class="line">    s_rec_start_date          string,</span><br><span class="line">    s_rec_end_date            string,</span><br><span class="line">    s_closed_date_sk          bigint,</span><br><span class="line">    s_store_name              string,</span><br><span class="line">    s_number_employees        int,</span><br><span class="line">    s_floor_space             int,</span><br><span class="line">    s_hours                   string,</span><br><span class="line">    s_manager                 string,</span><br><span class="line">    s_market_id               int,</span><br><span class="line">    s_geography_class         string,</span><br><span class="line">    s_market_desc             string,</span><br><span class="line">    s_market_manager          string,</span><br><span class="line">    s_division_id             int,</span><br><span class="line">    s_division_name           string,</span><br><span class="line">    s_company_id              int,</span><br><span class="line">    s_company_name            string,</span><br><span class="line">    s_street_number           string,</span><br><span class="line">    s_street_name             string,</span><br><span class="line">    s_street_type             string,</span><br><span class="line">    s_suite_number            string,</span><br><span class="line">    s_city                    string,</span><br><span class="line">    s_county                  string,</span><br><span class="line">    s_state                   string,</span><br><span class="line">    s_zip                     string,</span><br><span class="line">    s_country                 string,</span><br><span class="line">    s_gmt_offset              double,</span><br><span class="line">    s_tax_precentage          double                  </span><br><span class="line">,PRIMARY KEY(s_store_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (s_store_sk) PARTITIONS 2</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists time_dim;</span><br><span class="line"></span><br><span class="line">create table time_dim</span><br><span class="line">(</span><br><span class="line">    t_time_sk                 bigint,</span><br><span class="line">    t_time_id                 string,</span><br><span class="line">    t_time                    int,</span><br><span class="line">    t_hour                    int,</span><br><span class="line">    t_minute                  int,</span><br><span class="line">    t_second                  int,</span><br><span class="line">    t_am_pm                   string,</span><br><span class="line">    t_shift                   string,</span><br><span class="line">    t_sub_shift               string,</span><br><span class="line">    t_meal_time               string</span><br><span class="line">,PRIMARY KEY(t_time_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (t_time_sk) PARTITIONS 2</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists warehouse;</span><br><span class="line"></span><br><span class="line">create table warehouse(</span><br><span class="line">      w_warehouse_sk            bigint               </span><br><span class="line">,     w_warehouse_id            string              </span><br><span class="line">,     w_warehouse_name          string                   </span><br><span class="line">,     w_warehouse_sq_ft         int                       </span><br><span class="line">,     w_street_number           string                      </span><br><span class="line">,     w_street_name             string                   </span><br><span class="line">,     w_street_type             string                      </span><br><span class="line">,     w_suite_number            string                      </span><br><span class="line">,     w_city                    string                   </span><br><span class="line">,     w_county                  string                   </span><br><span class="line">,     w_state                   string                       </span><br><span class="line">,     w_zip                     string                      </span><br><span class="line">,     w_country                 string                   </span><br><span class="line">,     w_gmt_offset              double                  </span><br><span class="line">,PRIMARY KEY(w_warehouse_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (w_warehouse_sk) PARTITIONS 2</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists web_page;</span><br><span class="line"></span><br><span class="line">create table web_page(</span><br><span class="line">      wp_web_page_sk            bigint               </span><br><span class="line">,     wp_web_page_id            string              </span><br><span class="line">,     wp_rec_start_date        string                         </span><br><span class="line">,     wp_rec_end_date          string                         </span><br><span class="line">,     wp_creation_date_sk       bigint                       </span><br><span class="line">,     wp_access_date_sk         bigint                       </span><br><span class="line">,     wp_autogen_flag           string                       </span><br><span class="line">,     wp_customer_sk            bigint                       </span><br><span class="line">,     wp_url                    string                  </span><br><span class="line">,     wp_type                   string                      </span><br><span class="line">,     wp_char_count             int                       </span><br><span class="line">,     wp_link_count             int                       </span><br><span class="line">,     wp_image_count            int                       </span><br><span class="line">,     wp_max_ad_count           int</span><br><span class="line">,PRIMARY KEY(wp_web_page_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (wp_web_page_sk) PARTITIONS 2</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists web_returns;</span><br><span class="line"></span><br><span class="line">create table web_returns</span><br><span class="line">(</span><br><span class="line">    wr_item_sk                bigint,</span><br><span class="line">    wr_returned_date_sk       bigint,</span><br><span class="line">    wr_returned_time_sk       bigint,</span><br><span class="line">    wr_refunded_customer_sk   bigint,</span><br><span class="line">    wr_refunded_cdemo_sk      bigint,</span><br><span class="line">    wr_refunded_hdemo_sk      bigint,</span><br><span class="line">    wr_refunded_addr_sk       bigint,</span><br><span class="line">    wr_returning_customer_sk  bigint,</span><br><span class="line">    wr_returning_cdemo_sk     bigint,</span><br><span class="line">    wr_returning_hdemo_sk     bigint,</span><br><span class="line">    wr_returning_addr_sk      bigint,</span><br><span class="line">    wr_web_page_sk            bigint,</span><br><span class="line">    wr_reason_sk              bigint,</span><br><span class="line">    wr_order_number           bigint,</span><br><span class="line">    wr_return_quantity        int,</span><br><span class="line">    wr_return_amt             double,</span><br><span class="line">    wr_return_tax             double,</span><br><span class="line">    wr_return_amt_inc_tax     double,</span><br><span class="line">    wr_fee                    double,</span><br><span class="line">    wr_return_ship_cost       double,</span><br><span class="line">    wr_refunded_cash          double,</span><br><span class="line">    wr_reversed_charge        double,</span><br><span class="line">    wr_account_credit         double,</span><br><span class="line">    wr_net_loss               double</span><br><span class="line">,PRIMARY KEY(wr_item_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (wr_item_sk) PARTITIONS 8</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists web_sales;</span><br><span class="line"></span><br><span class="line">create table web_sales</span><br><span class="line">(</span><br><span class="line">    ws_item_sk                bigint,</span><br><span class="line">    ws_sold_date_sk           bigint,</span><br><span class="line">    ws_sold_time_sk           bigint,</span><br><span class="line">    ws_ship_date_sk           bigint,</span><br><span class="line">    ws_bill_customer_sk       bigint,</span><br><span class="line">    ws_bill_cdemo_sk          bigint,</span><br><span class="line">    ws_bill_hdemo_sk          bigint,</span><br><span class="line">    ws_bill_addr_sk           bigint,</span><br><span class="line">    ws_ship_customer_sk       bigint,</span><br><span class="line">    ws_ship_cdemo_sk          bigint,</span><br><span class="line">    ws_ship_hdemo_sk          bigint,</span><br><span class="line">    ws_ship_addr_sk           bigint,</span><br><span class="line">    ws_web_page_sk            bigint,</span><br><span class="line">    ws_web_site_sk            bigint,</span><br><span class="line">    ws_ship_mode_sk           bigint,</span><br><span class="line">    ws_warehouse_sk           bigint,</span><br><span class="line">    ws_promo_sk               bigint,</span><br><span class="line">    ws_order_number           bigint,</span><br><span class="line">    ws_quantity               int,</span><br><span class="line">    ws_wholesale_cost         double,</span><br><span class="line">    ws_list_price             double,</span><br><span class="line">    ws_sales_price            double,</span><br><span class="line">    ws_ext_discount_amt       double,</span><br><span class="line">    ws_ext_sales_price        double,</span><br><span class="line">    ws_ext_wholesale_cost     double,</span><br><span class="line">    ws_ext_list_price         double,</span><br><span class="line">    ws_ext_tax                double,</span><br><span class="line">    ws_coupon_amt             double,</span><br><span class="line">    ws_ext_ship_cost          double,</span><br><span class="line">    ws_net_paid               double,</span><br><span class="line">    ws_net_paid_inc_tax       double,</span><br><span class="line">    ws_net_paid_inc_ship      double,</span><br><span class="line">    ws_net_paid_inc_ship_tax  double,</span><br><span class="line">    ws_net_profit             double</span><br><span class="line">,PRIMARY KEY(ws_item_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (ws_item_sk) PARTITIONS 64</span><br><span class="line">STORED AS KUDU;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create database if not exists kudu_spark_tpcds_1000;</span><br><span class="line">use kudu_spark_tpcds_1000;</span><br><span class="line"></span><br><span class="line">drop table if exists web_site;</span><br><span class="line"></span><br><span class="line">create table web_site</span><br><span class="line">(</span><br><span class="line">    web_site_sk           bigint,</span><br><span class="line">    web_site_id           string,</span><br><span class="line">    web_rec_start_date    string,</span><br><span class="line">    web_rec_end_date      string,</span><br><span class="line">    web_name              string,</span><br><span class="line">    web_open_date_sk      bigint,</span><br><span class="line">    web_close_date_sk     bigint,</span><br><span class="line">    web_class             string,</span><br><span class="line">    web_manager           string,</span><br><span class="line">    web_mkt_id            int,</span><br><span class="line">    web_mkt_class         string,</span><br><span class="line">    web_mkt_desc          string,</span><br><span class="line">    web_market_manager    string,</span><br><span class="line">    web_company_id        int,</span><br><span class="line">    web_company_name      string,</span><br><span class="line">    web_street_number     string,</span><br><span class="line">    web_street_name       string,</span><br><span class="line">    web_street_type       string,</span><br><span class="line">    web_suite_number      string,</span><br><span class="line">    web_city              string,</span><br><span class="line">    web_county            string,</span><br><span class="line">    web_state             string,</span><br><span class="line">    web_zip               string,</span><br><span class="line">    web_country           string,</span><br><span class="line">    web_gmt_offset        double,</span><br><span class="line">    web_tax_percentage    double</span><br><span class="line">,PRIMARY KEY(web_site_sk)</span><br><span class="line">)</span><br><span class="line">PARTITION BY HASH (web_site_sk) PARTITIONS 2</span><br><span class="line">STORED AS KUDU;</span><br></pre></td></tr></table></figure><p>命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">impala-shell -f impala-shell</span><br></pre></td></tr></table></figure><p>Tips：可能会遇到这样的错误</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ERROR: ImpalaRuntimeException: Error creating Kudu table 'impala::kudu_spark_tpcds_2.catalog_sales'</span><br><span class="line">CAUSED BY: NonRecoverableException: The requested number of tablets is over the maximum permitted at creation time (60). Additional tablets may be added by adding range partitions to the table post-creation.</span><br></pre></td></tr></table></figure><p>原因：</p><p><code>Kudu</code>默认配置最多分区被限制了，需要配置</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3azpwvi62j21c10k9ta6.jpg" alt></p><p>如图栏目里，配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--max_create_tablets_per_ts=30</span><br></pre></td></tr></table></figure><p>生成日志后</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tail q* -n 1 &gt;&gt; kudu_time_2.log</span><br></pre></td></tr></table></figure><p>–</p><p>–</p><p>–</p><p>不知道为什么，<code>impala+kudu</code>对内存的管理存在一些问题，明明物理内存足够使用，却老是会用上交换内存。</p><p>测试性能下降，这里取消交换内存再试一次</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 取消交换内存：</span><br><span class="line">swapoff -a</span><br><span class="line">swapon -a</span><br></pre></td></tr></table></figure><p>parquet表格生成脚本  <code>alltables_parquet.sql</code></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">database</span> <span class="keyword">if</span> <span class="keyword">exists</span> $&#123;<span class="keyword">VAR</span>:DB&#125; <span class="keyword">cascade</span>;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> $&#123;<span class="keyword">VAR</span>:DB&#125;;</span><br><span class="line"><span class="keyword">use</span> $&#123;<span class="keyword">VAR</span>:DB&#125;;</span><br><span class="line"><span class="keyword">set</span> parquet_file_size=<span class="number">512</span>M;</span><br><span class="line"><span class="keyword">set</span> COMPRESSION_CODEC=snappy;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> call_center;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.call_center</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.call_center;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> catalog_page;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.catalog_page</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.catalog_page;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> catalog_returns;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.catalog_returns</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.catalog_returns;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> catalog_sales;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.catalog_sales</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.catalog_sales;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> customer_address;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.customer_address</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.customer_address;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> customer_demographics;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.customer_demographics</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.customer_demographics;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> customer;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.customer</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.customer;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> date_dim;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.date_dim</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.date_dim;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> household_demographics;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.household_demographics</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.household_demographics;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> income_band;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.income_band</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.income_band;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> inventory;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.inventory</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.inventory;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> item;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.item</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.item;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> promotion;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.promotion</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.promotion;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> reason;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.reason</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.reason;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> ship_mode;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.ship_mode</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.ship_mode;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> store_returns;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.store_returns</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.store_returns;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> store_sales;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.store_sales</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.store_sales;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> <span class="keyword">store</span>;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.store</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.store;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> time_dim;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.time_dim</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.time_dim;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> warehouse;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.warehouse</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.warehouse;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> web_page;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.web_page</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.web_page;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> web_returns;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.web_returns</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.web_returns;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> web_sales;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.web_sales</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.web_sales;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> web_site;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.web_site</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> parquet</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.web_site;</span><br></pre></td></tr></table></figure><p>然后用命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">impala-shell -i datanode127 --var=DB=tpcds_parquet_500 --var=HIVE_DB=tpcds_text_500 -f alltables_parquet.sql</span><br></pre></td></tr></table></figure><p>理论上也能这么生成<code>Kudu</code>表，只要用下面的语句。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">database</span> <span class="keyword">if</span> <span class="keyword">exists</span> $&#123;<span class="keyword">VAR</span>:DB&#125; <span class="keyword">cascade</span>;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> $&#123;<span class="keyword">VAR</span>:DB&#125;;</span><br><span class="line"><span class="keyword">use</span> $&#123;<span class="keyword">VAR</span>:DB&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> call_center;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.call_center</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (cc_call_center_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.call_center;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> catalog_page;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.catalog_page</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (cp_catalog_page_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.catalog_page;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> catalog_returns;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.catalog_returns</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (cr_returned_date_sk,cr_returned_time_sk,cr_item_sk,cr_refunded_customer_sk)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">HASH</span>(cr_returned_date_sk,cr_returned_time_sk,cr_item_sk,cr_refunded_customer_sk) <span class="keyword">PARTITIONS</span> <span class="number">5</span></span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.catalog_returns;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> catalog_sales;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.catalog_sales</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (cs_sold_date_sk,cs_sold_time_sk,cs_ship_date_sk,cs_bill_customer_sk)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">HASH</span>(cs_sold_date_sk,cs_sold_time_sk,cs_ship_date_sk,cs_bill_customer_sk) <span class="keyword">PARTITIONS</span> <span class="number">5</span></span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.catalog_sales;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> customer_address;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.customer_address</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (ca_address_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.customer_address;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> customer_demographics;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.customer_demographics</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (cd_demo_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.customer_demographics;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> customer;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.customer</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (c_customer_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.customer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> date_dim;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.date_dim</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (d_date_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.date_dim;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> household_demographics;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.household_demographics</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (hd_demo_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.household_demographics;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> income_band;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.income_band</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (ib_income_band_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.income_band;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> inventory;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.inventory</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (inv_date_sk,inv_item_sk,inv_warehouse_sk)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">HASH</span>(inv_date_sk,inv_item_sk,inv_warehouse_sk) <span class="keyword">PARTITIONS</span> <span class="number">5</span></span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.inventory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> item;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.item</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (i_item_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.item;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> promotion;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.promotion</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (p_promo_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.promotion;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> reason;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.reason</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (r_reason_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.reason;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> ship_mode;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.ship_mode</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (sm_ship_mode_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.ship_mode;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> store_returns;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.store_returns</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (sr_returned_date_sk,sr_return_time_sk,sr_item_sk,sr_customer_sk)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">HASH</span>(sr_returned_date_sk,sr_return_time_sk,sr_item_sk,sr_customer_sk) <span class="keyword">PARTITIONS</span> <span class="number">5</span></span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.store_returns;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> store_sales;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.store_sales</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (ss_sold_date_sk,ss_sold_time_sk,ss_item_sk,ss_customer_sk)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">HASH</span>(ss_sold_date_sk,ss_sold_time_sk,ss_item_sk,ss_customer_sk) <span class="keyword">PARTITIONS</span> <span class="number">5</span></span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.store_sales;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> <span class="keyword">store</span>;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.store</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (s_store_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.store;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> time_dim;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.time_dim</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (t_time_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.time_dim;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> warehouse;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.warehouse</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (w_warehouse_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.warehouse;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> web_page;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.web_page</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (wp_web_page_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.web_page;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> web_returns;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.web_returns</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (wr_returned_date_sk,wr_returned_time_sk,wr_item_sk,wr_refunded_customer_sk)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">HASH</span>(wr_returned_date_sk,wr_returned_time_sk,wr_item_sk,wr_refunded_customer_sk) <span class="keyword">PARTITIONS</span> <span class="number">5</span></span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.web_returns;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> web_sales;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.web_sales</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (ws_sold_date_sk,ws_sold_time_sk,ws_ship_date_sk,ws_item_sk,ws_bill_customer_sk)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">HASH</span>(ws_sold_date_sk,ws_sold_time_sk,ws_ship_date_sk,ws_item_sk,ws_bill_customer_sk) <span class="keyword">PARTITIONS</span> <span class="number">5</span></span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.web_sales;</span><br><span class="line"></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> web_site;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> $&#123;<span class="keyword">VAR</span>:DB&#125;.web_site</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (web_site_sk)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> KUDU</span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> $&#123;<span class="keyword">VAR</span>:HIVE_DB&#125;.web_site;</span><br></pre></td></tr></table></figure><p>但是存在问题就是<code>Kudu</code>的表需要主键，并且主键需要放置在最前面，但是<code>tpcds</code>默认生成的表格无法把主键放在最前面，所以这样创建的表格主主键包含很多个key，所以还是用上面的方法。</p><hr><p><a href="https://blog.csdn.net/weixin_39478115/article/details/78469837" target="_blank" rel="noopener">kudu性能调优</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;为了测试Kudu的性能，学习了一下大公司SRE生成模拟数据的手段&lt;br&gt;本文会贴上各种原帖，本文仅记录生成过程中遇到的困难和介绍文章中的不同&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Apache" scheme="http://yoursite.com/categories/Apache/"/>
    
      <category term="Kudu" scheme="http://yoursite.com/categories/Apache/Kudu/"/>
    
    
      <category term="Analog Data" scheme="http://yoursite.com/tags/Analog-Data/"/>
    
  </entry>
  
  <entry>
    <title>Data Preprocessing | Day 1</title>
    <link href="http://yoursite.com/2020/03/09/day01/"/>
    <id>http://yoursite.com/2020/03/09/day01/</id>
    <published>2020-03-09T10:03:41.351Z</published>
    <updated>2019-05-09T01:43:44.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>针对英语文档阅读使用能力和ML知识点开的一个新坑<br>不定期更新<br>尽量使用英语</p></blockquote><a id="more"></a> <h2 id="Data-Preprocessing-Day-1"><a href="#Data-Preprocessing-Day-1" class="headerlink" title="Data Preprocessing | Day 1"></a>Data Preprocessing | Day 1</h2><h3 id="Step-1-Import-the-required-Libraries"><a href="#Step-1-Import-the-required-Libraries" class="headerlink" title="Step 1: Import the required Libraries"></a>Step 1: Import the required Libraries</h3><p>These Two are essential libraries which we will import every time.</p><p>NumPy: Library which contains Mathematical functions.</p><p>Pandas: Library used to import and manage the data sets.</p><h3 id="Step-2-Importing-the-Data-Set"><a href="#Step-2-Importing-the-Data-Set" class="headerlink" title="Step 2: Importing the Data Set"></a>Step 2: Importing the Data Set</h3><p>Data sets are generally available in .csv format. A CSV file stores tabular data in plain text(纯文本). Each lines of the file is a data record. We use the read_csv method of the pandas library to read a local CSV file as a dataframe. Then we make separate(分离) Matrix and Vector of independent and dependent variables from the dataframe.(然后我们从dataframe中制作自变量和因变量的矩阵和向量)</p><h3 id="Step-3-Handling-the-Missing-Data"><a href="#Step-3-Handling-the-Missing-Data" class="headerlink" title="Step 3: Handling the Missing Data"></a>Step 3: Handling the Missing Data</h3><p>The data we get is rarely homogeneous(同质的).Data can be missing due to various and needs to be handled so that it does not reduce the performance of our machine learning model. We can replace the missing data by the Mean or median of the entire column. We use <code>imputer</code> class of <code>sklearn.preprocessing</code> for this task.</p><h3 id="Step-4-Encoding-Categorical-Data"><a href="#Step-4-Encoding-Categorical-Data" class="headerlink" title="Step 4: Encoding Categorical Data"></a>Step 4: Encoding Categorical Data</h3><p>Categorical data are variables that contain label values(标签值) rather than numeric values(数值).The number of possible values is often limited to a fixed set. Example values such as “Yes” and “No” cannot be used in mathematical equations(数学方程) of the model so we need  to encode these variables into numbers. To achieve this we import <code>LabelEncoder</code> class from <code>Sklearn.preprocessing</code> library.</p><h3 id="Step-5-Splitting-the-dataset-into-test-set-and-training-set"><a href="#Step-5-Splitting-the-dataset-into-test-set-and-training-set" class="headerlink" title="Step 5: Splitting the dataset into test set and training set"></a>Step 5: Splitting the dataset into test set and training set</h3><p>We make two partitions of dataset one for training the model called training set and other for testing the performance of the trained model called test set. The split generally 80/20. We import <code>train_test_split()</code> method of <code>sklearn.crossvalidation</code> library.</p><h3 id="Step-6-Feature-Scaling-特征归一化"><a href="#Step-6-Feature-Scaling-特征归一化" class="headerlink" title="Step 6: Feature Scaling(特征归一化)"></a>Step 6: Feature Scaling(特征归一化)</h3><p>Most of the machine learning algorithms use the Euclidean distance(欧式距离) between two data points in their computations, features highly varying(变化) in magnitudes(大小), units and range(范围) pose(提出) problems. high magnitudes(幅度) features will weigh more in the distance calculations than features with low magnitudes. Done by Feature standardization or Z-score normalization(正常化). <code>StandardScalar</code> of <code>sklearn.preprocessing</code> is imported.</p><h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">dataset = pd.read_csv(<span class="string">"D:\\APP\\DataSet\\100-Days-Of-ML-Code-master\\datasets\\Data.csv"</span>)</span><br><span class="line">X = dataset.iloc[ : , :<span class="number">-1</span>].values</span><br><span class="line">Y = dataset.iloc[ : , <span class="number">3</span>].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line">imputer = Imputer(missing_values = <span class="string">"NaN"</span>, strategy = <span class="string">"mean"</span>, axis = <span class="number">0</span>)</span><br><span class="line">imputer = imputer.fit(X[ : , <span class="number">1</span>:<span class="number">3</span>])</span><br><span class="line">X[ : , <span class="number">1</span>:<span class="number">3</span>] = imputer.transform(X[ : , <span class="number">1</span>:<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder, OneHotEncoder</span><br><span class="line">labelencoder_X = LabelEncoder()</span><br><span class="line">X[ : , <span class="number">0</span>] = labelencoder_X.fit_transform(X[ : , <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">onehotencoder = OneHotEncoder(categorical_features = [<span class="number">0</span>])</span><br><span class="line">X = onehotencoder.fit_transform(X).toarray()</span><br><span class="line">labelencoder_Y = LabelEncoder()</span><br><span class="line">Y =  labelencoder_Y.fit_transform(Y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, Y_train, Y_test = train_test_split( X , Y , test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">sc_X = StandardScaler()</span><br><span class="line">X_train = sc_X.fit_transform(X_train)</span><br><span class="line">X_test = sc_X.transform(X_test)</span><br></pre></td></tr></table></figure><h4 id="分析："><a href="#分析：" class="headerlink" title="分析："></a>分析：</h4><p>代码详解</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><p>首先我们使用一个简单的数据集。每一个数据集都会包括两部分，独立变量（independent variable）和依赖变量（dependent variable)。机器学习的目的就是需要通过独立变量来预测非独立变量（prediction）。<br>独立变量不会被影响而非独立变量可能被独立变量影响。</p><p>在以下数据集中Age和Salary就是独立变量，我们需要通过这两个独立变量预测是否会Purchase。所以Purchased就是非独立变量。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g2s67p6d2tj209706iq2w.jpg" alt></p><p>把np作为<code>numpy</code>的缩写，后面可以直接使用np来调用各种方法。</p><p>==&gt;</p><p><code>numpy</code>系统是<code>python</code>的一种开源的数值计算扩展。<br>这种工具可用来存储和处理大型矩阵，比<code>python</code>自身的嵌套列表结构要高效的多。<br>你可以理解为凡是和矩阵有关的都用<code>numpy</code>这个库。</p><p>==&gt;</p><p><code>pandas</code>该工具是为了解决数据分析任务而创建的。<code>pandas</code> 纳入了大量库和一些标准的数据模型，提供了高效地操作大型数据集所需的工具。<br><code>pandas</code>提供了大量能使我们快速便捷地处理数据的函数和方法。它是使<code>python</code>成为强大而高效的数据分析环境的重要因素之一.</p><p>==&gt;</p><p>pandas导入语法：</p><ul><li>导入路径斜线问题</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">file_path1 = <span class="string">'D:/0Raw_data/ftm_p.csv'</span></span><br><span class="line">file_path2 = <span class="string">'D:\\0Raw_data\\ftm_p.csv'</span></span><br><span class="line">file_path3 = <span class="string">r'D:\0Raw_data\ftm_p.csv'</span></span><br></pre></td></tr></table></figure><ul><li>中文路径问题</li></ul><p>当错误类型如下，则一般是中文路径问题。</p><p>OSError: Initializing from file failed</p><p>不废话，解决方案就是先用open打开，而且一般用open先打开，能直接解决编码问题：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">file_path = <span class="string">'D:/0Raw_data/zhaoyang_charge_sta/京AW7531'</span></span><br><span class="line">path = open(file_path)</span><br><span class="line">data = pd.read_csv(path)</span><br></pre></td></tr></table></figure><ul><li>编码问题</li></ul><p>报错：UnicodeDecodeError: ‘utf-8’ codec can’t decode byte 0xb9 in position 0: invalid start byte</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">file_path = <span class="string">'D:/0Raw_data/zhaoyang_charge_sta/京AW7531'</span></span><br><span class="line">f = open(file_path,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">data = pd.read_csv(f)</span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure><p>解决方案2：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">file_path = <span class="string">'D:/0Raw_data/zhaoyang_charge_sta/京AW7531'</span></span><br><span class="line">data = pd.read_csv(<span class="string">'D:/0Raw_data/ftm_p.csv'</span>,encoding=<span class="string">'gbk'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create 独立变量vector</span></span><br><span class="line">X = dataset.iloc[:, :<span class="number">-1</span>].values  <span class="comment"># 第一个冒号是所有列（row），第二个是所有行（column）除了最后一个(Purchased)</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create 依赖变量vector</span></span><br><span class="line">Y = dataset.iloc[:, <span class="number">3</span> ].values <span class="comment"># 只取最后一个column作为依赖变量。</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 处理丢失数据</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line">imputer = Imputer(missing_values = <span class="string">'NaN'</span>, strategy = <span class="string">'mean'</span>, axis = <span class="number">0</span>)</span><br><span class="line">imputer = imputer.fit(X[:, <span class="number">1</span>:<span class="number">3</span>])   <span class="comment"># (inclusive column 1, exclusive column 3, means col 1 &amp; 2 逗号之前代表 所有行 ：,后面代表 [1,3)列])</span></span><br><span class="line">X[:, <span class="number">1</span>:<span class="number">3</span>] = imputer.transform(X[:, <span class="number">1</span>:<span class="number">3</span>]) <span class="comment"># 将imputer 应用到数据</span></span><br></pre></td></tr></table></figure><h4 id="sklearn-preprocessing-Imputer解析"><a href="#sklearn-preprocessing-Imputer解析" class="headerlink" title="sklearn.preprocessing.Imputer解析:"></a>sklearn.preprocessing.Imputer解析:</h4><p>sklearn.preprocessing.Imputer(missing_values=’NaN’, strategy=’mean’, axis=0, verbose=0, copy=True)</p><p>missing_values：缺失值，可以为整数或NaN(缺失值numpy.nan用字符串‘NaN’表示)，默认为NaN</p><p>strategy：替换策略，字符串，默认用均值‘mean’替换</p><p>①若为mean时，用特征列的均值替换</p><p>②若为median时，用特征列的中位数替换</p><p>③若为most_frequent时，用特征列的众数替换</p><p>axis：指定轴数，默认axis=0代表列，axis=1代表行</p><p>copy：设置为True代表不在原数据集上修改，设置为False时，就地修改，存在如下情况时，即使设置为False时，也不会就地修改</p><p>①X不是浮点值数组</p><p>②X是稀疏且missing_values=0</p><p>③axis=0且X为CRS矩阵</p><p>④axis=1且X为CSC矩阵</p><p>statistics_属性：axis设置为0时，每个特征的填充值数组，axis=1时，报没有该属性错误</p><p>处理之前：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">array([[&apos;France&apos;, 44.0, 72000.0],</span><br><span class="line">       [&apos;Spain&apos;, 27.0, 48000.0],</span><br><span class="line">       [&apos;Germany&apos;, 30.0, 54000.0],</span><br><span class="line">       [&apos;Spain&apos;, 38.0, 61000.0],</span><br><span class="line">       [&apos;Germany&apos;, 40.0, nan],</span><br><span class="line">       [&apos;France&apos;, 35.0, 58000.0],</span><br><span class="line">       [&apos;Spain&apos;, nan, 52000.0],</span><br><span class="line">       [&apos;France&apos;, 48.0, 79000.0],</span><br><span class="line">       [&apos;Germany&apos;, 50.0, 83000.0],</span><br><span class="line">       [&apos;France&apos;, 37.0, 67000.0]], dtype=object)</span><br></pre></td></tr></table></figure><p>处理之后</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">array([[&apos;France&apos;, 44.0, 72000.0],</span><br><span class="line">       [&apos;Spain&apos;, 27.0, 48000.0],</span><br><span class="line">       [&apos;Germany&apos;, 30.0, 54000.0],</span><br><span class="line">       [&apos;Spain&apos;, 38.0, 61000.0],</span><br><span class="line">       [&apos;Germany&apos;, 40.0, 63777.77777777778],</span><br><span class="line">       [&apos;France&apos;, 35.0, 58000.0],</span><br><span class="line">       [&apos;Spain&apos;, 38.77777777777778, 52000.0],</span><br><span class="line">       [&apos;France&apos;, 48.0, 79000.0],</span><br><span class="line">       [&apos;Germany&apos;, 50.0, 83000.0],</span><br><span class="line">       [&apos;France&apos;, 37.0, 67000.0]], dtype=object)</span><br></pre></td></tr></table></figure><h4 id="Sklearn数据预处理中fit-和transform-与fit-transform-的区别"><a href="#Sklearn数据预处理中fit-和transform-与fit-transform-的区别" class="headerlink" title="Sklearn数据预处理中fit()和transform()与fit_transform()的区别"></a>Sklearn数据预处理中fit()和transform()与fit_transform()的区别</h4><ul><li>fit():Method calculates the parameters μ and σ and saves them as internal objects.</li></ul><p>Imputer定义了规则，imputer指定训练范围，进行fit ，这里提到的模型都是非常简单的，无非平均数、方差这种。</p><ul><li>transform():Method using these calculated parameters apply the transformation to a particular dataset.</li></ul><p>transform，我理解是这样的，fit和transform的区别有点类似训练模型和训练数据，transform类似于训练数据这一块的</p><ul><li>fit_transform():joins the fit() and transform() method for transformation of dataset.</li></ul><p>将训练模型和训练数据放到一起的一个步骤。</p><p>Note</p><p>必须先用fit_transform(trainData)，之后再transform(testData)<br>如果直接transform(testData)，程序会报错<br>如果fit_transfrom(trainData)后，使用fit_transform(testData)而不transform(testData)，虽然也能归一化，但是两个结果不是在同一个“标准”下的，具有明显差异。(一定要避免这种情况)</p><p>==&gt;</p><h4 id="什么是独热编码？"><a href="#什么是独热编码？" class="headerlink" title="什么是独热编码？"></a>什么是独热编码？</h4><p> 独热码，在英文文献中称做 one-hot code, 直观来说就是有多少个状态就有多少比特，而且只有一个比特为1，其他全为0的一种码制。举例如下：</p><p>直观来说就是有多少个状态就有多少比特，而且只有一个比特为1，其他全为0的一种码制。举例如下：</p><p>假如有三种颜色特征：红、黄、蓝。在利用机器学习的算法时一般需要进行向量化或者数字化。那么你可能想令 红=1，黄=2，蓝=3。那么这样其实实现了标签编码，即给不同类别以标签。然而这意味着机器可能会学习到“红&lt;黄&lt;蓝”，但这并不是我们的让机器学习的本意，只是想让机器区分它们，并无大小比较之意。</p><p>所以这时标签编码是不够的，需要进一步转换。因为有三种颜色状态，所以就有3个比特。即红色：1 0 0 ，黄色: 0 1 0，蓝色：0 0 1 。</p><p>如此一来每两个向量之间的距离都是根号2，在向量空间距离都相等，所以这样不会出现偏序性，基本不会影响基于向量空间度量算法的效果。</p><h4 id="OneHotEncoder-和-LabelEncoder-独热编码和标签编码"><a href="#OneHotEncoder-和-LabelEncoder-独热编码和标签编码" class="headerlink" title="OneHotEncoder 和 LabelEncoder 独热编码和标签编码"></a>OneHotEncoder 和 LabelEncoder 独热编码和标签编码</h4><p>首先了解机器学习中的特征类别：<strong>连续型特征</strong>和<strong>离散型特征</strong></p><p>拿到获取的原始特征，必须对每一特征分别进行归一化，比如，特征A的取值范围是[-1000,1000]，特征B的取值范围是[-1,1]，如果使用logistic回归，w1<em>x1+w2</em>x2，因为x1取值太大了，所以x2基本起不了作用。所以，必须进行特征的归一化，每个特征都单独进行归一化。</p><p> 对于连续性特征：</p><ul><li><strong>Rescale bounded continuous features</strong>: All continuous input that are bounded, rescale them to [-1, 1] through x = (2x - max - min)/(max - min).    线性放缩到[-1,1]</li><li><strong>Standardize all continuous features</strong>: All continuous input should be standardized and by this I mean, for every continuous feature, compute its mean (u) and standard deviation (s) and do x = (x - u)/s.       放缩到均值为0，方差为1</li></ul><p>对于离散性特征：</p><ul><li><strong>Binarize categorical/discrete features</strong>: 对于离散的特征基本就是按照<strong>one-hot（独热）</strong>编码，该离散特征有多少取值，就用多少维来表示该特征。</li></ul><hr><p>1、方差是各个数据分别与其平均数之差的平方的和的平均数，用字母D表示。在概率论和数理统计中，方差（Variance）用来度量随机变量和其数学期望（即均值）之间的偏离程度。在许多实际问题中，研究随机变量和均值之间的偏离程度有着重要意义。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g2tw7h5xxuj208a00z0rz.jpg" alt></p><p>2、平方差公式（difference of two squares）是数学公式的一种，它属于乘法公式、因式分解及恒等式，被普遍使用。平方差指一个平方数或正方形，减去另一个平方数或正方形得来的乘法公式：a²-b²=(a+b)(a-b)</p><p>3、标准差（Standard Deviation） ，中文环境中又常称均方差，但不同于均方误差（mean squared error，均方误差是各数据偏离真实值的距离平方的平均数，也即误差平方和的平均数，计算公式形式上接近方差，它的开方叫均方根误差，均方根误差才和标准差形式上接近），标准差是离均差平方和平均后的方根，用σ表示。假设有一组数值X1,X2,X3,……XN（皆为实数），其平均值（算术平均值）为μ，公式如图。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g2tw8bxdo1j204601o3y9.jpg" alt></p><p>概率论还是要慢慢补。。。</p><hr><p>Reference：</p><p><a href="https://blog.csdn.net/appleyuchi/article/details/73503282" target="_blank" rel="noopener">https://blog.csdn.net/appleyuchi/article/details/73503282</a></p><p><a href="https://scikit-learn.org/stable/_downloads/scikit-learn-docs.pdf" target="_blank" rel="noopener">scikit-learn user guide</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;针对英语文档阅读使用能力和ML知识点开的一个新坑&lt;br&gt;不定期更新&lt;br&gt;尽量使用英语&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Mechine Learning" scheme="http://yoursite.com/categories/Mechine-Learning/"/>
    
      <category term="100 Days Of ML Code" scheme="http://yoursite.com/categories/Mechine-Learning/100-Days-Of-ML-Code/"/>
    
    
      <category term="sklearn" scheme="http://yoursite.com/tags/sklearn/"/>
    
      <category term="OneHotEncoder" scheme="http://yoursite.com/tags/OneHotEncoder/"/>
    
      <category term="LabelEncoder" scheme="http://yoursite.com/tags/LabelEncoder/"/>
    
  </entry>
  
  <entry>
    <title>Simple Linear Regression | Day 2</title>
    <link href="http://yoursite.com/2020/03/09/day02/"/>
    <id>http://yoursite.com/2020/03/09/day02/</id>
    <published>2020-03-09T10:03:41.335Z</published>
    <updated>2019-05-23T09:42:46.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>这边还是直接贴上原图吧，手打实在是比较累，而且我按图打字的时候容易分心，很容易变成机械运动，不如直接上图。</p></blockquote><a id="more"></a> <p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g39v8hb3uzj20m81jk4qp.jpg" alt></p><h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">dataset = pd.read_csv(<span class="string">'F:\\dataset\\100-Days-Of-ML-Code-master\\datasets\\studentscores.csv'</span>)</span><br><span class="line">X = dataset.iloc[ : ,   : <span class="number">1</span> ].values</span><br><span class="line">Y = dataset.iloc[ : , <span class="number">1</span> ].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = <span class="number">1</span>/<span class="number">4</span>, random_state = <span class="number">0</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">regressor = LinearRegression()</span><br><span class="line">regressor = regressor.fit(X_train, Y_train)</span><br><span class="line"></span><br><span class="line">Y_pred = regressor.predict(X_test)</span><br><span class="line"></span><br><span class="line">plt.scatter(X_train , Y_train, color = <span class="string">'red'</span>)</span><br><span class="line">plt.plot(X_train , regressor.predict(X_train), color =<span class="string">'blue'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3bbvz6ns6j20ac070mx2.jpg" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(X_test , Y_test, color = <span class="string">'red'</span>)</span><br><span class="line">plt.plot(X_test , regressor.predict(X_test), color =<span class="string">'blue'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3bbwiv3v2j20ac070q2u.jpg" alt></p><h4 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h4><p>第二天的内容比较简单，没有需要特别结实的内容</p><p>值得注意的是，最后两个测试结果可视化和训练结果可视化内容里面的向量其实是一样的，<code>Y_pred = regressor.predict(X_test)</code>这一步其实类似于保存结果，但是后面不知道为什么没有直接使用起来，有点奇怪。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;这边还是直接贴上原图吧，手打实在是比较累，而且我按图打字的时候容易分心，很容易变成机械运动，不如直接上图。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Mechine Learning" scheme="http://yoursite.com/categories/Mechine-Learning/"/>
    
      <category term="100 Days Of ML Code" scheme="http://yoursite.com/categories/Mechine-Learning/100-Days-Of-ML-Code/"/>
    
    
      <category term="Linear Regression" scheme="http://yoursite.com/tags/Linear-Regression/"/>
    
  </entry>
  
  <entry>
    <title>Multiple Linear Regression | Day 3</title>
    <link href="http://yoursite.com/2020/03/09/day03/"/>
    <id>http://yoursite.com/2020/03/09/day03/</id>
    <published>2020-03-09T10:03:40.983Z</published>
    <updated>2019-05-23T23:57:08.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>多元线性回归</p></blockquote><a id="more"></a> <p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3beehr6fqj20m81jke81.jpg" alt></p><h3 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h3><h4 id="Assumptions"><a href="#Assumptions" class="headerlink" title="Assumptions"></a>Assumptions</h4><p>For a successful regression analysis. It’s essential to validate these assumptions.</p><ol><li><p>Linearity: The relationship between dependent and independent variables should be Linear.</p></li><li><p>Homoscedasticity 方差齐性: (constant variance 恒定方差) of the errors should be maintained.  方差：离散程度的度量</p></li><li>Multivarivate Normality(多元正态性):  Multiple regression assumes that the residuals are normally distributed.</li><li>Lack of Multicollinearity(没有多重共线性，由于存在精确相关关系或者高度相关关系而使模型估计失真或难以估计准确): It is assumed that there is little or no multicollinearity in the data. Multicollinearity occurs when the features (or independent variables) are not independent of each other.</li></ol><h4 id="Dummy-Variables-虚变量、哑变量"><a href="#Dummy-Variables-虚变量、哑变量" class="headerlink" title="Dummy Variables(虚变量、哑变量)"></a>Dummy Variables(虚变量、哑变量)</h4><p>Using categorical data in Multiple Regression Models is a powerful method to include non-numeric data types into a regression model.</p><p>Categorical data refers to data values which represent categories - data values with a fixed and unordered number of values. for instance, gender(male/female). In a regression model, these values can be represented bu dummy variables - variables containing values such as 1 or 0 representing the presence or absence of the categorical.</p><h4 id="NOTE"><a href="#NOTE" class="headerlink" title="NOTE"></a>NOTE</h4><p>having too many variables could potentially cause our model to become less accurate. especially if certain variables have no effect on the outcome or have a significant effect on other variables. There are various methods to select the appropriate various methods to select the appropriate variable like -</p><ol><li>Forward Selection</li><li>Backward Elimination</li><li>Bi-directional Comparision</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;多元线性回归&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Mechine Learning" scheme="http://yoursite.com/categories/Mechine-Learning/"/>
    
      <category term="100 Days Of ML Code" scheme="http://yoursite.com/categories/Mechine-Learning/100-Days-Of-ML-Code/"/>
    
    
      <category term="Linear Regression" scheme="http://yoursite.com/tags/Linear-Regression/"/>
    
  </entry>
  
  <entry>
    <title>Grokking Algorithms</title>
    <link href="http://yoursite.com/2020/03/09/Grokking%20Algorithms/"/>
    <id>http://yoursite.com/2020/03/09/Grokking Algorithms/</id>
    <published>2020-03-09T10:03:40.785Z</published>
    <updated>2020-04-10T17:08:33.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>对算法的了解一直很肤浅（听学数学的朋友说算法在数学中也叫数论？），本书阅读不求快，本就是入门读物，希望能尽量理解，争取早日拿下。</p><p>这边值得一提的是作者推荐了一个网站，可汗学院，<code>khanacademy.org</code>  mark一下。</p><p>看完40%来总结一下，非常好，文盲也能看懂的算法入门。</p><p>这本书看完应该会扫一眼结城浩的《图解密码学》</p></blockquote><a id="more"></a> <h2 id="第一章-算法简介"><a href="#第一章-算法简介" class="headerlink" title="第一章 算法简介"></a>第一章 算法简介</h2><h3 id="1-1-引言"><a href="#1-1-引言" class="headerlink" title="1.1 引言"></a>1.1 引言</h3><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g2w8rt2sg9j20fk026mxh.jpg" alt></p><p>好的，我具备了</p><h3 id="1-2-二分查找"><a href="#1-2-二分查找" class="headerlink" title="1.2 二分查找"></a>1.2 二分查找</h3><p>二分查找(binary search)又叫折半搜索(half-interval search)、对数搜索(logarithmic search)，是一种在<strong>有序数组</strong>中查找某一特定元素的搜索算法。搜索过程从数组的中间元素开始，如果中间元素正好是要查找的元素，则搜索过程结束；如果某一特定元素大于或者小于中间元素，则在数组大于或小于中间元素的那一半中查找，而且跟开始一样从中间元素开始比较。如果在某一步骤数组为空，则代表找不到。这种搜索算法每一次比较都使搜索范围缩小一半。</p><p>对数：幂运算的逆运算</p><p>假设你要在字典中查找一个单词，而该字典包含240000个单词，<br>你认为每种查找最多需要多少步？</p><p>log<sub>2</sub> n步，本题中就是18步</p><p>给定一个有序数组和一个需要定位的数字，先创建两个变量 low 和 high，low和high一开始分别是数组的第一个和最后一个坐标，划定一个取中间元素的空间，然后取出中间元素和目标元素比较，如果不是的话，就更改low或者high中某一个的坐标为(low + high)/2，将查找空间缩小为原来的二分之一，然后继续。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_search</span><span class="params">(list, item)</span>:</span></span><br><span class="line">  low = <span class="number">0</span></span><br><span class="line">  high = len(list) - <span class="number">1</span></span><br><span class="line">  </span><br><span class="line">  <span class="keyword">while</span> low &lt;= high:</span><br><span class="line">    mid = (low + high) // <span class="number">2</span></span><br><span class="line">    guess = list[mid]</span><br><span class="line">    <span class="keyword">if</span> guess == item:</span><br><span class="line">      <span class="keyword">return</span> mid</span><br><span class="line">    <span class="keyword">if</span> guess &gt; item:</span><br><span class="line">      high = mid <span class="number">-1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      low = mid + <span class="number">1</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">my_list = [<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> binary_search(my_list, <span class="number">3</span>)</span><br><span class="line"><span class="keyword">print</span> binary_search(my_list, <span class="number">-1</span>)</span><br></pre></td></tr></table></figure><p><a href="https://colab.research.google.com/notebook#create=true&amp;language=python3" target="_blank" rel="noopener">运行环境</a></p><p>Tips：关于为什么更换搜索区域的时候没有直接用high = mid 或者low = mid</p><p>注意while的条件，如果没有这一条，范围缩小到两个数的时候，会无限循环</p><h4 id="运行时间"><a href="#运行时间" class="headerlink" title="运行时间"></a>运行时间</h4><p>最多猜测次数与列表长度相同被称为线性时间(linear time).</p><p>二分查找的运行时间为对数时间(log time).</p><h3 id="1-3-大-O-表示法"><a href="#1-3-大-O-表示法" class="headerlink" title="1.3 大 O 表示法"></a>1.3 大 O 表示法</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">O(1):             常量时间，哈希</span><br><span class="line">O(log2(n)):       对数时间，二分，</span><br><span class="line">O(n):             线性时间，简单</span><br><span class="line">O(nlog2(n)):              快速排序</span><br><span class="line">O(n2):                    选择排序（冒泡）</span><br><span class="line">O(n!):                    旅行商问题</span><br></pre></td></tr></table></figure><p>算法的速度指的并非时间，而是操作数的增速。</p><p>谈论算法的速度时，我们说的是随着输入的增加，其运行时间将以什么样的速度增加。</p><p>算法的运行时间用大O表示法表示。</p><p>O(log n)比O(n)快，当需要搜索的元素越多时，前者比后者快得越多。</p><h4 id="旅行商问题"><a href="#旅行商问题" class="headerlink" title="旅行商问题"></a>旅行商问题</h4><p>行商问题（最短路径问题）（英语：travelling salesman problem, TSP）是这样一个问题：给定一系列城市和每对城市之间的距离，求解访问每一座城市一次并回到起始城市的最短回路。它是组合优化中的一个NP困难问题，在运筹学和理论计算机科学中非常重要。</p><hr><h2 id="第二章-选择排序"><a href="#第二章-选择排序" class="headerlink" title="第二章 选择排序"></a>第二章 选择排序</h2><h3 id="2-1-内存工作原理"><a href="#2-1-内存工作原理" class="headerlink" title="2.1 内存工作原理"></a>2.1 内存工作原理</h3><h3 id="2-2-数组和链表"><a href="#2-2-数组和链表" class="headerlink" title="2.2 数组和链表"></a>2.2 数组和链表</h3><p><strong>链表</strong>：不需要移动元素，优势在插入元素</p><p>使用链表在中间插入元素只需要修改前面一个元素指向的地址，因此当需要在中间插入的时候，链表是更好的选择。</p><p>删除也是一样</p><p>数组和链表的运行时间：</p><table><thead><tr><th></th><th>数组</th><th>链表</th></tr></thead><tbody><tr><td>读取</td><td>O(1)</td><td>O(n)</td></tr><tr><td>插入</td><td>O(n)</td><td>O(1)</td></tr><tr><td>删除</td><td>O(n)</td><td>O(1)</td></tr></tbody></table><p>有两种访问方式：随机访问和顺序访问。</p><p>顺序访问意味着从第一个元素开始逐个读取元素，链表只能顺序访问，数组支持随机访问，所以数组在需要随机访问的情况下用得很多。</p><h3 id="2-3-选择排序"><a href="#2-3-选择排序" class="headerlink" title="2.3 选择排序"></a>2.3 选择排序</h3><p>时间复杂度的Tips</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g39qnoufddj20oz08a0v8.jpg" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">findSmallest</span><span class="params">(arr)</span>:</span></span><br><span class="line">    smallest = arr[<span class="number">0</span>]</span><br><span class="line">    smallest_index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(arr)):</span><br><span class="line">        <span class="keyword">if</span> arr[i] &lt; smallest:</span><br><span class="line">            smallest = arr[i]</span><br><span class="line">            smallest_index = i</span><br><span class="line">    <span class="keyword">return</span> smallest_index</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selection</span><span class="params">(arr)</span>:</span></span><br><span class="line">    newArr = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(arr)):</span><br><span class="line">        smallest = findSmallest(arr)</span><br><span class="line">        newArr.append(arr.pop(smallest))</span><br><span class="line">    <span class="keyword">return</span> newArr</span><br><span class="line"></span><br><span class="line">print(selection( [<span class="number">5</span>,<span class="number">3</span>,<span class="number">6</span>,<span class="number">2</span>,<span class="number">10</span>] ))</span><br></pre></td></tr></table></figure><p>Tips：</p><p>python之间的语法不兼容是很蛋疼的事情</p><p>py2：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> <span class="string">"Pyhon 2 can use print string without ()"</span>;</span><br></pre></td></tr></table></figure><p>py3:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Python3, print must use () to output string"</span>);</span><br></pre></td></tr></table></figure><p>py3中，print作为函数必须要带括号</p><h2 id="第三章-递归"><a href="#第三章-递归" class="headerlink" title="第三章 递归"></a>第三章 递归</h2><p>递归：优雅的问题解决办法</p><h3 id="3-1-递归"><a href="#3-1-递归" class="headerlink" title="3.1 递归"></a>3.1 递归</h3><p>“如果使用循环，程序的性能可能更高；如果使用递归，程序可能 更容易理解。如何选择要看什么对你来说更重要“</p><h3 id="3-2-基线条件和递归条件"><a href="#3-2-基线条件和递归条件" class="headerlink" title="3.2 基线条件和递归条件"></a>3.2 基线条件和递归条件</h3><p>递归条件(base case)是指函数调用自己，基线条件(recursive case)是指函数不再调用自己，从而表面形成无限循环。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">countdown</span><span class="params">(i)</span>:</span></span><br><span class="line">    print(i)</span><br><span class="line">    <span class="keyword">if</span> i &lt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        countdown(i<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">countdown(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><h3 id="3-3-栈"><a href="#3-3-栈" class="headerlink" title="3.3 栈"></a>3.3 栈</h3><p>调用栈（call stack）</p><p>python虽然不是用的JVM 但是 对于栈内存的调用 好像都差不多</p><p>递归函数factorial(5)写作5!</p><p>意义是5! = 5 <em> 4 </em> 3 <em> 2 </em> 1</p><p>使用栈虽然很方便但是也要付出代价：占用大量内存</p><h2 id="第四章-快速排序"><a href="#第四章-快速排序" class="headerlink" title="第四章 快速排序"></a>第四章 快速排序</h2><h3 id="4-1-分而治之"><a href="#4-1-分而治之" class="headerlink" title="4.1 分而治之"></a>4.1 分而治之</h3><p>一种著名的递归式问题解决方法—divide and conquer,D&amp;C</p><p>重要的D&amp;C是算法：快排，优雅代码的典范</p><p>欧几里得算法(辗转相除法)：gcd(a.b) = gcd(b, a%b)</p><table><thead><tr><th>大的那个数</th><th>小的那个数</th><th>余数</th><th>商</th></tr></thead><tbody><tr><td>a</td><td>b</td><td>r0 = a%b</td><td>q0</td></tr><tr><td>b</td><td>r0</td><td>r1 = b% r0</td><td>q1</td></tr><tr><td>r0</td><td>r1</td><td>r2 = r0 % r1</td><td>q2</td></tr><tr><td>…</td><td>…</td><td>…</td><td>…</td></tr><tr><td>rN-4</td><td>rN-3</td><td>rN-2 = rN-4 % rN-3</td><td>qN-2</td></tr><tr><td>rN-3</td><td>rN-2</td><td>rN-1 = rN-3 % rN-2</td><td>qN-1</td></tr><tr><td>rN-2</td><td>rN-1</td><td>rN = rN-2 % rN-1</td><td>qN</td></tr><tr><td>rN-1</td><td>rN == 0</td><td>rN-1 = 1 <em> rN-1 - 0 </em> rN</td><td>0</td></tr></tbody></table><p>得到的最大公约数就是rN-1</p><p>欧几里得算法的证明：</p><p>我个人觉得反证法比较好理解：</p><p> 要证欧几里德算法成立，即证: gcd(a,b)=gcd(b,r),其中 gcd是取最大公约数的意思，r=a mod b<br>    下面证 gcd（a，b）=gcd（b，r）<br>    设  c是a，b的最大公约数，即c=gcd（a，b），则有 a=mc，b=nc，其中m，n为正整数，且m，n互为质数<br>    由 r= a mod b可知，r= a- qb 其中，q是正整数，<br>    则 r=a-qb=mc-qnc=（m-qn）c<br>    b=nc,r=(m-qn)c，且n，（m-qn）互质（假设n，m-qn不互质，则n=xd, m-qn=yd 其中x,y,d都是正整数，且d&gt;1</p><p>​    则a=mc=(qx+y)dc, b=xdc,这时a,b 的最大公约数变成dc，与前提矛盾，所以n ，m-qn一定互质）<br>​    则gcd（b,r）=c=gcd（a,b）<br>​    得证。</p><p>编写涉及数组的递归函数时，基线条件通常是数组为空或只包含一个元素。陷入困境时， 请检查基线条件是不是这样的。 </p><h3 id="4-2-快排"><a href="#4-2-快排" class="headerlink" title="4.2 快排"></a>4.2 快排</h3><p>快排使用了D&amp;C</p><p>思路：</p><p>基线条件：数组为空或者只包含一个元素。这种情况下，只需要原样返回。</p><p>对于两个元素的数组：如果第一个元素比第二个元素小，直接返回，如果不是，就交换位置。</p><p>三个元素的数组：</p><p>从数组中选择一个元素，这个元素被称为基准值(pivot)，</p><p>我们暂时先将数组的第一个元素作为基准值。</p><p>接下来找出比基准值小的元素以及比他大的元素。这个过程被称为分区（partition）</p><p>这里两个分区出来的数组时无需的，但是如果这两个数组是有序的，对整个数组进行排序将非常容易。</p><p>那么问题就转化成了如何对子数组进行排序，</p><p>这里我们讨论的是特定情况（三个元素），无论选用哪个元素作为pivot，剩下的情况总能用上面两个元素数组的排序方法代入。</p><p>于是就得到了解决办法</p><p>接下来四个元素的情况，类似的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quicksort</span><span class="params">(array)</span>:</span></span><br><span class="line">    <span class="comment"># 基线条件</span></span><br><span class="line">    <span class="keyword">if</span> len(array) &lt; <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> array</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 递归条件</span></span><br><span class="line">        pivot = array[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 分为两个数组</span></span><br><span class="line">        less = [ i <span class="keyword">for</span> i <span class="keyword">in</span> array[<span class="number">1</span>:] <span class="keyword">if</span> i &lt;= pivot]</span><br><span class="line">        greater = [i <span class="keyword">for</span> i <span class="keyword">in</span> array[<span class="number">1</span>:] <span class="keyword">if</span> i &gt; pivot]</span><br><span class="line">        <span class="keyword">return</span> quicksort(less) + [pivot] + quicksort(greater)</span><br><span class="line"></span><br><span class="line">print(quicksort([<span class="number">1</span>,<span class="number">6</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">45645</span>,<span class="number">34</span>,<span class="number">23</span>,<span class="number">65</span>,<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><p>这边可以对比一下时间复杂度</p><p>选择排序的时间复杂度是O(n<sup>2</sup>)</p><p>快速排序的时间复杂度最差是O(n<sup>2</sup>)，平均情况是O(n log n)</p><p>还有一种合并排序(merge sort)运行时间是O(n log n)</p><p>现在做出一个有趣的假设，假设简单查找每次需要10ms，二分查找的常量是1s，现在我们假设查找的元素个数是10个，简单查找需要100ms，二分查找却需要log 10 * 1s，可以二分查找的时间远大于简单查找，但是我们查找的元素很大时，比如40亿，这个时候我们使用简单查找需要463天，但是二分查找只要32s。</p><p>通过这个例子，我们可以看到常量的影响可能会很大。</p><p>我们再来看快排，快排的效率取决于选择的pivot，当pivot是最小值的时候，我们其实只用到的一个数组，要递归很多次才能递归结束，这种情况是最坏的情况</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3c25jnmi2j20jx0ga0v4.jpg" alt></p><p>如果我们选择的是中间值，是最佳情况，这种情况下根本不要这么多递归，因此调用栈就短得多。</p><p>需要注意的是，我们并不是如图这么简单的+n次调用，作为递归二次每次调用栈都设计O(n)，这是递归的性质决定的。</p><p>因此，实际上最佳情况是O(n log n)</p><p>最佳情况也是平均情况（和最佳情况在同一数量级所以忽略掉前面的参数，剩下的相同），快排是D&amp;G的典范。</p><h2 id="第五章-散列表-Hash-Table"><a href="#第五章-散列表-Hash-Table" class="headerlink" title="第五章 散列表 Hash Table"></a>第五章 散列表 Hash Table</h2><blockquote><p>散列表是足有用的基本数据结构之一。</p></blockquote><p>虽然二分法的效率已经可以了，但是能不能有一种查找方法的查找时间是O(1)呢——任意给出一个查找内容，都能立即给出答案。</p><h3 id="5-1-散列函数"><a href="#5-1-散列函数" class="headerlink" title="5.1 散列函数"></a>5.1 散列函数</h3><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g3eicbpqf2j20ar07y3z4.jpg" alt></p><p>散列函数应该满足的要求：</p><ul><li>他必须是一致的。例如：假设你输入apple时得到的是4，那么每次输入apple的时候，得到的都必须是4，如果不是这样，散列表将毫无用处。</li><li>它应该将不同的输入映射到不同的数字，如果一个散列函数不管输入是什么都返回1就不可以。最理想的情况是，将不同的输入映射到不同的数字。</li></ul><p>原理：</p><ul><li>散列函数总是将同样的输入映射到相同的索引。</li><li>不同输入映射到不同的索引。</li><li>散列函数知道数组有多大。</li></ul><p>散列表是一种包含额外逻辑的数据结构。</p><p>散列表又被称为散列映射、映射、字典和关联数组。（Hash Table）</p><p>python提供的散列表实现为字典，可以使用<code>dictt</code>来创建散列表。</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g3ej8m95ydj20hm09omx2.jpg" alt></p><p>python语法中</p><p><code>book = dict()</code>和<code>book = {}</code>等价。</p><h3 id="5-2-应用案例"><a href="#5-2-应用案例" class="headerlink" title="5.2 应用案例"></a>5.2 应用案例</h3><p>电话簿</p><p>DNS解析（域名关联IP）DNS resolution</p><p>防止重复（比如抽奖、投票）</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2ly1g3ejoaiscwj20gr0743yd.jpg" alt></p><p>将案列表用作缓存</p><p>Facebook将主页、about页面，Contact页面、Terms 和 Conditions页面等众多页面通过页面URL映射到页面数据。</p><h3 id="5-3-冲突-collision"><a href="#5-3-冲突-collision" class="headerlink" title="5.3 冲突 collision"></a>5.3 冲突 collision</h3><p>大多数语言都提供了散列实现，冲突是指，两个键分配的数组位置相同，这是个问题。</p><p>解决办法：如果两个键映射到了同一个位置，就在这个位置存储一个链表。 </p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3fi55lqjgj20l606i74w.jpg" alt></p><p>但是，如果A开头的物品过多，散列表的效率将激素下降，然而：如果散列函数用的很好，这些列表就不会很长。</p><h3 id="5-4-性能"><a href="#5-4-性能" class="headerlink" title="5.4 性能"></a>5.4 性能</h3><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3fi9iv10gj20d0071my4.jpg" alt></p><p>平均情况下，散列表的查找速度和数组一样快，而插入和删除速度与链表一样快，因此它兼具两者的优点！但是最糟的情况下，散列表的各种操作都很慢。</p><p>因此，为了避免冲突，需要有：</p><p>较低的填装因子。</p><p>良好的散列函数。</p><p>装填因子：</p><p>散列表包含的元素数目/位置总数</p><p>假设再散列表中存储100种商品的价格，散列表包含100个位置名最佳情况下，每个商品都将有自己的位置。</p><p>装填因子在大于1的情况下，需要在散列表中添加位置，这个操作被称为<strong>调整长度(resizing)</strong>。</p><p>一般操作是：<strong>数组增加一倍</strong>。</p><p>接下来，将所有元素用hash函数插入到新的散列表中。</p><p>平均而言，即便考虑到调整长度所需的时间，散列表操作所需的 时间也为O(1)。 </p><p>良好的散列函数让数组中的值呈均匀分布。 </p><p>糟糕的散列函数让值扎堆，导致大量的冲突。 </p><h2 id="第六章-广度优先搜索"><a href="#第六章-广度优先搜索" class="headerlink" title="第六章 广度优先搜索"></a>第六章 广度优先搜索</h2><blockquote><p>图算法之<em>广度优先搜索</em> (breadth-first search)</p></blockquote><h3 id="6-1-图简介"><a href="#6-1-图简介" class="headerlink" title="6.1 图简介"></a>6.1 图简介</h3><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3finx3k1jj20jb07yq40.jpg" alt></p><p>如图用来解决从A点到B点最短路径问题的办法叫图计算方法。</p><p>这种最短路径既可能是最短路径，也有可能是国际象棋中将对方将死的最少步数。</p><p>解决最短路径问题的算法被称为<strong>广度优先搜索</strong>。</p><h3 id="6-2-图是什么"><a href="#6-2-图是什么" class="headerlink" title="6.2 图是什么"></a>6.2 图是什么</h3><p>图用于模拟不同的东西是如何相连的。</p><h3 id="6-3-广度优先搜索"><a href="#6-3-广度优先搜索" class="headerlink" title="6.3 广度优先搜索"></a>6.3 广度优先搜索</h3><p>书中的例计较简单，在朋友圈中找A，先遍历朋友，查找是否有A，有的话结束，没有的话，依次遍历朋友的朋友。（和之前找芒果经销商是一样的）</p><p>能够实现这种目的的数据结构叫做<strong>队列（queue）</strong></p><p>队列的工作原理：你不能随机访问队列中的元素。队列只支持两种操作：入队和出队。</p><p>队列是一种<strong>先进先出（First In First Out，FIFO）</strong>的数据结构，而栈是一种<strong>后进先出（Last In First Out，LIFO）</strong>的数据结构。 </p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3fj0qapdpj20cd04ddg7.jpg" alt></p><h3 id="6-4-实现图"><a href="#6-4-实现图" class="headerlink" title="6.4 实现图"></a>6.4 实现图</h3><p>python实现一个简单的图：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3fj7iusshj20f70azab9.jpg" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">graph = &#123;&#125; </span><br><span class="line">graph[<span class="string">"you"</span>] = [<span class="string">"alice"</span>, <span class="string">"bob"</span>, <span class="string">"claire"</span>] </span><br><span class="line">graph[<span class="string">"bob"</span>] = [<span class="string">"anuj"</span>, <span class="string">"peggy"</span>] </span><br><span class="line">graph[<span class="string">"alice"</span>] = [<span class="string">"peggy"</span>] </span><br><span class="line">graph[<span class="string">"claire"</span>] = [<span class="string">"thom"</span>, <span class="string">"jonny"</span>] </span><br><span class="line">graph[<span class="string">"anuj"</span>] = [] </span><br><span class="line">graph[<span class="string">"peggy"</span>] = [] </span><br><span class="line">graph[<span class="string">"thom"</span>] = [] </span><br><span class="line">graph[<span class="string">"jonny"</span>] = []</span><br></pre></td></tr></table></figure><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3fj9dzn13j20mt04pwf5.jpg" alt></p><p>上图中的有向图和无向图是等价的。</p><h3 id="6-5-实现算法"><a href="#6-5-实现算法" class="headerlink" title="6.5 实现算法"></a>6.5 实现算法</h3><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3fjb7w4rwj20jv0ls77b.jpg" alt></p><p>在Python中，可以使用函数deque来创建一个双端队列</p><p>这边需要考虑一个情况：就是朋友是朋友的朋友，循环调用会造成无限循环。</p><p>所以需要添加容错判断。用一个列表来记录检查过的人。</p><p>图的特殊情况：指针只往一个方向，比如说：族谱。</p><h2 id="第七章-狄克斯特拉算法-Dijkstra’s-Algorithm"><a href="#第七章-狄克斯特拉算法-Dijkstra’s-Algorithm" class="headerlink" title="第七章 狄克斯特拉算法 Dijkstra’s Algorithm"></a>第七章 狄克斯特拉算法 Dijkstra’s Algorithm</h2><h3 id="7-1-狄克斯特拉算法介绍"><a href="#7-1-狄克斯特拉算法介绍" class="headerlink" title="7.1 狄克斯特拉算法介绍"></a>7.1 狄克斯特拉算法介绍</h3><p>依旧图的讨论。</p><p>如果之前的路径有了权重（节点到节点之间花费的时间不等价），重新计算最短路径，就应该使用狄克斯特拉算法。</p><p>狄克斯特拉算法包含四个步骤：</p><ul><li>找出最便宜的节点，即可在最短时间内前往的节点。</li><li>对于该节点的邻居，检查是否有前往他们的最短路径，如果有，就更新其开销。</li><li>重复这个过程，知道对图中的每个节点都这样做了。</li><li>计算最终路径。</li></ul><h3 id="7-3-术语"><a href="#7-3-术语" class="headerlink" title="7.3 术语"></a>7.3 术语</h3><p>每条边关联的数字叫做权重（weight）。</p><p>带权重的图称为加权图（weighted graph），不带权重的图称为非加权图（unweighted graph）。</p><p>要计算非加权图中的最短路径，可以使用<strong>广度优先搜索</strong>。</p><p>如果是为了计算加权图中的最短路径，可以使用<strong>迪克斯特拉算法</strong>。</p><p>图还可能有环，这意味着你可以从一个节点出发，走一圈后又回到这个节点</p><p>在无向图中，每条边都是一个环，狄克斯特拉算法只使用于有向无环图（DAG）</p><h3 id="7-4-负权边"><a href="#7-4-负权边" class="headerlink" title="7.4 负权边"></a>7.4 负权边</h3><p>如果有负权边就不能用，就不能使用狄克斯特拉算法，因为负权边，就不能使用狄克斯特拉算法。</p><p>因为负权边会导致这种算法不管用。</p><p>因为：根据狄克斯特拉算法，没有比不支付任何费用获得海报更便宜的方式。</p><p>因此：不能将狄克斯特拉算法用于包含负权边的图。</p><p>要在包含负权边的图中，找出最短路径，可以使用另一种算法： 贝尔曼—福德算法（Bellman-Ford algorithm）.</p><h3 id="7-5-实现"><a href="#7-5-实现" class="headerlink" title="7.5 实现"></a>7.5 实现</h3><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3gntz3sx0j20aa06fq38.jpg" alt></p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3gobfcl77j20fz0i4wek.jpg" alt></p><p>可以用以上代码表示上图的散列表。</p><p>上面代码表达的表：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3goeygswbj20b00a6dgw.jpg" alt></p><p>接下来需要一个散列表来粗春<strong>每个节点的开销</strong>。</p><p>节点的开销：从起点出发前往该节点需要的时间。</p><p>用表表示的话如图：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3gofc9opgj205805zdg6.jpg" alt></p><p>表中的无穷大可以这么表示：</p><p><a href="https://www.cnblogs.com/lvye-song/p/4029691.html" target="_blank" rel="noopener">python正负无穷</a></p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3goiypuf7j20e205z0sk.jpg" alt></p><p>除了上面两张表，还需要一个存储父节点的散列表：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3gox0oz11j209g096wf7.jpg" alt></p><p>创建这个散列表的代码如下：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3gozpliz7j20aj05mjr7.jpg" alt></p><p>最后，需要一个数组用于记录处理过的节点，因为对于同一个节点，你不用处理多次。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">processd = &#123;&#125;</span><br></pre></td></tr></table></figure><p>动图表示整个认证过程：</p><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3hv4x3xeqg207v066jrc.gif" alt></p><p>整体过程：</p><p>本书介绍的python 迪克斯特拉算法：</p><p>使用了三个散列表和一个数组，三个散列表的作用分别是：</p><p>第一个：Graph散列表</p><p>用来记录每个节点到指向节点的权重</p><p>第二个：Costs散列表</p><p>指的起点到某个节点的消耗</p><p>第三个：Parents散列表</p><p>指的是父节点的散列表</p><p>数组的作用是记录用于处理过的节点。</p><p>处理过程是，</p><p>找出一个未处理的节点（规则定位开销最小的）</p><p>然后在表一获得该节点的开销和邻居。</p><p>遍历邻居，</p><p>接着计算从起点到X再到邻居节点的距离，然后在表一中对比这样的开销和原先的开销大小，如果这样效率更高，那么在表二中替换掉（或者更新掉原先的数字），然后在表三中改变其父节点为X</p><p>（表二记载的开销是经过父节点的最短开销）</p><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">node = find_lowest_cost_node(costs)</span><br><span class="line"><span class="keyword">while</span> node <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">cost = costs[node]</span><br><span class="line">neighbors = graph[node]</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> neighbors.keys():</span><br><span class="line">new_cost = cost + neighbors[n]</span><br><span class="line"><span class="keyword">if</span> costs[n] &gt; new_cost:</span><br><span class="line">costs[n] = new_cost</span><br><span class="line">parents[n] = node</span><br><span class="line">processed.append(node)</span><br><span class="line">node = find_lowest_cost_node(costs)</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_lowest_cost_node</span><span class="params">(costs)</span>:</span></span><br><span class="line">    lowest_cost = float(<span class="string">"inf"</span>)</span><br><span class="line">    lowest_cost_node = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> costs:</span><br><span class="line">        cost = costs[node]</span><br><span class="line">        <span class="keyword">if</span> cost &lt; lowest_cost <span class="keyword">and</span> node <span class="keyword">not</span> <span class="keyword">in</span> processed:</span><br><span class="line">        lowest_cost = cost</span><br><span class="line">            lowest_cost_node = node</span><br><span class="line"><span class="keyword">return</span> lowest_cost_node</span><br></pre></td></tr></table></figure><p>书上对这个过程的描述还可以，但是我觉得如果能增加一个循环就更好了。</p><h2 id="第八章-贪婪算法"><a href="#第八章-贪婪算法" class="headerlink" title="第八章 贪婪算法"></a>第八章 贪婪算法</h2><h3 id="8-1-教室调度问题"><a href="#8-1-教室调度问题" class="headerlink" title="8.1 教室调度问题"></a>8.1 教室调度问题</h3><p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1g3iys53c86j20m50b140f.jpg" alt></p><p>解决方法：</p><p>(1) 选出结束最早的课，它就是要在这间教室上的第一堂课。 </p><p>(2) 接下来，必须选择第一堂课结束后才开始的课。同样，你选择结束最早的课，这将是要 在这间教室上的第二堂课。 </p><p>重读这样做就能找出答案。</p><p>即：每步都选择局部最优解，最终得到的就是全局最优解。</p><p>此方法并非万能！但是行之有效，并且<strong>简单</strong>！</p><h3 id="8-2-背包问题"><a href="#8-2-背包问题" class="headerlink" title="8.2 背包问题"></a>8.2 背包问题</h3>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;对算法的了解一直很肤浅（听学数学的朋友说算法在数学中也叫数论？），本书阅读不求快，本就是入门读物，希望能尽量理解，争取早日拿下。&lt;/p&gt;
&lt;p&gt;这边值得一提的是作者推荐了一个网站，可汗学院，&lt;code&gt;khanacademy.org&lt;/code&gt;  mark一下。&lt;/p&gt;
&lt;p&gt;看完40%来总结一下，非常好，文盲也能看懂的算法入门。&lt;/p&gt;
&lt;p&gt;这本书看完应该会扫一眼结城浩的《图解密码学》&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Reading Note" scheme="http://yoursite.com/categories/Reading-Note/"/>
    
      <category term="Grokking Algorithms" scheme="http://yoursite.com/categories/Reading-Note/Grokking-Algorithms/"/>
    
    
      <category term="Reading notes" scheme="http://yoursite.com/tags/Reading-notes/"/>
    
      <category term="Grokking Algorithms" scheme="http://yoursite.com/tags/Grokking-Algorithms/"/>
    
      <category term="Algorithm" scheme="http://yoursite.com/tags/Algorithm/"/>
    
      <category term="欧几里得算法" scheme="http://yoursite.com/tags/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%AE%97%E6%B3%95/"/>
    
      <category term="快排" scheme="http://yoursite.com/tags/%E5%BF%AB%E6%8E%92/"/>
    
  </entry>
  
</feed>

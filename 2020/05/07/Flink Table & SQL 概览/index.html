<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/xingqiushangcheng.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/xingqiushangcheng.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-mac-osx.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Flink Table 和 SQL 整体的脉络">
<meta property="og:type" content="article">
<meta property="og:title" content="Flink Table &amp; SQL">
<meta property="og:url" content="http://yoursite.com/2020/05/07/Flink Table & SQL 概览/index.html">
<meta property="og:site_name" content="Mars">
<meta property="og:description" content="Flink Table 和 SQL 整体的脉络">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/bec9bff2gy1gejppurwd5j20ib046t9h.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/bec9bff2gy1geby8il5f3j20gj08g0sx.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/bec9bff2gy1gebyby4r2yj20ji035jt2.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/bec9bff2gy1gebyly5qi6j20ex05e74v.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/bec9bff2gy1gebyo6k1awj20lr0aljsg.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/bec9bff2gy1gebyrhzrcdj20kf081t9b.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/bec9bff2gy1gebz2a1sjmj20kk089js9.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/bec9bff2gy1gejnzvbpitj20jf0b6jsm.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/bec9bff2gy1gejo6fdbb4j20je09cta0.jpg">
<meta property="og:updated_time" content="2020-05-07T06:38:51.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Flink Table &amp; SQL">
<meta name="twitter:description" content="Flink Table 和 SQL 整体的脉络">
<meta name="twitter:image" content="http://ww1.sinaimg.cn/large/bec9bff2gy1gejppurwd5j20ib046t9h.jpg">

<link rel="canonical" href="http://yoursite.com/2020/05/07/Flink Table & SQL 概览/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Flink Table & SQL | Mars</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Mars" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Mars</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/07/Flink Table & SQL 概览/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Fly Hugh">
      <meta itemprop="description" content="WE CHOOSE TO  GO TO THE MARS">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mars">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Flink Table & SQL
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-05-07 10:43:59 / 修改时间：14:38:51" itemprop="dateCreated datePublished" datetime="2020-05-07T10:43:59+08:00">2020-05-07</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Apache/" itemprop="url" rel="index"><span itemprop="name">Apache</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Apache/Flink/" itemprop="url" rel="index"><span itemprop="name">Flink</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <blockquote>
<p>Flink Table 和 SQL 整体的脉络</p>
</blockquote>
<p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gejppurwd5j20ib046t9h.jpg" alt="3.png"></p>
<a id="more"></a> 

<h1 id="Flink-Table-amp-SQL"><a href="#Flink-Table-amp-SQL" class="headerlink" title="Flink Table &amp; SQL"></a>Flink Table &amp; SQL</h1><h2 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h2><p>依赖没啥好说的，要想一下的是Zeppelin是否需要手动把这些依赖全都加上去</p>
<h2 id="两种Planner的区别"><a href="#两种Planner的区别" class="headerlink" title="两种Planner的区别"></a>两种Planner的区别</h2><ul>
<li>最大区别 流批一体，blink不支持和dataset之间的转换了</li>
<li>取消了BatchTableSource，使用有界的StreamTableSource</li>
<li>Blink只支持全新的catalog，旧的ExternalCatalog不再支持</li>
<li>基于字符串的键值配置选项仅适用于Blink planner</li>
<li>PlannerConfig在两个planner中的实现不同</li>
<li>Blink planner会将多个sink优化在一个DAG中（仅在TableEnvironment上受支持，而在StreamTableEnvironment上不受支持）。而旧planner的优化总是将每一个sink放在一个新的DAG中，其中所有DAG彼此独立</li>
<li>旧的planner不支持目录统计，而Blink planner支持</li>
</ul>
<h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><h3 id="基本程序结构"><a href="#基本程序结构" class="headerlink" title="基本程序结构"></a>基本程序结构</h3><p>Table API 和 SQL 的程序结构，与流式处理的程序结构类似；也可以近似地认为有这么几步：首先创建执行环境，然后定义source、transform和sink</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tableEnv = ...     <span class="comment">// 创建表的执行环境</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一张表，用于读取数据</span></span><br><span class="line">tableEnv.connect(...).createTemporaryTable(<span class="string">"inputTable"</span>)</span><br><span class="line"><span class="comment">// 注册一张表，用于把计算结果输出</span></span><br><span class="line">tableEnv.connect(...).createTemporaryTable(<span class="string">"outputTable"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过 Table API 查询算子，得到一张结果表</span></span><br><span class="line"><span class="keyword">val</span> result = tableEnv.from(<span class="string">"inputTable"</span>).select(...)</span><br><span class="line"><span class="comment">// 通过 SQL查询语句，得到一张结果表</span></span><br><span class="line"><span class="keyword">val</span> sqlResult  = tableEnv.sqlQuery(<span class="string">"SELECT ... FROM inputTable ..."</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将结果表写入输出表中</span></span><br><span class="line">result.insertInto(<span class="string">"outputTable"</span>)</span><br></pre></td></tr></table></figure>

<h3 id="创建表环境"><a href="#创建表环境" class="headerlink" title="创建表环境"></a>创建表环境</h3><p>创建表环境最简单的方式，就是基于流处理执行环境，调create方法直接创建:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">StreamTableEnvironment</span>.create(env)</span><br></pre></td></tr></table></figure>

<p>表环境（TableEnvironment）是flink中集成Table API &amp; SQL的核心概念。它负责:</p>
<ul>
<li>注册catalog</li>
<li>在内部 catalog 中注册表</li>
<li>执行SQL查询</li>
<li>注册用户自定义函数</li>
<li>将DataStream或DataSet转换成表</li>
<li>保存对ExecutionEnvironment或者StreamExecutionEnvironment的引用</li>
</ul>
<p>在创建TableEnv的时候，可以多传入一个EnvironmentSettings 或者 TableConfig 参数，可以用来配置tEnv的一些特性</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> settings = <span class="type">EnvironmentSettings</span>.newInstance()</span><br><span class="line">  .useOldPlanner()      <span class="comment">// 使用老版本planner</span></span><br><span class="line">  .inStreamingMode()    <span class="comment">// 流处理模式</span></span><br><span class="line">  .build()</span><br><span class="line"><span class="keyword">val</span> tableEnv = <span class="type">StreamTableEnvironment</span>.create(env, settings)</span><br></pre></td></tr></table></figure>

<p>基于老版本的批处理环境（Flink-Batch-Query）</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> batchEnv = <span class="type">ExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"><span class="keyword">val</span> batchTableEnv = <span class="type">BatchTableEnvironment</span>.create(batchEnv)</span><br></pre></td></tr></table></figure>

<p>基于blink版本的流处理环境(Blink-Streaming-Query):</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> bsSettings = <span class="type">EnvironmentSettings</span>.newInstance()</span><br><span class="line">.useBlinkPlanner()</span><br><span class="line">.inStreamingMode().build()</span><br><span class="line"><span class="keyword">val</span> bsTableEnv = <span class="type">StreamTableEnvironment</span>.create(env, bsSettings)</span><br></pre></td></tr></table></figure>

<p>基于Blink版本的批处理环境(Blink-Batch-Query)</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> bbSettings = <span class="type">EnvironmentSettings</span>.newInstance()</span><br><span class="line">.useBlinkPlanner()</span><br><span class="line">.inBatchMode().build()</span><br><span class="line"><span class="keyword">val</span> bbTableEnv = <span class="type">TableEnvironment</span>.create(bbSettings)</span><br></pre></td></tr></table></figure>

<h3 id="注册表"><a href="#注册表" class="headerlink" title="注册表"></a>注册表</h3><p>TableEnvironment可以注册目录Catalog，并可以基于Catalog注册表。它会维护一个Catalog-Table表之间的map。</p>
<p>表（Table）是由一个“标识符”来指定的，由3部分组成：Catalog名、数据库（database）名和对象名（表名）。如果没有指定目录或数据库，就使用当前的默认值。</p>
<p>表可以是常规的（Table，表），或者虚拟的（View，视图）。常规表（Table）一般可以用来描述外部数据，比如文件、数据库表或消息队列的数据，也可以直接从 DataStream转换而来。视图可以从现有的表中创建，通常是table API或者SQL查询的一个结果。</p>
<h3 id="连接到文件系统（CSV）"><a href="#连接到文件系统（CSV）" class="headerlink" title="连接到文件系统（CSV）"></a>连接到文件系统（CSV）</h3><p>连接外部系统在Catalog中注册表，直接调用tableEnv.connect()就可以，里面参数要传入一个ConnectorDescriptor，也就是connector描述器。对于文件系统的connector而言，flink内部已经提供了，就叫做FileSystem()。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tableEnv</span><br><span class="line">.connect( <span class="keyword">new</span> <span class="type">FileSystem</span>().path(<span class="string">"sensor.txt"</span>))  <span class="comment">// 定义表数据来源，外部连接</span></span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">OldCsv</span>())    <span class="comment">// 定义从外部系统读取数据之后的格式化方法</span></span><br><span class="line">  .withSchema( <span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">    .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">    .field(<span class="string">"timestamp"</span>, <span class="type">DataTypes</span>.<span class="type">BIGINT</span>())</span><br><span class="line">    .field(<span class="string">"temperature"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">  )    <span class="comment">// 定义表结构</span></span><br><span class="line">  .createTemporaryTable(<span class="string">"inputTable"</span>)    <span class="comment">// 创建临时表</span></span><br></pre></td></tr></table></figure>

<p>这是旧版本的csv格式描述器。由于它是非标的，跟外部系统对接并不通用，所以将被弃用，以后会被一个符合RFC-4180标准的新format描述器取代。新的描述器就叫Csv()，但flink没有直接提供，需要引入依赖flink-csv：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;flink-csv&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.10.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>

<p>代码非常类似，只需要把withFormat里的OldCsv改成Csv就可以了。</p>
<h3 id="连接到Kafka"><a href="#连接到Kafka" class="headerlink" title="连接到Kafka"></a>连接到Kafka</h3><p>kafka的连接器flink-kafka-connector中，1.10版本的已经提供了Table API的支持。我们可以在 connect方法中直接传入一个叫做Kafka的类，这就是kafka连接器的描述器ConnectorDescriptor</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.connect(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Kafka</span>()</span><br><span class="line">    .version(<span class="string">"0.11"</span>) <span class="comment">// 定义kafka的版本</span></span><br><span class="line">    .topic(<span class="string">"sensor"</span>) <span class="comment">// 定义主题</span></span><br><span class="line">    .property(<span class="string">"zookeeper.connect"</span>, <span class="string">"localhost:2181"</span>) </span><br><span class="line">    .property(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>)</span><br><span class="line">)</span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">Csv</span>())</span><br><span class="line">  .withSchema(<span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">  .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">  .field(<span class="string">"timestamp"</span>, <span class="type">DataTypes</span>.<span class="type">BIGINT</span>())</span><br><span class="line">  .field(<span class="string">"temperature"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">)</span><br><span class="line">  .createTemporaryTable(<span class="string">"kafkaInputTable"</span>)</span><br></pre></td></tr></table></figure>

<p>当然也可以连接到ElasticSearch、MySql、HBase、Hive等外部系统，实现方式基本上是类似的。</p>
<h3 id="表的查询"><a href="#表的查询" class="headerlink" title="表的查询"></a>表的查询</h3><p>利用外部系统的连接器connector，我们可以读写数据，并在环境的Catalog中注册表。接下来就可以对表做查询转换了。</p>
<p>Flink给我们提供了两种查询方式：Table API和 SQL。</p>
<h3 id="TableAPI的调用"><a href="#TableAPI的调用" class="headerlink" title="TableAPI的调用"></a>TableAPI的调用</h3><p>Table API是集成在Scala和Java语言内的查询API。与SQL不同，Table API的查询不会用字符串表示，而是在宿主语言中一步一步调用完成的。</p>
<p>Table API基于代表一张“表”的Table类，并提供一整套操作处理的方法API。这些方法会返回一个新的Table对象，这个对象就表示对输入表应用转换操作的结果。有些关系型转换操作，可以由多个方法调用组成，构成链式调用结构。例如table.select(…).filter(…)，其中select（…）表示选择表中指定的字段，filter(…)表示筛选条件。</p>
<p>代码中的实现如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorTable: <span class="type">Table</span> = tableEnv.from(<span class="string">"inputTable"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultTable: <span class="type">Table</span> = senorTable</span><br><span class="line">.select(<span class="string">"id, temperature"</span>)</span><br><span class="line">.filter(<span class="string">"id ='sensor_1'"</span>)</span><br></pre></td></tr></table></figure>

<h3 id="SQL查询"><a href="#SQL查询" class="headerlink" title="SQL查询"></a>SQL查询</h3><p>Flink的SQL集成，基于的是<code>ApacheCalcite</code>，</p>
<p>它实现了SQL标准。</p>
<p>在Flink中，用常规字符串来定义SQL查询语句。</p>
<p>SQL 查询的结果，是一个新的 Table。</p>
<p>代码如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> resultSqlTable: <span class="type">Table</span> = tableEnv.sqlQuery(<span class="string">"select id, temperature from inputTable where id ='sensor_1'"</span>)</span><br></pre></td></tr></table></figure>

<p>或者：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> resultSqlTable: <span class="type">Table</span> = tableEnv.sqlQuery(</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |select id, temperature</span></span><br><span class="line"><span class="string">    |from inputTable</span></span><br><span class="line"><span class="string">    |where id = 'sensor_1'</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin)</span><br></pre></td></tr></table></figure>

<p>当然，也可以加上聚合操作，比如我们统计每个sensor温度数据出现的个数，做个count统计：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val aggResultTable = sensorTable</span><br><span class="line">    .groupBy(&apos;id)</span><br><span class="line">    .select(&apos;id, &apos;id.count as &apos;count)</span><br></pre></td></tr></table></figure>

<p>SQL:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> aggResultSqlTable = tableEnv.sqlQuery(<span class="string">"select id, count(id) as cnt from inputTable group by id"</span>)</span><br></pre></td></tr></table></figure>

<p>这里Table API里指定的字段，前面加了一个单引号’，这是Table API中定义的Expression类型的写法，可以很方便地表示一个表中的字段。</p>
<p>字段可以直接全部用双引号引起来，也可以用半边单引号+字段名的方式。以后的代码中，一般都用后一种形式。</p>
<h3 id="将DataStream转换成表"><a href="#将DataStream转换成表" class="headerlink" title="将DataStream转换成表"></a>将DataStream转换成表</h3><p>Flink允许我们把Table和DataStream做转换：</p>
<p>我们可以基于一个DataStream，</p>
<p>先流式地读取数据源，</p>
<p>然后map成样例类，</p>
<p>再把它转成Table。</p>
<p>Table的列字段（column fields），</p>
<p>就是样例类里的字段，</p>
<p>这样就不用再麻烦地定义schema了。</p>
<p><strong>Code</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">val inputStream: DataStream[String] = env.readTextFile(&quot;sensor.txt&quot;)</span><br><span class="line">val dataStream: DataStream[SensorReading] = inputStream</span><br><span class="line">  .map(data =&gt; &#123;</span><br><span class="line">    val dataArray = data.split(&quot;,&quot;)</span><br><span class="line">    SensorReading(dataArray(0), dataArray(1).toLong, dataArray(2).toDouble)</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">val sensorTable: Table = tableEnv.fromDataStream(dataStream)</span><br><span class="line"></span><br><span class="line">val sensorTable2 = tableEnv.fromDataStream(dataStream, &apos;id, &apos;timestamp as &apos;ts)</span><br></pre></td></tr></table></figure>

<h3 id="数据类型与-Table-schema的对应"><a href="#数据类型与-Table-schema的对应" class="headerlink" title="数据类型与 Table schema的对应"></a>数据类型与 Table schema的对应</h3><p>在上面的例子中，DataStream 中的数据类型，与表的 Schema 之间的对应关系，是按照样例类中的字段名来对应的（name-based mapping），所以还可以用as做重命名。</p>
<p>另外一种对应方式是，直接按照字段的位置来对应（position-based mapping），对应的过程中，就可以直接指定新的字段名了。</p>
<p><strong>基于名称的对应</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorTable = tableEnv.fromDataStream(dataStream, <span class="symbol">'timestamp</span> as <span class="symbol">'ts</span>, <span class="symbol">'id</span> as <span class="symbol">'myId</span>, <span class="symbol">'temperature</span>)</span><br></pre></td></tr></table></figure>

<p><strong>基于位置的对应</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorTable = tableEnv.fromDataStream(dataStream, <span class="symbol">'myId</span>, <span class="symbol">'ts</span>)</span><br></pre></td></tr></table></figure>

<p>Flink的DataStream和DataSet API支持多种类型。</p>
<p>组合类型，比如元组（内置Scala和Java元组）、POJO、Scala case类和Flink的Row类型等，允许具有多个字段的嵌套数据结构，这些字段可以在Table的表达式中访问。其他类型，则被视为原子类型。</p>
<p>元组类型和原子类型，一般用位置对应会好一些；如果非要用名称对应，也是可以的：</p>
<p>元组类型，默认的名称是 “_1”, “_2”；而原子类型，默认名称是 ”f0”。</p>
<h3 id="创建临时视图（Temporary-View）"><a href="#创建临时视图（Temporary-View）" class="headerlink" title="创建临时视图（Temporary View）"></a>创建临时视图（Temporary View）</h3><p>创建临时视图的第一种方式，就是直接从DataStream传唤而来。同样，可以直接对应字段转换；也可以在转换的时候，指定相应的字段。</p>
<p><strong>Code</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.createTemporaryView(<span class="string">"sensorView"</span>, dataStream)</span><br><span class="line">tableEnv.createTemporaryView(<span class="string">"sensorView"</span>, dataStream, <span class="symbol">'id</span>, <span class="symbol">'temperature</span>, <span class="symbol">'timestamp</span> as <span class="symbol">'ts</span>)</span><br></pre></td></tr></table></figure>

<p>另外，当然还可以基于Table创建视图：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.createTemporaryView(<span class="string">"sensorView"</span>, sensorTable)</span><br></pre></td></tr></table></figure>

<p>View和Table的Schema完全相同。事实上，在Table API中，可以认为View和Table是等价的。</p>
<h3 id="输出表"><a href="#输出表" class="headerlink" title="输出表"></a>输出表</h3><p>表的输出，是通过将数据写入 TableSink 来实现的。TableSink 是一个通用接口，可以支持不同的文件格式、存储数据库和消息队列。</p>
<p>具体实现，输出表最直接的方法，就是通过 Table.insertInto() 方法将一个 Table 写入注册过的 TableSink 中。</p>
<p>输出到文件</p>
<p><strong>Code</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 注册输出表</span></span><br><span class="line">tableEnv.connect(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">FileSystem</span>().path(<span class="string">"…\\resources\\out.txt"</span>)</span><br><span class="line">) <span class="comment">// 定义到文件系统的连接</span></span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">Csv</span>()) <span class="comment">// 定义格式化方法，Csv格式</span></span><br><span class="line">  .withSchema(<span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">  .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">  .field(<span class="string">"temp"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">) <span class="comment">// 定义表结构</span></span><br><span class="line">  .createTemporaryTable(<span class="string">"outputTable"</span>) <span class="comment">// 创建临时表</span></span><br><span class="line"></span><br><span class="line">resultSqlTable.insertInto(<span class="string">"outputTable"</span>)</span><br></pre></td></tr></table></figure>

<h3 id="更新模式"><a href="#更新模式" class="headerlink" title="更新模式"></a>更新模式</h3><p>在流处理过程中，表的处理并不像传统定义的那样简单。</p>
<p>对于流式查询（Streaming Queries），需要声明如何在（动态）表和外部连接器之间执行转换。与外部系统交换的消息类型，由<strong>更新模式</strong>（update mode）指定。</p>
<p>Flink Table API中的更新模式有以下三种：</p>
<p><strong>1) 追加模式 Append Mode</strong></p>
<p>在追加模式下，表（动态表）和外部连接器只插入（Insert）消息。</p>
<p><strong>2)撤回模式 Retract Mode</strong></p>
<p>撤回模式下，表和外部连接器交换的是：添加ADD 和撤回Retract 消息。</p>
<p>插入（Insert）会被编码为添加消息。</p>
<p>删除（Delete）则编码为撤回消息。</p>
<p>更新（Update）则会编码为。已更新行（上一行）的撤回消息，和更新行（新行）的添加消息。</p>
<p>从模式下，不能定义key，这一点跟upsert模式完全不同。</p>
<p><strong>3)更新插入模式 Upsert</strong></p>
<p>在Upsert模式下，动态表和外部连接器交换Upsert和Delete消息。</p>
<p>这个模式需要一个唯一的key，通过这个key可以传递更新消息。为了正确应用消息，外部连接器需要知道这个唯一key的属性。</p>
<ul>
<li><p>插入（Insert）和更新（Update）都被编码为Upsert消息；</p>
</li>
<li><p>删除（Delete）编码为Delete信息。</p>
</li>
</ul>
<p>这种模式和Retract模式的主要区别在于，Update操作是用单个消息编码的，所以效率会更高。</p>
<h3 id="输出到Kafka"><a href="#输出到Kafka" class="headerlink" title="输出到Kafka"></a>输出到Kafka</h3><p>除了输出到文件，也可以输出到Kafka。我们可以结合前面Kafka作为输入数据，构建数据管道，kafka进，kafka出</p>
<p><strong>Code</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.connect(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Kafka</span>()</span><br><span class="line">    .version(<span class="string">"0.11"</span>)</span><br><span class="line">    .topic(<span class="string">"sinkTest"</span>)</span><br><span class="line">    .property(<span class="string">"zookeeper.connect"</span>, <span class="string">"localhost:2181"</span>)</span><br><span class="line">    .property(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>)</span><br><span class="line">)</span><br><span class="line">  .withFormat( <span class="keyword">new</span> <span class="type">Csv</span>() )</span><br><span class="line">  .withSchema( <span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">    .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">    .field(<span class="string">"temp"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">  )</span><br><span class="line">  .createTemporaryTable(<span class="string">"kafkaOutputTable"</span>)</span><br><span class="line"></span><br><span class="line">resultTable.insertInto(<span class="string">"kafkaOutputTable"</span>)</span><br></pre></td></tr></table></figure>

<h3 id="输出到ES"><a href="#输出到ES" class="headerlink" title="输出到ES"></a>输出到ES</h3><p>ElasticSearch的connector可以在upsert（update+insert，更新插入）模式下操作，这样就可以使用Query定义的键（key）与外部系统交换UPSERT/DELETE消息。</p>
<p>另外，对于“仅追加”（append-only）的查询，connector还可以在append 模式下操作，这样就可以与外部系统只交换insert消息。</p>
<p>es目前支持的数据格式，只有Json，而flink本身并没有对应的支持，所以还需要引入依赖：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;flink-json&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.10.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>

<p><strong>Code</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 输出到es</span></span><br><span class="line">tableEnv.connect(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Elasticsearch</span>()</span><br><span class="line">    .version(<span class="string">"6"</span>)</span><br><span class="line">    .host(<span class="string">"localhost"</span>, <span class="number">9200</span>, <span class="string">"http"</span>)</span><br><span class="line">    .index(<span class="string">"sensor"</span>)</span><br><span class="line">    .documentType(<span class="string">"temp"</span>)</span><br><span class="line">)</span><br><span class="line">  .inUpsertMode()           <span class="comment">// 指定是 Upsert 模式</span></span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">Json</span>())</span><br><span class="line">  .withSchema( <span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">    .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">    .field(<span class="string">"count"</span>, <span class="type">DataTypes</span>.<span class="type">BIGINT</span>())</span><br><span class="line">  )</span><br><span class="line">  .createTemporaryTable(<span class="string">"esOutputTable"</span>)</span><br><span class="line"></span><br><span class="line">aggResultTable.insertInto(<span class="string">"esOutputTable"</span>)</span><br></pre></td></tr></table></figure>

<h3 id="输出到MySQL"><a href="#输出到MySQL" class="headerlink" title="输出到MySQL"></a>输出到MySQL</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;flink-jdbc_2<span class="number">.11</span>&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;<span class="number">1.10</span><span class="number">.0</span>&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>

<p>jdbc连接的代码实现比较特殊，因为没有对应的java/scala类实现ConnectorDescriptor，所以不能直接tableEnv.connect()。不过Flink SQL留下了执行DDL的接口：tableEnv.sqlUpdate()。</p>
<p>对于jdbc的创建表操作，天生就适合直接写DDL来实现，所以我们的代码可以这样写：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 输出到 Mysql</span></span><br><span class="line"><span class="keyword">val</span> sinkDDL: <span class="type">String</span> =</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |create table jdbcOutputTable (</span></span><br><span class="line"><span class="string">    |  id varchar(20) not null,</span></span><br><span class="line"><span class="string">    |  cnt bigint not null</span></span><br><span class="line"><span class="string">    |) with (</span></span><br><span class="line"><span class="string">    |  'connector.type' = 'jdbc',</span></span><br><span class="line"><span class="string">    |  'connector.url' = 'jdbc:mysql://localhost:3306/test',</span></span><br><span class="line"><span class="string">    |  'connector.table' = 'sensor_count',</span></span><br><span class="line"><span class="string">    |  'connector.driver' = 'com.mysql.jdbc.Driver',</span></span><br><span class="line"><span class="string">    |  'connector.username' = 'root',</span></span><br><span class="line"><span class="string">    |  'connector.password' = '123456'</span></span><br><span class="line"><span class="string">    |)</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin</span><br><span class="line"></span><br><span class="line">tableEnv.sqlUpdate(sinkDDL)</span><br><span class="line">aggResultSqlTable.insertInto(<span class="string">"jdbcOutputTable"</span>)</span><br></pre></td></tr></table></figure>

<h3 id="Table转换为DataStream"><a href="#Table转换为DataStream" class="headerlink" title="Table转换为DataStream"></a>Table转换为DataStream</h3><p>表可以转换为DataStream或DataSet。这样，自定义流处理或批处理程序就可以继续在 Table API或SQL查询的结果上运行了。</p>
<p>将表转换为DataStream或DataSet时，需要指定生成的数据类型，即要将表的每一行转换成的数据类型。通常，最方便的转换类型就是Row。当然，因为结果的所有字段类型都是明确的，我们也经常会用元组类型来表示。</p>
<p>表作为流式查询的结果，是动态更新的。</p>
<p>所以，将这种动态查询转换成的数据流，同样需要对表的更新操作进行编码，</p>
<p>进而有不同的转换模式。</p>
<p>Table API中表到DataStream有两种模式</p>
<ul>
<li>追加 Append Mode</li>
</ul>
<p>用于表只会被插入（Insert）操作更改的场景。</p>
<ul>
<li>撤回 RetractMode</li>
</ul>
<p>得到的数据会增加一个Boolean类型的标识位（返回的第一个字段），用它来表示到底是新增的数据（Insert），还是被删除的数据（老数据， Delete）。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> resultStream: <span class="type">DataStream</span>[<span class="type">Row</span>] = tableEnv.toAppendStream[<span class="type">Row</span>](resultTable)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> aggResultStream: <span class="type">DataStream</span>[(<span class="type">Boolean</span>, (<span class="type">String</span>, <span class="type">Long</span>))] = </span><br><span class="line">tableEnv.toRetractStream[(<span class="type">String</span>, <span class="type">Long</span>)](aggResultTable)</span><br><span class="line"></span><br><span class="line">resultStream.print(<span class="string">"result"</span>)</span><br><span class="line">aggResultStream.print(<span class="string">"aggResult"</span>)</span><br></pre></td></tr></table></figure>

<p>所以，没有经过groupby之类聚合操作，可以直接用 toAppendStream 来转换；而如果经过了聚合，有更新操作，一般就必须用 toRetractDstream。</p>
<h3 id="Query的解释和执行"><a href="#Query的解释和执行" class="headerlink" title="Query的解释和执行"></a>Query的解释和执行</h3><p>Table API提供了一种机制来解释（Explain）计算表的逻辑和优化查询计划。这是通过TableEnvironment.explain（table）方法或TableEnvironment.explain（）方法完成的</p>
<p>explain方法会返回一个字符串，描述三个计划：</p>
<ul>
<li><p>未优化的逻辑查询计划</p>
</li>
<li><p>优化后的逻辑查询计划</p>
</li>
<li><p>实际执行计划</p>
</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> explaination: <span class="type">String</span> = tableEnv.explain(resultTable)</span><br><span class="line">println(explaination)</span><br></pre></td></tr></table></figure>

<p>Query的解释和执行过程，老planner和blink planner大体是一致的，又有所不同。整体来讲，Query都会表示成一个逻辑查询计划，然后分两步解释：</p>
<p>1.优化查询计划</p>
<p>2.解释成DataStream或者DataSet程序</p>
<p>而Blink版本是批流统一的，所以所有的Query，只会被解释成DataStream程序；另外在批处理环境TableEnvironment下，Blink版本要到tableEnv.execute()执行调用才开始解释。</p>
<h2 id="流处理中的特殊概念"><a href="#流处理中的特殊概念" class="headerlink" title="流处理中的特殊概念"></a>流处理中的特殊概念</h2><p>Table API和SQL，本质上还是基于关系型表的操作方式；而关系型表、关系代数，以及SQL本身，一般是有界的，更适合批处理的场景。这就导致在进行流处理的过程中，理解会稍微复杂一些，需要引入一些特殊概念。</p>
<p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1geby8il5f3j20gj08g0sx.jpg" alt="1.png"></p>
<p>可以看到，其实关系代数（主要就是指关系型数据库中的表）和SQL，主要就是针对批处理的，这和流处理有天生的隔阂。</p>
<h3 id="Dynamic-Tables"><a href="#Dynamic-Tables" class="headerlink" title="Dynamic Tables"></a>Dynamic Tables</h3><p>因为流处理面对的数据，是连续不断的，这和我们熟悉的关系型数据库中保存的“表”完全不同。所以，如果我们把流数据转换成Table，然后执行类似于table的select操作，结果就不是一成不变的，而是随着新数据的到来，会不停更新。</p>
<p>我们可以随着新数据的到来，不停地在之前的基础上更新结果。这样得到的表，在Flink Table API概念里，就叫做“<strong>动态表</strong>”（Dynamic Tables）。</p>
<p>动态表是Flink对流数据的Table API和SQL支持的核心概念。与表示批处理数据的静态表不同，动态表是随时间变化的。动态表可以像静态的批处理表一样进行查询，查询一个动态表会产生持续查询（Continuous Query）。连续查询永远不会终止，并会生成另一个动态表。查询（Query）会不断更新其动态结果表，以反映其动态输入表上的更改。</p>
<h3 id="流式持续查询的过程"><a href="#流式持续查询的过程" class="headerlink" title="流式持续查询的过程"></a>流式持续查询的过程</h3><p>下图显示了流、动态表和连续查询的关系：</p>
<p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gebyby4r2yj20ji035jt2.jpg" alt="2.png"></p>
<p>流式持续查询的过程为：</p>
<ol>
<li><p>流被转换为动态表。</p>
</li>
<li><p>对动态表计算连续查询，生成新的动态表。</p>
</li>
<li><p>生成的动态表被转换回流。</p>
</li>
</ol>
<h3 id="将流转换成表（Table）"><a href="#将流转换成表（Table）" class="headerlink" title="将流转换成表（Table）"></a>将流转换成表（Table）</h3><p>为了处理带有关系查询的流，必须先将其转换为表。</p>
<p>从概念上讲，流的每个数据记录，都被解释为对结果表的插入（Insert）修改。因为流式持续不断的，而且之前的输出结果无法改变。本质上，我们其实是从一个、只有插入操作的changelog（更新日志）流，来构建一个表。</p>
<p>为了更好地说明动态表和持续查询的概念，我们来举一个具体的例子。</p>
<p>比如，我们现在的输入数据，就是用户在网站上的访问行为，数据类型（Schema）如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">  user:  VARCHAR,   // 用户名</span><br><span class="line">  cTime: TIMESTAMP, // 访问某个URL的时间戳</span><br><span class="line">  url:   VARCHAR    // 用户访问的URL</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>下图显示了如何将访问URL事件流，或者叫点击事件流（左侧）转换为表（右侧）。</p>
<p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gebyly5qi6j20ex05e74v.jpg" alt="3.png"></p>
<p>随着插入更多的访问事件流记录，生成的表将不断增长。</p>
<h3 id="持续查询（Continuous-Query）"><a href="#持续查询（Continuous-Query）" class="headerlink" title="持续查询（Continuous Query）"></a>持续查询（Continuous Query）</h3><p>持续查询，会在动态表上做计算处理，并作为结果生成新的动态表。与批处理查询不同，连续查询从不终止，并根据输入表上的更新更新其结果表。</p>
<p>在任何时间点，连续查询的结果在语义上，等同于在输入表的快照上，以批处理模式执行的同一查询的结果。</p>
<p>在下面的示例中，我们展示了对点击事件流中的一个持续查询。</p>
<p>这个Query很简单，是一个分组聚合做count统计的查询。它将用户字段上的clicks表分组，并统计访问的url数。图中显示了随着时间的推移，当clicks表被其他行更新时如何计算查询。</p>
<p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gebyo6k1awj20lr0aljsg.jpg" alt="4.png"></p>
<h3 id="将动态表转换成流"><a href="#将动态表转换成流" class="headerlink" title="将动态表转换成流"></a>将动态表转换成流</h3><p>与常规的数据库表一样，动态表可以通过插入（Insert）、更新（Update）和删除（Delete）更改，进行持续的修改。将动态表转换为流或将其写入外部系统时，需要对这些更改进行编码。Flink的Table API和SQL支持三种方式对动态表的更改进行编码：</p>
<p>1).仅追加（Append-only）流</p>
<p>仅通过插入（Insert）更改，来修改的动态表，可以直接转换为“仅追加”流。这个流中发出的数据，就是动态表中新增的每一行。</p>
<p>2).撤回（Retract）流</p>
<p>Retract流是包含两类消息的流，添加（Add）消息和撤回（Retract）消息。</p>
<p>动态表通过将INSERT 编码为add消息、DELETE 编码为retract消息、UPDATE编码为被更改行（前一行）的retract消息和更新后行（新行）的add消息，转换为retract流。</p>
<p>下图显示了将动态表转换为Retract流的过程。</p>
<p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gebyrhzrcdj20kf081t9b.jpg" alt="5.png"></p>
<p>3).Upsert（更新插入）流</p>
<p>Upsert流包含两种类型的消息：Upsert消息和delete消息。转换为upsert流的动态表，需要有唯一的键（key）。</p>
<p>通过将INSERT和UPDATE更改编码为upsert消息，将DELETE更改编码为DELETE消息，就可以将具有唯一键（Unique Key）的动态表转换为流。</p>
<p>下图显示了将动态表转换为upsert流的过程。</p>
<p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gebz2a1sjmj20kk089js9.jpg" alt="6.png"></p>
<p>这些概念我们之前都已提到过。需要注意的是，在代码里将动态表转换为DataStream时，仅支持Append和Retract流。而向外部系统输出动态表的TableSink接口，则可以有不同的实现，比如之前我们讲到的ES，就可以有Upsert模式。</p>
<h2 id="时间特性"><a href="#时间特性" class="headerlink" title="时间特性"></a>时间特性</h2><p>基于时间的操作（比如Table API和SQL中窗口操作），需要定义相关的时间语义和时间数据来源的信息。所以，Table可以提供一个逻辑上的时间字段，用于在表处理程序中，指示时间和访问相应的时间戳。</p>
<p>时间属性，可以是每个表schema的一部分。一旦定义了时间属性，它就可以作为一个字段引用，并且可以在基于时间的操作中使用。</p>
<p>时间属性的行为类似于常规时间戳，可以访问，并且进行计算。</p>
<h3 id="Processing-Time"><a href="#Processing-Time" class="headerlink" title="Processing Time"></a>Processing Time</h3><p>处理时间语义下，允许表处理程序根据机器的本地时间生成结果。它是时间的最简单概念。它既不需要提取时间戳，也不需要生成watermark。</p>
<p>定义处理时间属性有三种方法：在DataStream转化时直接指定；在定义Table Schema时指定；在创建表的DDL中指定。</p>
<h4 id="DataStream转换成Table时指定"><a href="#DataStream转换成Table时指定" class="headerlink" title="DataStream转换成Table时指定"></a>DataStream转换成Table时指定</h4><p>由DataStream转换成表的时候，可以在后面指定字段名来定义Schema。在定义Schema期间，可以使用.proctime定义处理时间字段。</p>
<p>注意，这个proctime属性只能通过附加逻辑字段，来拓展物理schema，因此，</p>
<p><strong>只能在schema定义的末尾定义它。</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义好schema</span></span><br><span class="line"><span class="keyword">val</span> inputStream: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">"\\sensor.txt"</span>)</span><br><span class="line"><span class="keyword">val</span> dataStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = inputStream</span><br><span class="line">  .map(data =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> dataArray = data.split(<span class="string">","</span>)</span><br><span class="line">    <span class="type">SensorReading</span>(dataArray(<span class="number">0</span>), dataArray(<span class="number">1</span>).toLong, dataArray(<span class="number">2</span>).toDouble)</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream转换为 Table，并指定时间字段</span></span><br><span class="line"><span class="keyword">val</span> sensorTable = tableEnv.fromDataStream(dataStream, <span class="symbol">'id</span>, <span class="symbol">'temperature</span>, <span class="symbol">'timestamp</span>, <span class="symbol">'pt</span>.proctime)</span><br></pre></td></tr></table></figure>

<h4 id="定义Table-Schema-时指定"><a href="#定义Table-Schema-时指定" class="headerlink" title="定义Table Schema 时指定"></a>定义Table Schema 时指定</h4><p>定义Schema的时候，加上一个新字段，指定成proctime就可以。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.connect(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">FileSystem</span>().path(<span class="string">"..\\sensor.txt"</span>))</span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">Csv</span>())</span><br><span class="line">  .withSchema(<span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">    .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">    .field(<span class="string">"timestamp"</span>, <span class="type">DataTypes</span>.<span class="type">BIGINT</span>())</span><br><span class="line">    .field(<span class="string">"temperature"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">    .field(<span class="string">"pt"</span>, <span class="type">DataTypes</span>.<span class="type">TIMESTAMP</span>(<span class="number">3</span>))</span><br><span class="line">      .proctime()    <span class="comment">// 指定 pt字段为处理时间</span></span><br><span class="line">  ) <span class="comment">// 定义表结构</span></span><br><span class="line">  .createTemporaryTable(<span class="string">"inputTable"</span>) <span class="comment">// 创建临时表</span></span><br></pre></td></tr></table></figure>

<h4 id="创建表的DDL中指定"><a href="#创建表的DDL中指定" class="headerlink" title="创建表的DDL中指定"></a>创建表的DDL中指定</h4><p>在创建表的DDL中，增加一个字段并指定成proctime，也可以指定当前的时间字段。</p>
<p>代码如下:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sinkDDL: <span class="type">String</span> =</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |create table dataTable (</span></span><br><span class="line"><span class="string">    |  id varchar(20) not null,</span></span><br><span class="line"><span class="string">    |  ts bigint,</span></span><br><span class="line"><span class="string">    |  temperature double,</span></span><br><span class="line"><span class="string">    |  pt AS PROCTIME()</span></span><br><span class="line"><span class="string">    |) with (</span></span><br><span class="line"><span class="string">    |  'connector.type' = 'filesystem',</span></span><br><span class="line"><span class="string">    |  'connector.path' = 'file:///D:\\..\\sensor.txt',</span></span><br><span class="line"><span class="string">    |  'format.type' = 'csv'</span></span><br><span class="line"><span class="string">    |)</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin</span><br><span class="line"></span><br><span class="line">tableEnv.sqlUpdate(sinkDDL) <span class="comment">// 执行 DDL</span></span><br></pre></td></tr></table></figure>

<p>注意：运行这段DDL，必须使用Blink Planner。</p>
<h3 id="事件时间（Event-Time）"><a href="#事件时间（Event-Time）" class="headerlink" title="事件时间（Event Time）"></a>事件时间（Event Time）</h3><p>事件时间语义，允许表处理程序根据每个记录中包含的时间生成结果。这样即使在有乱序事件或者延迟事件时，也可以获得正确的结果。</p>
<p>为了处理无序事件，并区分流中的准时和迟到事件；Flink需要从事件数据中，提取时间戳，并用来推进事件时间的进展（watermark）。</p>
<h4 id="DataStream转化成Table时指定"><a href="#DataStream转化成Table时指定" class="headerlink" title="DataStream转化成Table时指定"></a>DataStream转化成Table时指定</h4><p>在DataStream转换成Table，schema的定义期间，使用.rowtime可以定义事件时间属性。</p>
<p>注意，必须在转换的数据流中分配时间戳和watermark。</p>
<p>在将数据流转换为表时，有两种定义时间属性的方法。根据指定的.rowtime字段名是否存在于数据流的架构中，timestamp字段可以：</p>
<ol>
<li><p><strong>作为新字段追加到schema</strong></p>
</li>
<li><p><strong>替换现有字段</strong></p>
</li>
</ol>
<p>在这两种情况下，定义的事件时间戳字段，都将保存DataStream中事件时间戳的值。</p>
<p>代码如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> inputStream: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">"\\sensor.txt"</span>)</span><br><span class="line"><span class="keyword">val</span> dataStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = inputStream</span><br><span class="line">    .map(data =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> dataArray = data.split(<span class="string">","</span>)</span><br><span class="line">        <span class="type">SensorReading</span>(dataArray(<span class="number">0</span>), dataArray(<span class="number">1</span>).toLong, dataArray(<span class="number">2</span>).toDouble)</span><br><span class="line">      &#125;)</span><br><span class="line">    .assignAscendingTimestamps(_.timestamp * <span class="number">1000</span>L)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 DataStream转换为 Table，并指定时间字段</span></span><br><span class="line"><span class="keyword">val</span> sensorTable = tableEnv.fromDataStream(dataStream, <span class="symbol">'id</span>, <span class="symbol">'timestamp</span>.rowtime, <span class="symbol">'temperature</span>)</span><br><span class="line"><span class="comment">// 或者，直接追加字段</span></span><br><span class="line"><span class="keyword">val</span> sensorTable2 = tableEnv.fromDataStream(dataStream, <span class="symbol">'id</span>, <span class="symbol">'temperature</span>, <span class="symbol">'timestamp</span>, <span class="symbol">'rt</span>.rowtime)</span><br></pre></td></tr></table></figure>

<h4 id="定义Schema时指定"><a href="#定义Schema时指定" class="headerlink" title="定义Schema时指定"></a>定义Schema时指定</h4><p>这种方法只要在定义Schema的时候，将事件时间指定，并指定成rowtime就可以了。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.connect(</span><br><span class="line">  <span class="keyword">new</span> <span class="type">FileSystem</span>().path(<span class="string">"sensor.txt"</span>))</span><br><span class="line">  .withFormat(<span class="keyword">new</span> <span class="type">Csv</span>())</span><br><span class="line">  .withSchema(<span class="keyword">new</span> <span class="type">Schema</span>()</span><br><span class="line">    .field(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">STRING</span>())</span><br><span class="line">    .field(<span class="string">"timestamp"</span>, <span class="type">DataTypes</span>.<span class="type">BIGINT</span>())</span><br><span class="line">      .rowtime(</span><br><span class="line">        <span class="keyword">new</span> <span class="type">Rowtime</span>()</span><br><span class="line">          .timestampsFromField(<span class="string">"timestamp"</span>)    <span class="comment">// 从字段中提取时间戳</span></span><br><span class="line">          .watermarksPeriodicBounded(<span class="number">1000</span>)    <span class="comment">// watermark延迟1秒</span></span><br><span class="line">      )</span><br><span class="line">    .field(<span class="string">"temperature"</span>, <span class="type">DataTypes</span>.<span class="type">DOUBLE</span>())</span><br><span class="line">  ) <span class="comment">// 定义表结构</span></span><br><span class="line">  .createTemporaryTable(<span class="string">"inputTable"</span>) <span class="comment">// 创建临时表</span></span><br></pre></td></tr></table></figure>

<h4 id="创建表的DDL中指定-1"><a href="#创建表的DDL中指定-1" class="headerlink" title="创建表的DDL中指定"></a>创建表的DDL中指定</h4><p>事件时间属性，是使用CREATE TABLE DDL中的WARDMARK语句定义的。watermark语句，定义现有事件时间字段上的watermark生成表达式，该表达式将事件时间字段标记为事件时间属性。</p>
<p>代码如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sinkDDL: <span class="type">String</span> =</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |create table dataTable (</span></span><br><span class="line"><span class="string">    |  id varchar(20) not null,</span></span><br><span class="line"><span class="string">    |  ts bigint,</span></span><br><span class="line"><span class="string">    |  temperature double,</span></span><br><span class="line"><span class="string">    |  rt AS TO_TIMESTAMP( FROM_UNIXTIME(ts) ),</span></span><br><span class="line"><span class="string">    |  watermark for rt as rt - interval '1' second</span></span><br><span class="line"><span class="string">    |) with (</span></span><br><span class="line"><span class="string">    |  'connector.type' = 'filesystem',</span></span><br><span class="line"><span class="string">    |  'connector.path' = 'file:///D:\\..\\sensor.txt',</span></span><br><span class="line"><span class="string">    |  'format.type' = 'csv'</span></span><br><span class="line"><span class="string">    |)</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span>.stripMargin</span><br><span class="line"></span><br><span class="line">tableEnv.sqlUpdate(sinkDDL) <span class="comment">// 执行 DDL</span></span><br></pre></td></tr></table></figure>

<p>这里<em>FROM_UNIXTIME</em>是系统内置的时间函数，用来将一个整数（秒数）转换成“YYYY-MM-DD hh:mm:ss”格式（默认，也可以作为第二个String参数传入）的日期时间字符串（date time string）；然后再用<em>TO_TIMESTAMP</em>将其转换成Timestamp。</p>
<h2 id="窗口（Windows）"><a href="#窗口（Windows）" class="headerlink" title="窗口（Windows）"></a>窗口（Windows）</h2><p>时间语义，要配合窗口操作才能发挥作用。最主要的用途，当然就是开窗口、根据时间段做计算了。下面我们就来看看Table API和SQL中，怎么利用时间字段做窗口操作。</p>
<p>在Table API和SQL中，主要有两种窗口：Group Windows和Over Windows</p>
<h4 id="分组窗口"><a href="#分组窗口" class="headerlink" title="分组窗口"></a>分组窗口</h4><p>分组窗口（Group Windows）会根据时间或行计数间隔，将行聚合到有限的组（Group）中，并对每个组的数据执行一次聚合函数。</p>
<p>Table API中的Group Windows都是使用.window（w:GroupWindow）子句定义的，并且必须由as子句指定一个别名。为了按窗口对表进行分组，窗口的别名必须在group by子句中，像常规的分组字段一样引用。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> table = input</span><br><span class="line">  .window([w: <span class="type">GroupWindow</span>] as <span class="symbol">'w</span>) <span class="comment">// 定义窗口，别名 w</span></span><br><span class="line">  .groupBy(<span class="symbol">'w</span>, <span class="symbol">'a</span>)  <span class="comment">// 以属性a和窗口w作为分组的key </span></span><br><span class="line">  .select(<span class="symbol">'a</span>, <span class="symbol">'b</span>.sum)  <span class="comment">// 聚合字段b的值，求和</span></span><br></pre></td></tr></table></figure>

<p>或者，还可以把窗口的相关信息，作为字段添加到结果表中：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> table = input</span><br><span class="line">  .window([w: <span class="type">GroupWindow</span>] as <span class="symbol">'w</span>) </span><br><span class="line">  .groupBy(<span class="symbol">'w</span>, <span class="symbol">'a</span>) </span><br><span class="line">  .select(<span class="symbol">'a</span>, <span class="symbol">'w</span>.start, <span class="symbol">'w</span>.end, <span class="symbol">'w</span>.rowtime, <span class="symbol">'b</span>.count)</span><br></pre></td></tr></table></figure>

<p>Table API提供了一组具有特定语义的预定义Window类，这些类会被转换为底层DataStream或DataSet的窗口操作。</p>
<p>Table API支持的窗口定义，和我们熟悉的一样，主要也是三种：滚动（Tumbling）、滑动（Sliding）和会话（Session）。</p>
<h4 id="滚动窗口"><a href="#滚动窗口" class="headerlink" title="滚动窗口"></a>滚动窗口</h4><p>滚动窗口（Tumbling windows）要用Tumble类来定义，另外还有三个方法：</p>
<p>over：定义窗口长度</p>
<p>on：用来分组（按时间间隔）或者排序（按行数）的时间字段</p>
<p>as：别名，必须出现在后面的groupBy中</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Tumbling Event-time Window（事件时间字段rowtime）</span></span><br><span class="line">.window(<span class="type">Tumble</span> over <span class="number">10.</span>minutes on <span class="symbol">'rowtime</span> as <span class="symbol">'w</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Tumbling Processing-time Window（处理时间字段proctime）</span></span><br><span class="line">.window(<span class="type">Tumble</span> over <span class="number">10.</span>minutes on <span class="symbol">'proctime</span> as <span class="symbol">'w</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Tumbling Row-count Window (类似于计数窗口，按处理时间排序，10行一组)</span></span><br><span class="line">.window(<span class="type">Tumble</span> over <span class="number">10.</span>rows on <span class="symbol">'proctime</span> as <span class="symbol">'w</span>)</span><br></pre></td></tr></table></figure>

<h4 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h4><p>滑动窗口（Sliding windows）要用Slide类来定义，另外还有四个方法：</p>
<p>over：定义窗口长度</p>
<p>every：定义滑动步长</p>
<p>on：用来分组（按时间间隔）或者排序（按行数）的时间字段</p>
<p>as：别名，必须出现在后面的groupBy中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Sliding Event-time Window</span></span><br><span class="line">.window(Slide over <span class="number">10</span>.minutes every <span class="number">5</span>.minutes on <span class="string">'rowtime as '</span>w)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Sliding Processing-time window </span></span><br><span class="line">.window(Slide over <span class="number">10</span>.minutes every <span class="number">5</span>.minutes on <span class="string">'proctime as '</span>w)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Sliding Row-count window</span></span><br><span class="line">.window(Slide over <span class="number">10</span>.rows every <span class="number">5</span>.rows on <span class="string">'proctime as '</span>w)</span><br></pre></td></tr></table></figure>

<h4 id="会话窗口"><a href="#会话窗口" class="headerlink" title="会话窗口"></a>会话窗口</h4><p>会话窗口（Session windows）要用Session类来定义，另外还有三个方法：</p>
<ul>
<li><p>withGap：会话时间间隔</p>
</li>
<li><p>on：用来分组（按时间间隔）或者排序（按行数）的时间字段</p>
</li>
<li><p>as：别名，必须出现在后面的groupBy中</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Session Event-time Window</span></span><br><span class="line">.window(Session withGap <span class="number">10</span>.minutes on <span class="string">'rowtime as '</span>w)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Session Processing-time Window </span></span><br><span class="line">.window(Session withGap <span class="number">10</span>.minutes on <span class="string">'proctime as '</span>w)</span><br></pre></td></tr></table></figure>

<h4 id="Over-Windows"><a href="#Over-Windows" class="headerlink" title="Over Windows"></a>Over Windows</h4><p>Over window聚合是标准SQL中已有的（Over子句），可以在查询的SELECT子句中定义。Over window 聚合，会针对每个输入行，计算相邻行范围内的聚合。Over windows<br>使用.window（w:overwindows*）子句定义，并在select（）方法中通过别名来引用。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val table = input</span><br><span class="line">  .window([w: OverWindow] as <span class="string">'w)</span></span><br><span class="line"><span class="string">  .select('</span>a, <span class="string">'b.sum over '</span>w, <span class="string">'c.min over '</span>w)</span><br></pre></td></tr></table></figure>

<p>Table API提供了Over类，来配置Over窗口的属性。可以在事件时间或处理时间，以及指定为时间间隔、或行计数的范围内，定义Over windows。</p>
<p>无界的over window是使用常量指定的。也就是说，时间间隔要指定UNBOUNDED_RANGE，或者行计数间隔要指定UNBOUNDED_ROW。而有界的over window是用间隔的大小指定的。</p>
<p>实际代码应用如下：</p>
<p>1） 无界的 over window</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 无界的事件时间over window (时间字段 "rowtime")</span></span><br><span class="line">.window(Over partitionBy <span class="string">'a orderBy '</span>rowtime preceding UNBOUNDED_RANGE as <span class="string">'w)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">//无界的处理时间over window (时间字段"proctime")</span></span><br><span class="line"><span class="string">.window(Over partitionBy '</span>a orderBy <span class="string">'proctime preceding UNBOUNDED_RANGE as '</span>w)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 无界的事件时间Row-count over window (时间字段 "rowtime")</span></span><br><span class="line">.window(Over partitionBy <span class="string">'a orderBy '</span>rowtime preceding UNBOUNDED_ROW as <span class="string">'w)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">//无界的处理时间Row-count over window (时间字段 "rowtime")</span></span><br><span class="line"><span class="string">.window(Over partitionBy '</span>a orderBy <span class="string">'proctime preceding UNBOUNDED_ROW as '</span>w)</span><br></pre></td></tr></table></figure>

<p>2） 有界的over window</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 有界的事件时间over window (时间字段 "rowtime"，之前1分钟)</span></span><br><span class="line">.window(Over partitionBy <span class="string">'a orderBy '</span>rowtime preceding <span class="number">1</span>.minutes as <span class="string">'w)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">// 有界的处理时间over window (时间字段 "rowtime"，之前1分钟)</span></span><br><span class="line"><span class="string">.window(Over partitionBy '</span>a orderBy <span class="string">'proctime preceding 1.minutes as '</span>w)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 有界的事件时间Row-count over window (时间字段 "rowtime"，之前10行)</span></span><br><span class="line">.window(Over partitionBy <span class="string">'a orderBy '</span>rowtime preceding <span class="number">10</span>.rows as <span class="string">'w)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">// 有界的处理时间Row-count over window (时间字段 "rowtime"，之前10行)</span></span><br><span class="line"><span class="string">.window(Over partitionBy '</span>a orderBy <span class="string">'proctime preceding 10.rows as '</span>w)</span><br></pre></td></tr></table></figure>

<h3 id="SQL中窗口的定义"><a href="#SQL中窗口的定义" class="headerlink" title="SQL中窗口的定义"></a>SQL中窗口的定义</h3><p>我们已经了解了在Table API里window的调用方式，同样，我们也可以在SQL中直接加入窗口的定义和使用。</p>
<h4 id="Group-Windows"><a href="#Group-Windows" class="headerlink" title="Group Windows"></a>Group Windows</h4><p>Group Windows在SQL查询的Group BY子句中定义。与使用常规GROUP BY子句的查询一样，使用GROUP BY子句的查询会计算每个组的单个结果行。</p>
<p>SQL支持以下Group窗口函数:</p>
<ul>
<li>TUMBLE(time_attr, interval)</li>
</ul>
<p>定义一个滚动窗口，第一个参数是时间字段，第二个参数是窗口长度。</p>
<ul>
<li>HOP(time_attr, interval, interval)</li>
</ul>
<p>定义一个滑动窗口，第一个参数是时间字段，第二个参数是窗口滑动步长，第三个是窗口长度。</p>
<ul>
<li>SESSION(time_attr, interval)</li>
</ul>
<p>定义一个会话窗口，第一个参数是时间字段，第二个参数是窗口间隔（Gap）。</p>
<p>另外还有一些辅助函数，可以用来选择Group Window的开始和结束时间戳，以及时间属性。</p>
<p>这里只写TUMBLE_<em>，滑动和会话窗口是类似的（HOP_</em>，SESSION_*）。</p>
<ul>
<li>TUMBLE_START(time_attr, interval)</li>
<li>TUMBLE_END(time_attr, interval)</li>
<li>TUMBLE_ROWTIME(time_attr, interval)</li>
<li>TUMBLE_PROCTIME(time_attr, interval)</li>
</ul>
<h4 id="Over-Windows-1"><a href="#Over-Windows-1" class="headerlink" title="Over Windows"></a>Over Windows</h4><p>由于Over本来就是SQL内置支持的语法，所以这在SQL中属于基本的聚合操作。所有聚合必须在同一窗口上定义，也就是说，必须是相同的分区、排序和范围。目前仅支持在当前行范围之前的窗口（无边界和有边界）。</p>
<p>注意，ORDER BY必须在单一的时间属性上指定。</p>
<p>代码如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(amount) <span class="keyword">OVER</span> (</span><br><span class="line">  <span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">user</span></span><br><span class="line">  <span class="keyword">ORDER</span> <span class="keyword">BY</span> proctime</span><br><span class="line">  <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">2</span> <span class="keyword">PRECEDING</span> <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="keyword">ROW</span>)</span><br><span class="line"><span class="keyword">FROM</span> Orders</span><br><span class="line"></span><br><span class="line">// 也可以做多个聚合</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(amount) <span class="keyword">OVER</span> w, <span class="keyword">SUM</span>(amount) <span class="keyword">OVER</span> w</span><br><span class="line"><span class="keyword">FROM</span> Orders</span><br><span class="line"><span class="keyword">WINDOW</span> w <span class="keyword">AS</span> (</span><br><span class="line">  <span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">user</span></span><br><span class="line">  <span class="keyword">ORDER</span> <span class="keyword">BY</span> proctime</span><br><span class="line">  <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">2</span> <span class="keyword">PRECEDING</span> <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="keyword">ROW</span>)</span><br></pre></td></tr></table></figure>

<h3 id="CASE"><a href="#CASE" class="headerlink" title="CASE"></a>CASE</h3><p>开一个滚动窗口，统计10秒内出现的每个sensor的个数。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    </span><br><span class="line">	<span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">	env.setParallelism(<span class="number">1</span>)</span><br><span class="line">	env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">val</span> streamFromFile: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">"sensor.txt"</span>)</span><br><span class="line">	<span class="keyword">val</span> dataStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = streamFromFile</span><br><span class="line">.map( data =&gt; </span><br><span class="line">     &#123;</span><br><span class="line">	<span class="keyword">val</span> dataArray = data.split(<span class="string">","</span>)</span><br><span class="line">	<span class="type">SensorReading</span>(dataArray(<span class="number">0</span>).trim, dataArray(<span class="number">1</span>).trim.toLong, dataArray(<span class="number">2</span>).trim.toDouble)</span><br><span class="line">&#125; )</span><br><span class="line">	.assignTimestampsAndWatermarks( <span class="keyword">new</span> <span class="type">BoundedOutOfOrdernessTimestampExtractor</span>[<span class="type">SensorReading</span>](<span class="type">Time</span>.seconds(<span class="number">1</span>)) &#123;</span><br><span class="line">	<span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">extractTimestamp</span></span>(element: <span class="type">SensorReading</span>): <span class="type">Long</span> = element.timestamp * <span class="number">1000</span>L</span><br><span class="line">&#125; )</span><br><span class="line"></span><br><span class="line">	<span class="keyword">val</span> settings: <span class="type">EnvironmentSettings</span> = <span class="type">EnvironmentSettings</span></span><br><span class="line">										.newInstance()</span><br><span class="line">                                        .useOldPlanner()</span><br><span class="line">                                        .inStreamingMode()</span><br><span class="line">                                        .build()</span><br><span class="line">	<span class="keyword">val</span> tableEnv: <span class="type">StreamTableEnvironment</span> = </span><br><span class="line"><span class="type">StreamTableEnvironment</span>.create(env, settings)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">val</span> dataTable: <span class="type">Table</span> = tableEnv</span><br><span class="line">.fromDataStream(dataStream, <span class="symbol">'id</span>, <span class="symbol">'temperature</span>, <span class="symbol">'timestamp</span>.rowtime)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">val</span> resultTable: <span class="type">Table</span> = dataTable</span><br><span class="line">                                .window(<span class="type">Tumble</span> over <span class="number">10.</span>seconds on <span class="symbol">'timestamp</span> as <span class="symbol">'tw</span>)</span><br><span class="line">                                .groupBy(<span class="symbol">'id</span>, <span class="symbol">'tw</span>)</span><br><span class="line">                                .select(<span class="symbol">'id</span>, <span class="symbol">'id</span>.count)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">val</span> sqlDataTable: <span class="type">Table</span> = dataTable</span><br><span class="line">.select(<span class="symbol">'id</span>, <span class="symbol">'temperature</span>, <span class="symbol">'timestamp</span> as <span class="symbol">'ts</span>)</span><br><span class="line">	<span class="keyword">val</span> resultSqlTable: <span class="type">Table</span> = tableEnv</span><br><span class="line">.sqlQuery(<span class="string">"select id, count(id) from "</span> </span><br><span class="line">+ sqlDataTable </span><br><span class="line">+ <span class="string">" group by id,tumble(ts,interval '10' second)"</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 把 Table转化成数据流</span></span><br><span class="line">	<span class="keyword">val</span> resultDstream: <span class="type">DataStream</span>[(<span class="type">Boolean</span>, (<span class="type">String</span>, <span class="type">Long</span>))] = 		resultSqlTable.toRetractStream[(<span class="type">String</span>, <span class="type">Long</span>)]</span><br><span class="line"></span><br><span class="line">	resultDstream.filter(_._1).print()</span><br><span class="line">	env.execute()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><p>Flink Table 和 SQL内置了很多SQL中支持的函数；如果有无法满足的需要，则可以实现用户自定义的函数（UDF）来解决。</p>
<h3 id="系统内置函数"><a href="#系统内置函数" class="headerlink" title="系统内置函数"></a>系统内置函数</h3><p>Flink Table API 和 SQL为用户提供了一组用于数据转换的内置函数。SQL中支持的很多函数，Table API和SQL都已经做了实现，其它还在快速开发扩展中。</p>
<p>以下是一些典型函数的举例，全部的内置函数，可以参考官网介绍。</p>
<table>
<thead>
<tr>
<th>内置函数</th>
<th>SQL</th>
<th>Table API</th>
</tr>
</thead>
<tbody><tr>
<td>判断比较</td>
<td>value1 = value2</td>
<td>ANY1 === ANY2</td>
</tr>
<tr>
<td></td>
<td>value1 &gt; value2</td>
<td>ANY1 &gt; ANY2</td>
</tr>
<tr>
<td>逻辑函数</td>
<td>boolean1 OR boolean2</td>
<td>BOOLEAN1</td>
</tr>
<tr>
<td></td>
<td>boolean IS FALSE</td>
<td>BOOLEAN.isFalse</td>
</tr>
<tr>
<td></td>
<td>NOT boolean</td>
<td>!BOOLEAN</td>
</tr>
<tr>
<td>算数函数</td>
<td>numeric1 + numeric2</td>
<td>NUMERIC1 + NUMERIC2</td>
</tr>
<tr>
<td></td>
<td>POWER(numeric1, numeric2)</td>
<td>NUMERIC1.power(NUMERIC2)</td>
</tr>
<tr>
<td>字符串函数</td>
<td>string1 丨丨 string2</td>
<td>string1 + string2</td>
</tr>
<tr>
<td></td>
<td>UPPER(string)</td>
<td>String.upperCase()</td>
</tr>
<tr>
<td></td>
<td>CHAR_LENGTH(string)</td>
<td>STRING.charLength()</td>
</tr>
<tr>
<td>时间函数</td>
<td>DATE string</td>
<td>STRING.toDate</td>
</tr>
<tr>
<td></td>
<td>TIMESTAMP string</td>
<td>STRING.toTimestamp</td>
</tr>
<tr>
<td></td>
<td>CURRENT_TIME</td>
<td>currentTime()</td>
</tr>
<tr>
<td></td>
<td>INTERVAL string range</td>
<td>NUMERIC.days</td>
</tr>
<tr>
<td></td>
<td></td>
<td>NUMERIC.minutes</td>
</tr>
<tr>
<td>聚合函数</td>
<td>COUNT(*)</td>
<td>FIELD.count</td>
</tr>
<tr>
<td></td>
<td>SUM([ALL丨DISTINCT] expression)</td>
<td>FIELD.sum0</td>
</tr>
<tr>
<td></td>
<td>RANK()</td>
<td></td>
</tr>
<tr>
<td></td>
<td>ROW_NUMBER()</td>
<td></td>
</tr>
</tbody></table>
<h3 id="UDF"><a href="#UDF" class="headerlink" title="UDF"></a>UDF</h3><p>在大多数情况下，用户定义的函数必须先注册，然后才能在查询中使用。不需要专门为Scala 的Table API注册函数。</p>
<p>函数通过调用registerFunction（）方法在TableEnvironment中注册。当用户定义的函数被注册时，它被插入到TableEnvironment的函数目录中，这样Table API或SQL解析器就可以识别并正确地解释它。</p>
<h4 id="标量函数"><a href="#标量函数" class="headerlink" title="标量函数"></a>标量函数</h4><p>用户定义的标量函数，可以将0、1或多个标量值，映射到新的标量值。</p>
<p>为了定义标量函数，必须在org.apache.flink.table.functions中扩展基类Scalar Function，并实现（一个或多个）求值（evaluation，eval）方法。标量函数的行为由求值方法决定，求值方法必须公开声明并命名为eval（直接def声明，没有override）。求值方法的参数类型和返回类型，确定了标量函数的参数和返回类型。</p>
<p>在下面的代码中，我们定义自己的HashCode函数，在TableEnvironment中注册它，并在查询中调用它。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 自定义一个标量函数</span></span><br><span class="line">class HashCode( factor: Int ) extends ScalarFunction &#123;</span><br><span class="line">  <span class="function">def <span class="title">eval</span><span class="params">( s: String )</span>: Int </span>= &#123;</span><br><span class="line">    s.hashCode * factor</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>主函数中调用，计算sensor id的哈希值（前面部分照抄，流环境、表环境、读取source、建表）：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">  env.setParallelism(<span class="number">1</span>)</span><br><span class="line">  env.setStreamTimeCharacteristic(<span class="type">TimeCharacteristic</span>.<span class="type">EventTime</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> settings = <span class="type">EnvironmentSettings</span></span><br><span class="line">    .newInstance()</span><br><span class="line">    .useOldPlanner()</span><br><span class="line">    .inStreamingMode()</span><br><span class="line">    .build()</span><br><span class="line">  <span class="keyword">val</span> tableEnv = <span class="type">StreamTableEnvironment</span>.create( env, settings )</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 定义好 DataStream</span></span><br><span class="line">  <span class="keyword">val</span> inputStream: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">"..\\sensor.txt"</span>)</span><br><span class="line">  <span class="keyword">val</span> dataStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = inputStream</span><br><span class="line">    .map(data =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> dataArray = data.split(<span class="string">","</span>)</span><br><span class="line">      <span class="type">SensorReading</span>(dataArray(<span class="number">0</span>), dataArray(<span class="number">1</span>).toLong, dataArray(<span class="number">2</span>).toDouble)</span><br><span class="line">    &#125;)</span><br><span class="line">    .assignAscendingTimestamps(_.timestamp * <span class="number">1000</span>L)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将 DataStream转换为 Table，并指定时间字段</span></span><br><span class="line">  <span class="keyword">val</span> sensorTable = tableEnv.fromDataStream(dataStream, <span class="symbol">'id</span>, <span class="symbol">'timestamp</span>.rowtime, <span class="symbol">'temperature</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Table API中使用</span></span><br><span class="line">  <span class="keyword">val</span> hashCode = <span class="keyword">new</span> <span class="type">HashCode</span>(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> resultTable = sensorTable</span><br><span class="line">    .select( <span class="symbol">'id</span>, hashCode(<span class="symbol">'id</span>) )</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// SQL 中使用</span></span><br><span class="line">  tableEnv.createTemporaryView(<span class="string">"sensor"</span>, sensorTable)</span><br><span class="line">  tableEnv.registerFunction(<span class="string">"hashCode"</span>, hashCode)</span><br><span class="line">  <span class="keyword">val</span> resultSqlTable = tableEnv.sqlQuery(<span class="string">"select id, hashCode(id) from sensor"</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 转换成流，打印输出</span></span><br><span class="line">  resultTable.toAppendStream[<span class="type">Row</span>].print(<span class="string">"table"</span>)</span><br><span class="line">  resultSqlTable.toAppendStream[<span class="type">Row</span>].print(<span class="string">"sql"</span>)</span><br><span class="line"> </span><br><span class="line">  env.execute()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="表函数（Table-Functions）"><a href="#表函数（Table-Functions）" class="headerlink" title="表函数（Table Functions）"></a>表函数（Table Functions）</h4><p>与用户定义的标量函数类似，用户定义的表函数，可以将0、1或多个标量值作为输入参数；与标量函数不同的是，它可以返回任意数量的行作为输出，而不是单个值。</p>
<p>为了定义一个表函数，必须扩展org.apache.flink.table.functions中的基类TableFunction并实现（一个或多个）求值方法。表函数的行为由其求值方法决定，求值方法必须是public的，并命名为eval。求值方法的参数类型，决定表函数的所有有效参数。</p>
<p>返回表的类型由TableFunction的泛型类型确定。求值方法使用protected collect（T）方法发出输出行。</p>
<p>在Table API中，Table函数需要与.joinLateral或.leftOuterJoinLateral一起使用。</p>
<p>joinLateral算子，会将外部表中的每一行，与表函数（TableFunction，算子的参数是它的表达式）计算得到的所有行连接起来。</p>
<p>而leftOuterJoinLateral算子，则是左外连接，它同样会将外部表中的每一行与表函数计算生成的所有行连接起来；并且，对于表函数返回的是空表的外部行，也要保留下来。</p>
<p>在SQL中，则需要使用Lateral Table（<tablefunction>），或者带有ON TRUE条件的左连接。</tablefunction></p>
<p>下面的代码中，我们将定义一个表函数，在表环境中注册它，并在查询中调用它。</p>
<p>自定义TableFunction：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 自定义TableFunction</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Split</span>(<span class="params">separator: <span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">TableFunction</span>[(<span class="type">String</span>, <span class="type">Int</span>)]</span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">eval</span></span>(str: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    str.split(separator).foreach(</span><br><span class="line">      word =&gt; collect((word, word.length))</span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>接下来，就是在代码中调用。首先是Table API的方式：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">	<span class="comment">// Table API中调用，需要用joinLateral</span></span><br><span class="line">    <span class="keyword">val</span> resultTable = sensorTable</span><br><span class="line">      .joinLateral(split(<span class="symbol">'id</span>) as (<span class="symbol">'word</span>, <span class="symbol">'length</span>))   <span class="comment">// as对输出行的字段重命名</span></span><br><span class="line">      .select(<span class="symbol">'id</span>, <span class="symbol">'word</span>, <span class="symbol">'length</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment">// 或者用leftOuterJoinLateral</span></span><br><span class="line">    <span class="keyword">val</span> resultTable2 = sensorTable</span><br><span class="line">      .leftOuterJoinLateral(split(<span class="symbol">'id</span>) as (<span class="symbol">'word</span>, <span class="symbol">'length</span>))</span><br><span class="line">      .select(<span class="symbol">'id</span>, <span class="symbol">'word</span>, <span class="symbol">'length</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 转换成流打印输出</span></span><br><span class="line">    resultTable.toAppendStream[<span class="type">Row</span>].print(<span class="string">"1"</span>)</span><br><span class="line">    resultTable2.toAppendStream[<span class="type">Row</span>].print(<span class="string">"2"</span>)</span><br></pre></td></tr></table></figure>

<p>然后是SQL的方式</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.createTemporaryView(<span class="string">"sensor"</span>, sensorTable)</span><br><span class="line">tableEnv.registerFunction(<span class="string">"split"</span>, split)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultSqlTable = tableEnv.sqlQuery(</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |select id, word, length</span></span><br><span class="line"><span class="string">    |from</span></span><br><span class="line"><span class="string">    |sensor, LATERAL TABLE(split(id)) AS newsensor(word, length)</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 或者用左连接的方式</span></span><br><span class="line"><span class="keyword">val</span> resultSqlTable2 = tableEnv.sqlQuery(</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |SELECT id, word, length</span></span><br><span class="line"><span class="string">    |FROM</span></span><br><span class="line"><span class="string">    |sensor</span></span><br><span class="line"><span class="string">    |LEFT JOIN </span></span><br><span class="line"><span class="string">    |LATERAL TABLE(split(id)) AS newsensor(word, length) </span></span><br><span class="line"><span class="string">    |ON TRUE</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 转换成流打印输出</span></span><br><span class="line">resultSqlTable.toAppendStream[<span class="type">Row</span>].print(<span class="string">"1"</span>)</span><br><span class="line">resultSqlTable2.toAppendStream[<span class="type">Row</span>].print(<span class="string">"2"</span>)</span><br></pre></td></tr></table></figure>

<h4 id="聚合函数-aggregate-Function"><a href="#聚合函数-aggregate-Function" class="headerlink" title="聚合函数(aggregate Function)"></a>聚合函数(aggregate Function)</h4><p>用户自定义聚合函数（User-Defined Aggregate Functions，UDAGGs）可以把一个表中的数据，聚合成一个标量值。用户定义的聚合函数，是通过继承AggregateFunction抽象类实现的。</p>
<p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gejnzvbpitj20jf0b6jsm.jpg" alt="1.png"></p>
<p>上图中显示了一个聚合的例子。</p>
<p>假设现在有一张表，包含了各种饮料的数据。该表由三列（id、name和price）、五行组成数据。现在我们需要找到表中所有饮料的最高价格，即执行max（）聚合，结果将是一个数值。</p>
<p>AggregateFunction的工作原理如下。</p>
<ul>
<li><p>首先，它需要一个累加器，用来保存聚合中间结果的数据结构（状态）。可以通过调用AggregateFunction的createAccumulator（）方法创建空累加器。</p>
</li>
<li><p>随后，对每个输入行调用函数的accumulate（）方法来更新累加器。</p>
</li>
<li><p>处理完所有行后，将调用函数的getValue（）方法来计算并返回最终结果。</p>
</li>
</ul>
<p>AggregationFunction要求必须实现的方法：</p>
<ul>
<li><p>createAccumulator()</p>
</li>
<li><p>accumulate()</p>
</li>
<li><p>getValue()</p>
</li>
</ul>
<p>除了上述方法之外，还有一些可选择实现的方法。其中一些方法，可以让系统执行查询更有效率，而另一些方法，对于某些场景是必需的。例如，如果聚合函数应用在会话窗口（session group window）的上下文中，则merge（）方法是必需的。</p>
<ul>
<li><p>retract() </p>
</li>
<li><p>merge() </p>
</li>
<li><p>resetAccumulator()</p>
</li>
</ul>
<p>除了上述方法之外，还有一些可选择实现的方法。其中一些方法，可以让系统执行查询更有效率，而另一些方法，对于某些场景是必需的。例如，如果聚合函数应用在会话窗口（session group window）的上下文中，则merge（）方法是必需的。</p>
<ul>
<li>retract()</li>
<li>merge()</li>
<li>resetAccumulator()</li>
</ul>
<p>接下来自定义AggregateFunction,计算一下每个sensor的平均温度值。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义AggregateFunction的Accumulator</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AvgTempAcc</span> </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> sum: <span class="type">Double</span> = <span class="number">0.0</span></span><br><span class="line">  <span class="keyword">var</span> count: <span class="type">Int</span> = <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AvgTemp</span> <span class="keyword">extends</span> <span class="title">AggregateFunction</span>[<span class="type">Double</span>, <span class="type">AvgTempAcc</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValue</span></span>(accumulator: <span class="type">AvgTempAcc</span>): <span class="type">Double</span> =</span><br><span class="line">    accumulator.sum / accumulator.count</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createAccumulator</span></span>(): <span class="type">AvgTempAcc</span> = <span class="keyword">new</span> <span class="type">AvgTempAcc</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">accumulate</span></span>(accumulator: <span class="type">AvgTempAcc</span>, temp: <span class="type">Double</span>): <span class="type">Unit</span> =&#123;</span><br><span class="line">    accumulator.sum += temp</span><br><span class="line">    accumulator.count += <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>接下来就可以在代码中调用了</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建一个聚合函数实例</span></span><br><span class="line"><span class="keyword">val</span> avgTemp = <span class="keyword">new</span> <span class="type">AvgTemp</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">// Table API的调用 </span></span><br><span class="line"><span class="keyword">val</span> resultTable = sensorTable.groupBy(<span class="symbol">'id</span>)</span><br><span class="line">  .aggregate(avgTemp(<span class="symbol">'temperature</span>) as <span class="symbol">'avgTemp</span>)</span><br><span class="line">  .select(<span class="symbol">'id</span>, <span class="symbol">'avgTemp</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// SQL的实现</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">"sensor"</span>, sensorTable)</span><br><span class="line">tableEnv.registerFunction(<span class="string">"avgTemp"</span>, avgTemp)</span><br><span class="line"><span class="keyword">val</span> resultSqlTable = tableEnv.sqlQuery(</span><br><span class="line">  <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    |SELECT</span></span><br><span class="line"><span class="string">    |id, avgTemp(temperature)</span></span><br><span class="line"><span class="string">    |FROM</span></span><br><span class="line"><span class="string">    |sensor</span></span><br><span class="line"><span class="string">    |GROUP BY id</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>.stripMargin)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 转换成流打印输出</span></span><br><span class="line">resultTable.toRetractStream[(<span class="type">String</span>, <span class="type">Double</span>)].print(<span class="string">"agg temp"</span>)</span><br><span class="line">resultSqlTable.toRetractStream[<span class="type">Row</span>].print(<span class="string">"agg temp sql"</span>)</span><br></pre></td></tr></table></figure>

<h3 id="表聚合函数（Table-Aggregate-Functions）"><a href="#表聚合函数（Table-Aggregate-Functions）" class="headerlink" title="表聚合函数（Table Aggregate Functions）"></a>表聚合函数（Table Aggregate Functions）</h3><p>用户定义的表聚合函数（User-Defined Table Aggregate Functions，UDTAGGs），可以把一个表中数据，聚合为具有多行和多列的结果表。这跟AggregateFunction非常类似，只是之前聚合结果是一个标量值，现在变成了一张表。</p>
<p><img src="http://ww1.sinaimg.cn/large/bec9bff2gy1gejo6fdbb4j20je09cta0.jpg" alt="2.png"></p>
<p>比如现在我们需要找到表中所有饮料的前2个最高价格，即执行top2（）表聚合。我们需要检查5行中的每一行，得到的结果将是一个具有排序后前2个值的表。</p>
<p>用户定义的表聚合函数，是通过继承TableAggregateFunction抽象类来实现的。</p>
<p>TableAggregateFunction的工作原理如下。</p>
<ul>
<li><p>首先，它同样需要一个累加器（Accumulator），它是保存聚合中间结果的数据结构。通过调用TableAggregateFunction的createAccumulator（）方法可以创建空累加器。</p>
</li>
<li><p>随后，对每个输入行调用函数的accumulate（）方法来更新累加器。</p>
</li>
<li><p>处理完所有行后，将调用函数的emitValue（）方法来计算并返回最终结果。</p>
</li>
</ul>
<p>AggregationFunction要求必须实现的方法：</p>
<ul>
<li><p>createAccumulator()</p>
</li>
<li><p>accumulate()</p>
</li>
</ul>
<p>除了上述方法之外，还有一些可选择实现的方法。</p>
<ul>
<li>retract() </li>
<li>merge()  </li>
<li>resetAccumulator() </li>
<li>emitValue() </li>
<li>emitUpdateWithRetract()</li>
</ul>
<p>接下来我们写一个自定义TableAggregateFunction，用来提取每个sensor最高的两个温度值。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 先定义一个 Accumulator </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Top2TempAcc</span></span>&#123;</span><br><span class="line">  <span class="keyword">var</span> highestTemp: <span class="type">Double</span> = <span class="type">Int</span>.<span class="type">MinValue</span></span><br><span class="line">  <span class="keyword">var</span> secondHighestTemp: <span class="type">Double</span> = <span class="type">Int</span>.<span class="type">MinValue</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 自定义 TableAggregateFunction</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Top2Temp</span> <span class="keyword">extends</span> <span class="title">TableAggregateFunction</span>[(<span class="type">Double</span>, <span class="type">Int</span>), <span class="type">Top2TempAcc</span>]</span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createAccumulator</span></span>(): <span class="type">Top2TempAcc</span> = <span class="keyword">new</span> <span class="type">Top2TempAcc</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">accumulate</span></span>(acc: <span class="type">Top2TempAcc</span>, temp: <span class="type">Double</span>): <span class="type">Unit</span> =&#123;</span><br><span class="line">    <span class="keyword">if</span>( temp &gt; acc.highestTemp )&#123;</span><br><span class="line">      acc.secondHighestTemp = acc.highestTemp</span><br><span class="line">      acc.highestTemp = temp</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span>( temp &gt; acc.secondHighestTemp )&#123;</span><br><span class="line">      acc.secondHighestTemp = temp</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">emitValue</span></span>(acc: <span class="type">Top2TempAcc</span>, out: <span class="type">Collector</span>[(<span class="type">Double</span>, <span class="type">Int</span>)]): <span class="type">Unit</span> =&#123;</span><br><span class="line">    out.collect(acc.highestTemp, <span class="number">1</span>)</span><br><span class="line">    out.collect(acc.secondHighestTemp, <span class="number">2</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>接下来就可以在代码中调用了。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建一个表聚合函数实例</span></span><br><span class="line"><span class="keyword">val</span> top2Temp = <span class="keyword">new</span> <span class="type">Top2Temp</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">// Table API的调用</span></span><br><span class="line"><span class="keyword">val</span> resultTable = sensorTable.groupBy(<span class="symbol">'id</span>)</span><br><span class="line">  .flatAggregate( top2Temp(<span class="symbol">'temperature</span>) as (<span class="symbol">'temp</span>, <span class="symbol">'rank</span>) )</span><br><span class="line">  .select(<span class="symbol">'id</span>, <span class="symbol">'temp</span>, <span class="symbol">'rank</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 转换成流打印输出</span></span><br><span class="line">resultTable.toRetractStream[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Int</span>)].print(<span class="string">"agg temp"</span>)</span><br><span class="line">resultSqlTable.toRetractStream[<span class="type">Row</span>].print(<span class="string">"agg temp sql"</span>)</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/04/27/Flink State/" rel="prev" title="Flink State">
      <i class="fa fa-chevron-left"></i> Flink State
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/05/07/美团数据质量/" rel="next" title="美团数据质量监管平台实践">
      美团数据质量监管平台实践 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC80Mzk4NC8yMDUyMA=="></div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Flink-Table-amp-SQL"><span class="nav-number">1.</span> <span class="nav-text">Flink Table &amp; SQL</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#依赖"><span class="nav-number">1.1.</span> <span class="nav-text">依赖</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#两种Planner的区别"><span class="nav-number">1.2.</span> <span class="nav-text">两种Planner的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#API"><span class="nav-number">1.3.</span> <span class="nav-text">API</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基本程序结构"><span class="nav-number">1.3.1.</span> <span class="nav-text">基本程序结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建表环境"><span class="nav-number">1.3.2.</span> <span class="nav-text">创建表环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#注册表"><span class="nav-number">1.3.3.</span> <span class="nav-text">注册表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#连接到文件系统（CSV）"><span class="nav-number">1.3.4.</span> <span class="nav-text">连接到文件系统（CSV）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#连接到Kafka"><span class="nav-number">1.3.5.</span> <span class="nav-text">连接到Kafka</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#表的查询"><span class="nav-number">1.3.6.</span> <span class="nav-text">表的查询</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TableAPI的调用"><span class="nav-number">1.3.7.</span> <span class="nav-text">TableAPI的调用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SQL查询"><span class="nav-number">1.3.8.</span> <span class="nav-text">SQL查询</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#将DataStream转换成表"><span class="nav-number">1.3.9.</span> <span class="nav-text">将DataStream转换成表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据类型与-Table-schema的对应"><span class="nav-number">1.3.10.</span> <span class="nav-text">数据类型与 Table schema的对应</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建临时视图（Temporary-View）"><span class="nav-number">1.3.11.</span> <span class="nav-text">创建临时视图（Temporary View）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#输出表"><span class="nav-number">1.3.12.</span> <span class="nav-text">输出表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#更新模式"><span class="nav-number">1.3.13.</span> <span class="nav-text">更新模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#输出到Kafka"><span class="nav-number">1.3.14.</span> <span class="nav-text">输出到Kafka</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#输出到ES"><span class="nav-number">1.3.15.</span> <span class="nav-text">输出到ES</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#输出到MySQL"><span class="nav-number">1.3.16.</span> <span class="nav-text">输出到MySQL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Table转换为DataStream"><span class="nav-number">1.3.17.</span> <span class="nav-text">Table转换为DataStream</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Query的解释和执行"><span class="nav-number">1.3.18.</span> <span class="nav-text">Query的解释和执行</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#流处理中的特殊概念"><span class="nav-number">1.4.</span> <span class="nav-text">流处理中的特殊概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Dynamic-Tables"><span class="nav-number">1.4.1.</span> <span class="nav-text">Dynamic Tables</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#流式持续查询的过程"><span class="nav-number">1.4.2.</span> <span class="nav-text">流式持续查询的过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#将流转换成表（Table）"><span class="nav-number">1.4.3.</span> <span class="nav-text">将流转换成表（Table）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#持续查询（Continuous-Query）"><span class="nav-number">1.4.4.</span> <span class="nav-text">持续查询（Continuous Query）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#将动态表转换成流"><span class="nav-number">1.4.5.</span> <span class="nav-text">将动态表转换成流</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#时间特性"><span class="nav-number">1.5.</span> <span class="nav-text">时间特性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Processing-Time"><span class="nav-number">1.5.1.</span> <span class="nav-text">Processing Time</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#DataStream转换成Table时指定"><span class="nav-number">1.5.1.1.</span> <span class="nav-text">DataStream转换成Table时指定</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#定义Table-Schema-时指定"><span class="nav-number">1.5.1.2.</span> <span class="nav-text">定义Table Schema 时指定</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建表的DDL中指定"><span class="nav-number">1.5.1.3.</span> <span class="nav-text">创建表的DDL中指定</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#事件时间（Event-Time）"><span class="nav-number">1.5.2.</span> <span class="nav-text">事件时间（Event Time）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#DataStream转化成Table时指定"><span class="nav-number">1.5.2.1.</span> <span class="nav-text">DataStream转化成Table时指定</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#定义Schema时指定"><span class="nav-number">1.5.2.2.</span> <span class="nav-text">定义Schema时指定</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建表的DDL中指定-1"><span class="nav-number">1.5.2.3.</span> <span class="nav-text">创建表的DDL中指定</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#窗口（Windows）"><span class="nav-number">1.6.</span> <span class="nav-text">窗口（Windows）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#分组窗口"><span class="nav-number">1.6.0.1.</span> <span class="nav-text">分组窗口</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#滚动窗口"><span class="nav-number">1.6.0.2.</span> <span class="nav-text">滚动窗口</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#滑动窗口"><span class="nav-number">1.6.0.3.</span> <span class="nav-text">滑动窗口</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#会话窗口"><span class="nav-number">1.6.0.4.</span> <span class="nav-text">会话窗口</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Over-Windows"><span class="nav-number">1.6.0.5.</span> <span class="nav-text">Over Windows</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SQL中窗口的定义"><span class="nav-number">1.6.1.</span> <span class="nav-text">SQL中窗口的定义</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Group-Windows"><span class="nav-number">1.6.1.1.</span> <span class="nav-text">Group Windows</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Over-Windows-1"><span class="nav-number">1.6.1.2.</span> <span class="nav-text">Over Windows</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CASE"><span class="nav-number">1.6.2.</span> <span class="nav-text">CASE</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#函数"><span class="nav-number">1.7.</span> <span class="nav-text">函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#系统内置函数"><span class="nav-number">1.7.1.</span> <span class="nav-text">系统内置函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#UDF"><span class="nav-number">1.7.2.</span> <span class="nav-text">UDF</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#标量函数"><span class="nav-number">1.7.2.1.</span> <span class="nav-text">标量函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#表函数（Table-Functions）"><span class="nav-number">1.7.2.2.</span> <span class="nav-text">表函数（Table Functions）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#聚合函数-aggregate-Function"><span class="nav-number">1.7.2.3.</span> <span class="nav-text">聚合函数(aggregate Function)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#表聚合函数（Table-Aggregate-Functions）"><span class="nav-number">1.7.3.</span> <span class="nav-text">表聚合函数（Table Aggregate Functions）</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Fly Hugh"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Fly Hugh</p>
  <div class="site-description" itemprop="description">WE CHOOSE TO  GO TO THE MARS</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">69</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">39</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">59</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/FlyMeToTheMars" title="GitHub → https://github.com/FlyMeToTheMars" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/flyhobo@live.com" title="E-Mail → flyhobo@live.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/u/3200892914" title="Weibo → https://weibo.com/u/3200892914" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/Fly__HoBo" title="Twitter → https://twitter.com/Fly__HoBo" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Fly Hugh</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  















  

  

<script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script>

</body>
</html>
